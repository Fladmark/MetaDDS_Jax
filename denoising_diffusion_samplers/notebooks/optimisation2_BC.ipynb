{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-14T01:54:03.870674Z",
     "end_time": "2023-05-14T01:54:03.893127Z"
    }
   },
   "outputs": [],
   "source": [
    "from dds.configs.config import set_task, get_config\n",
    "from dds.train_dds import train_dds\n",
    "\n",
    "import numpy as onp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-14T01:54:04.290932Z",
     "end_time": "2023-05-14T01:54:04.421496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "funnel_config = get_config()\n",
    "\n",
    "# Time and step settings (Need to be done before calling set_task)\n",
    "funnel_config.model.tfinal = 6.4\n",
    "funnel_config.model.dt = 0.05 #0.05\n",
    "\n",
    "if funnel_config.model.reference_process_key == \"oudstl\":\n",
    "    funnel_config.model.step_scheme_key = \"cos_sq\"\n",
    "\n",
    "from dds.targets.toy_targets import get_attr\n",
    "### SET TASK\n",
    "task = \"breastcancer\"\n",
    "div = 10\n",
    "c = 100000\n",
    "\n",
    "# div, e, other_dim = get_attr()\n",
    "# div = str(div).replace(\".\", \"\")\n",
    "# e = str(e).replace(\".\", \"\")\n",
    "#\n",
    "# save_name = f\"{task}_s{div}_plus{e}_od{other_dim}\"\n",
    "\n",
    "\n",
    "funnel_config = set_task(funnel_config, task, div, c)\n",
    "funnel_config.model.reference_process_key = \"oudstl\"\n",
    "funnel_config.model.reference_process_key = \"pisstl\"\n",
    "funnel_config.model.step_scheme_key = \"uniform\"\n",
    "funnel_config.model.step_scheme_key = \"cos_sq\"\n",
    "# funnel_config.model.reference_process_key = \"pisstl\"\n",
    "# funnel_config.model.step_scheme_key = \"uniform\"\n",
    "\n",
    "# exp_dec\n",
    "# cos_sq\n",
    "# uniform\n",
    "# last_small\n",
    "# linear_dds\n",
    "# linear\n",
    "# uniform_dds\n",
    "\n",
    "if funnel_config.model.reference_process_key == \"oudstl\":\n",
    "    funnel_config.model.step_scheme_key = \"cos_sq\"\n",
    "    \n",
    "    # Opt setting for funnel\n",
    "    funnel_config.model.sigma = 1.075\n",
    "    funnel_config.model.alpha = 0.6875\n",
    "    funnel_config.model.m = 1.0\n",
    "        \n",
    "    # Path opt settings    \n",
    "    funnel_config.model.exp_dds = False\n",
    "\n",
    "\n",
    "funnel_config.model.stl = False\n",
    "funnel_config.model.detach_stl_drift = False\n",
    "\n",
    "# funnel_config.model.stl = True\n",
    "# funnel_config.model.detach_stl_drift = True\n",
    "\n",
    "funnel_config.trainer.notebook = True\n",
    "funnel_config.trainer.epochs = 50\n",
    "# Opt settings we use\n",
    "# funnel_config.trainer.learning_rate = 0.0001\n",
    "funnel_config.trainer.learning_rate = 1 * 10**(-3)\n",
    "funnel_config.trainer.lr_sch_base_dec = 0.90 # For funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "Best training loss: 0.044401127845048904\n",
      "Best validation loss: 0.059328533709049225\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9894366264343262\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 0.9866197109222412\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9720279574394226\n",
      "Test Accuracy (AVG): 0.8741258382797241\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9790209531784058\n",
      "Test Accuracy (AVG): 0.8321678042411804\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -92056.328125)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -95487.953125)\n",
      "Best training loss: 0.008022007532417774\n",
      "Best validation loss: 0.035031337291002274\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.692307710647583\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9020978808403015\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -95480.9609375)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -94248.6953125)\n",
      "Best training loss: 0.0034495277795940638\n",
      "Best validation loss: 0.0328511968255043\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.8461538553237915\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -92967.921875)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -92249.859375)\n",
      "Best training loss: 0.0033989737275987864\n",
      "Best validation loss: 0.03882298618555069\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.8601398468017578\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.11888112127780914\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -92153.875)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -92459.390625)\n",
      "Best training loss: 0.003653177060186863\n",
      "Best validation loss: 0.039873674511909485\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6993007063865662\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7342657446861267\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -93089.109375)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -93737.4921875)\n",
      "Best training loss: 0.0034834810066968203\n",
      "Best validation loss: 0.0341450534760952\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.8461538553237915\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.37062937021255493\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -94507.34375)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -95198.484375)\n",
      "Best training loss: 0.004040985368192196\n",
      "Best validation loss: 0.030509233474731445\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.867132842540741\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.8881118893623352\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -95789.15625)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -96261.140625)\n",
      "Best training loss: 0.0052755894139409065\n",
      "Best validation loss: 0.034325357526540756\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7202796936035156\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -96590.953125)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -96801.671875)\n",
      "Best training loss: 0.005362612660974264\n",
      "Best validation loss: 0.03569081798195839\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.8531468510627747\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.8041958212852478\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -96931.765625)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -97020.375)\n",
      "Best training loss: 0.0044991448521614075\n",
      "Best validation loss: 0.03699710965156555\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.6013985872268677\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.5174825191497803\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -97158.3828125)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -97350.4765625)\n",
      "Best training loss: 0.00182019651401788\n",
      "Best validation loss: 0.03751206770539284\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.5874125957489014\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.4615384638309479\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -97503.6015625)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -97630.9609375)\n",
      "Best training loss: 0.0007522116065956652\n",
      "Best validation loss: 0.04013533517718315\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.748251736164093\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.5384615063667297\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -97704.6796875)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -97757.671875)\n",
      "Best training loss: 0.000286170921754092\n",
      "Best validation loss: 0.031076161190867424\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7062937021255493\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.4965035021305084\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -97811.0859375)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -97882.25)\n",
      "Best training loss: 0.00016250880435109138\n",
      "Best validation loss: 0.03895275294780731\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.6503496170043945\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -98021.8125)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -98210.453125)\n",
      "Best training loss: 7.44056305848062e-05\n",
      "Best validation loss: 0.04906775802373886\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9922534883022308\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7902097702026367\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -98441.375)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -98705.4296875)\n",
      "Best training loss: 2.578912244644016e-05\n",
      "Best validation loss: 0.03977348282933235\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.881118893623352\n",
      "('epoch: %s %s  loss: %s', 30, 'TRAIN', -98962.9609375)\n",
      "('epoch: %s %s  loss: %s', 31, 'TRAIN', -99157.6171875)\n",
      "Best training loss: 8.38391588331433e-06\n",
      "Best validation loss: 0.029506051912903786\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 32, 'TRAIN', -99312.7421875)\n",
      "('epoch: %s %s  loss: %s', 33, 'TRAIN', -99404.015625)\n",
      "Best training loss: 2.5585581170162186e-05\n",
      "Best validation loss: 0.05402872711420059\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 34, 'TRAIN', -99315.84375)\n",
      "('epoch: %s %s  loss: %s', 35, 'TRAIN', -97496.2734375)\n",
      "Best training loss: 2.111273488480947e-06\n",
      "Best validation loss: 0.06652255356311798\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9823943316936493\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 36, 'TRAIN', -97579.4609375)\n",
      "('epoch: %s %s  loss: %s', 37, 'TRAIN', -98996.6171875)\n",
      "Best training loss: 1.3679160474566743e-05\n",
      "Best validation loss: 0.10341755300760269\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788732051849365\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 38, 'TRAIN', -99069.140625)\n",
      "('epoch: %s %s  loss: %s', 39, 'TRAIN', -99326.796875)\n",
      "Best training loss: 2.8319478587945923e-05\n",
      "Best validation loss: 0.11164163053035736\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 40, 'TRAIN', -99592.1015625)\n",
      "('epoch: %s %s  loss: %s', 41, 'TRAIN', -99546.8984375)\n",
      "Best training loss: 1.2112463082303293e-05\n",
      "Best validation loss: 0.09922941029071808\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.978873199224472\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 42, 'TRAIN', -99683.234375)\n",
      "('epoch: %s %s  loss: %s', 43, 'TRAIN', -99792.1015625)\n",
      "Best training loss: 1.609989794815192e-06\n",
      "Best validation loss: 0.15707942843437195\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9739436328411102\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 44, 'TRAIN', -99857.8359375)\n",
      "('epoch: %s %s  loss: %s', 45, 'TRAIN', -99851.9140625)\n",
      "Best training loss: 1.1318949191263528e-06\n",
      "Best validation loss: 0.24685491621494293\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9725351870059967\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 46, 'TRAIN', -99908.1171875)\n",
      "('epoch: %s %s  loss: %s', 47, 'TRAIN', -99894.921875)\n",
      "Best training loss: 1.0305080877515138e-06\n",
      "Best validation loss: 0.12153219431638718\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9774647533893586\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 48, 'TRAIN', -99916.75)\n",
      "('epoch: %s %s  loss: %s', 49, 'TRAIN', -99894.5)\n",
      "Best training loss: 2.1970574834995205e-06\n",
      "Best validation loss: 0.09266781061887741\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 50, 'TRAIN', -99867.5078125)\n",
      "('epoch: %s %s  loss: %s', 51, 'TRAIN', -99857.703125)\n",
      "Best training loss: 1.925037622640957e-06\n",
      "Best validation loss: 0.058055441826581955\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.983098566532135\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 52, 'TRAIN', -99755.3671875)\n",
      "('epoch: %s %s  loss: %s', 53, 'TRAIN', -99581.984375)\n",
      "Best training loss: 1.535098363092402e-06\n",
      "Best validation loss: 0.0570872463285923\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 54, 'TRAIN', -99402.875)\n",
      "('epoch: %s %s  loss: %s', 55, 'TRAIN', -99298.15625)\n",
      "Best training loss: 1.3054559531155974e-06\n",
      "Best validation loss: 0.06461145728826523\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 56, 'TRAIN', -99320.9375)\n",
      "('epoch: %s %s  loss: %s', 57, 'TRAIN', -99386.546875)\n",
      "Best training loss: 2.196250306951697e-06\n",
      "Best validation loss: 0.06422781199216843\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 58, 'TRAIN', -99431.875)\n",
      "('epoch: %s %s  loss: %s', 59, 'TRAIN', -99380.0546875)\n",
      "Best training loss: 3.1890474474494113e-06\n",
      "Best validation loss: 0.06564682722091675\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 60, 'TRAIN', -99469.3203125)\n",
      "('epoch: %s %s  loss: %s', 61, 'TRAIN', -99754.375)\n",
      "Best training loss: 9.41322809921985e-07\n",
      "Best validation loss: 0.11288467794656754\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 62, 'TRAIN', -99798.1484375)\n",
      "('epoch: %s %s  loss: %s', 63, 'TRAIN', -99820.1796875)\n",
      "Best training loss: 8.701671845301462e-07\n",
      "Best validation loss: 0.11522028595209122\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 64, 'TRAIN', -99910.625)\n",
      "('epoch: %s %s  loss: %s', 65, 'TRAIN', -100007.9921875)\n",
      "Best training loss: 1.7409975043847226e-06\n",
      "Best validation loss: 0.12227126955986023\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 66, 'TRAIN', -100023.859375)\n",
      "('epoch: %s %s  loss: %s', 67, 'TRAIN', -100035.1875)\n",
      "Best training loss: 2.1635260054608807e-06\n",
      "Best validation loss: 0.12299347668886185\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112531661987\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 68, 'TRAIN', -100047.9921875)\n",
      "('epoch: %s %s  loss: %s', 69, 'TRAIN', -100025.5234375)\n",
      "Best training loss: 1.7972353134609875e-06\n",
      "Best validation loss: 0.12017005681991577\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112531661987\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 70, 'TRAIN', -99982.5390625)\n",
      "('epoch: %s %s  loss: %s', 71, 'TRAIN', -99919.3515625)\n",
      "Best training loss: 1.2147944516982534e-06\n",
      "Best validation loss: 0.1151852011680603\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112472057343\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 72, 'TRAIN', -99768.6640625)\n",
      "('epoch: %s %s  loss: %s', 73, 'TRAIN', -99714.515625)\n",
      "Best training loss: 1.5892525198069052e-06\n",
      "Best validation loss: 0.11412456631660461\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 74, 'TRAIN', -99497.5703125)\n",
      "('epoch: %s %s  loss: %s', 75, 'TRAIN', -99423.9375)\n",
      "Best training loss: 1.813005610529217e-06\n",
      "Best validation loss: 0.11427069455385208\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 76, 'TRAIN', -99347.9296875)\n",
      "('epoch: %s %s  loss: %s', 77, 'TRAIN', -99314.7890625)\n",
      "Best training loss: 2.2265164716372965e-06\n",
      "Best validation loss: 0.11471927911043167\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9859154760837555\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 78, 'TRAIN', -99334.1328125)\n",
      "('epoch: %s %s  loss: %s', 79, 'TRAIN', -99198.2421875)\n",
      "Best training loss: 1.6660735582263442e-06\n",
      "Best validation loss: 0.11870432645082474\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 80, 'TRAIN', -99137.515625)\n",
      "('epoch: %s %s  loss: %s', 81, 'TRAIN', -99015.5859375)\n",
      "Best training loss: 1.645270231165341e-06\n",
      "Best validation loss: 0.12226800620555878\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 82, 'TRAIN', -98862.5)\n",
      "('epoch: %s %s  loss: %s', 83, 'TRAIN', -98820.1953125)\n",
      "Best training loss: 1.3978211654830375e-06\n",
      "Best validation loss: 0.11270260810852051\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 84, 'TRAIN', -98719.84375)\n",
      "('epoch: %s %s  loss: %s', 85, 'TRAIN', -99970.109375)\n",
      "Best training loss: 4.457792215362133e-07\n",
      "Best validation loss: 0.11232256144285202\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 86, 'TRAIN', -99982.5)\n",
      "('epoch: %s %s  loss: %s', 87, 'TRAIN', -100080.28125)\n",
      "Best training loss: 4.6592768399023043e-07\n",
      "Best validation loss: 0.11253050714731216\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 88, 'TRAIN', -100107.15625)\n",
      "('epoch: %s %s  loss: %s', 89, 'TRAIN', -100104.4375)\n",
      "Best training loss: 7.964907240420871e-07\n",
      "Best validation loss: 0.11615860462188721\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 90, 'TRAIN', -100095.4453125)\n",
      "('epoch: %s %s  loss: %s', 91, 'TRAIN', -100102.7578125)\n",
      "Best training loss: 5.242744691713597e-07\n",
      "Best validation loss: 0.12468845397233963\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112531661987\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 92, 'TRAIN', -100104.0)\n",
      "('epoch: %s %s  loss: %s', 93, 'TRAIN', -100106.2890625)\n",
      "Best training loss: 4.4368061935529113e-07\n",
      "Best validation loss: 0.16385728120803833\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 94, 'TRAIN', -100105.5390625)\n",
      "('epoch: %s %s  loss: %s', 95, 'TRAIN', -100110.671875)\n",
      "Best training loss: 6.76439697144815e-07\n",
      "Best validation loss: 0.18019185960292816\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 96, 'TRAIN', -100112.625)\n",
      "('epoch: %s %s  loss: %s', 97, 'TRAIN', -100095.28125)\n",
      "Best training loss: 7.914561024335853e-07\n",
      "Best validation loss: 0.1885680854320526\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774221420288\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 98, 'TRAIN', -100103.3671875)\n",
      "('epoch: %s %s  loss: %s', 99, 'TRAIN', -100089.3515625)\n",
      "Best training loss: 6.865121804366936e-07\n",
      "Best validation loss: 0.2268187552690506\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 100, 'TRAIN', -100061.6953125)\n",
      "('epoch: %s %s  loss: %s', 101, 'TRAIN', -99974.90625)\n",
      "Best training loss: 7.673186814827204e-07\n",
      "Best validation loss: 0.2320992350578308\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 102, 'TRAIN', -99781.21875)\n",
      "('epoch: %s %s  loss: %s', 103, 'TRAIN', -99790.8203125)\n",
      "Best training loss: 1.305475734625361e-06\n",
      "Best validation loss: 0.2133806347846985\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 104, 'TRAIN', -99573.0703125)\n",
      "('epoch: %s %s  loss: %s', 105, 'TRAIN', -99603.109375)\n",
      "Best training loss: 1.7899175190905225e-06\n",
      "Best validation loss: 0.1954619139432907\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774221420288\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 106, 'TRAIN', -99662.7890625)\n",
      "('epoch: %s %s  loss: %s', 107, 'TRAIN', -99825.3828125)\n",
      "Best training loss: 1.785719973668165e-06\n",
      "Best validation loss: 0.2124275267124176\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 108, 'TRAIN', -99951.78125)\n",
      "('epoch: %s %s  loss: %s', 109, 'TRAIN', -100000.828125)\n",
      "Best training loss: 1.8982634628628148e-06\n",
      "Best validation loss: 0.18405865132808685\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520786762238\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 110, 'TRAIN', -100043.4765625)\n",
      "('epoch: %s %s  loss: %s', 111, 'TRAIN', -100065.015625)\n",
      "Best training loss: 2.5695781005197205e-06\n",
      "Best validation loss: 0.2164531946182251\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520786762238\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 112, 'TRAIN', -100055.59375)\n",
      "('epoch: %s %s  loss: %s', 113, 'TRAIN', -100064.328125)\n",
      "Best training loss: 2.2571880435862113e-06\n",
      "Best validation loss: 0.24022895097732544\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9767605245113373\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 114, 'TRAIN', -100102.40625)\n",
      "('epoch: %s %s  loss: %s', 115, 'TRAIN', -100011.171875)\n",
      "Best training loss: 6.74131115374621e-07\n",
      "Best validation loss: 0.24352551996707916\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9732394099235535\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 116, 'TRAIN', -99483.921875)\n",
      "('epoch: %s %s  loss: %s', 117, 'TRAIN', -98739.171875)\n",
      "Best training loss: 1.1214099231438013e-06\n",
      "Best validation loss: 0.23142266273498535\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9725351870059967\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 118, 'TRAIN', -98372.7265625)\n",
      "('epoch: %s %s  loss: %s', 119, 'TRAIN', -98212.7421875)\n",
      "Best training loss: 1.1652746252366342e-06\n",
      "Best validation loss: 0.21358861029148102\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9725351870059967\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 120, 'TRAIN', -98510.8828125)\n",
      "('epoch: %s %s  loss: %s', 121, 'TRAIN', -98979.8125)\n",
      "Best training loss: 7.154778813855955e-07\n",
      "Best validation loss: 0.2066625952720642\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9725351870059967\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 122, 'TRAIN', -99630.1796875)\n",
      "('epoch: %s %s  loss: %s', 123, 'TRAIN', -99958.578125)\n",
      "Best training loss: 4.413712701989425e-07\n",
      "Best validation loss: 0.2157522290945053\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9732394099235535\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 124, 'TRAIN', -100090.6796875)\n",
      "('epoch: %s %s  loss: %s', 125, 'TRAIN', -100125.65625)\n",
      "Best training loss: 6.155738105917408e-07\n",
      "Best validation loss: 0.22307242453098297\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 126, 'TRAIN', -100129.203125)\n",
      "('epoch: %s %s  loss: %s', 127, 'TRAIN', -100107.03125)\n",
      "Best training loss: 7.885236072979751e-07\n",
      "Best validation loss: 0.23890964686870575\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9739436328411102\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 128, 'TRAIN', -100087.125)\n",
      "('epoch: %s %s  loss: %s', 129, 'TRAIN', -99947.265625)\n",
      "Best training loss: 1.36842811571114e-06\n",
      "Best validation loss: 0.2118746042251587\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.974647855758667\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 130, 'TRAIN', -99870.640625)\n",
      "('epoch: %s %s  loss: %s', 131, 'TRAIN', -99850.2265625)\n",
      "Best training loss: 1.7913819192472147e-06\n",
      "Best validation loss: 0.17183591425418854\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9781689703464508\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 132, 'TRAIN', -100101.140625)\n",
      "('epoch: %s %s  loss: %s', 133, 'TRAIN', -100121.78125)\n",
      "Best training loss: 1.917966073960997e-06\n",
      "Best validation loss: 0.19031447172164917\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9739436328411102\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 134, 'TRAIN', -100094.8515625)\n",
      "('epoch: %s %s  loss: %s', 135, 'TRAIN', -100040.3828125)\n",
      "Best training loss: 2.2500285012938548e-06\n",
      "Best validation loss: 0.23546256124973297\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 136, 'TRAIN', -99976.6796875)\n",
      "('epoch: %s %s  loss: %s', 137, 'TRAIN', -99995.1171875)\n",
      "Best training loss: 2.7284429506835295e-06\n",
      "Best validation loss: 0.2457580715417862\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 138, 'TRAIN', -99941.5859375)\n",
      "('epoch: %s %s  loss: %s', 139, 'TRAIN', -100011.65625)\n",
      "Best training loss: 1.5122079730645055e-06\n",
      "Best validation loss: 0.30118033289909363\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 140, 'TRAIN', -100012.75)\n",
      "('epoch: %s %s  loss: %s', 141, 'TRAIN', -99997.25)\n",
      "Best training loss: 1.3957303508504992e-06\n",
      "Best validation loss: 0.319198340177536\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 142, 'TRAIN', -99913.796875)\n",
      "('epoch: %s %s  loss: %s', 143, 'TRAIN', -99829.921875)\n",
      "Best training loss: 1.186480290016334e-06\n",
      "Best validation loss: 0.3307415544986725\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9704225182533264\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 144, 'TRAIN', -99742.84375)\n",
      "('epoch: %s %s  loss: %s', 145, 'TRAIN', -99577.015625)\n",
      "Best training loss: 1.2255145520612132e-06\n",
      "Best validation loss: 0.29034143686294556\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 146, 'TRAIN', -99528.0390625)\n",
      "('epoch: %s %s  loss: %s', 147, 'TRAIN', -99844.765625)\n",
      "Best training loss: 9.100498914449417e-07\n",
      "Best validation loss: 0.24651460349559784\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9732394099235535\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 148, 'TRAIN', -99676.359375)\n",
      "('epoch: %s %s  loss: %s', 149, 'TRAIN', -100042.984375)\n",
      "Best training loss: 8.015413186512887e-07\n",
      "Best validation loss: 0.18063776195049286\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 150, 'TRAIN', -100056.3203125)\n",
      "('epoch: %s %s  loss: %s', 151, 'TRAIN', -99939.4921875)\n",
      "Best training loss: 1.310949642174819e-06\n",
      "Best validation loss: 0.11975172907114029\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 152, 'TRAIN', -99770.4921875)\n",
      "('epoch: %s %s  loss: %s', 153, 'TRAIN', -99699.71875)\n",
      "Best training loss: 2.648043846420478e-05\n",
      "Best validation loss: 0.08822561800479889\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112472057343\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 154, 'TRAIN', -99765.5234375)\n",
      "('epoch: %s %s  loss: %s', 155, 'TRAIN', -99875.875)\n",
      "Best training loss: 0.00013494117592927068\n",
      "Best validation loss: 0.03981621935963631\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 156, 'TRAIN', -99899.765625)\n",
      "('epoch: %s %s  loss: %s', 157, 'TRAIN', -99941.0859375)\n",
      "Best training loss: 9.823856089496985e-05\n",
      "Best validation loss: 0.05162360519170761\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 158, 'TRAIN', -99984.953125)\n",
      "('epoch: %s %s  loss: %s', 159, 'TRAIN', -100005.5703125)\n",
      "Best training loss: 7.382078911177814e-05\n",
      "Best validation loss: 0.06113801896572113\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 160, 'TRAIN', -100023.25)\n",
      "('epoch: %s %s  loss: %s', 161, 'TRAIN', -100025.3671875)\n",
      "Best training loss: 2.6458164938958362e-05\n",
      "Best validation loss: 0.07043305039405823\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 162, 'TRAIN', -100034.9140625)\n",
      "('epoch: %s %s  loss: %s', 163, 'TRAIN', -100054.8671875)\n",
      "Best training loss: 8.694673852005508e-06\n",
      "Best validation loss: 0.07937037199735641\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9823943376541138\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 164, 'TRAIN', -100065.15625)\n",
      "('epoch: %s %s  loss: %s', 165, 'TRAIN', -100047.9921875)\n",
      "Best training loss: 6.276669409999158e-06\n",
      "Best validation loss: 0.06887097656726837\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 166, 'TRAIN', -100020.6796875)\n",
      "('epoch: %s %s  loss: %s', 167, 'TRAIN', -99977.5703125)\n",
      "Best training loss: 9.280971653424785e-07\n",
      "Best validation loss: 0.04785018414258957\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027834892273\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 168, 'TRAIN', -99992.359375)\n",
      "('epoch: %s %s  loss: %s', 169, 'TRAIN', -100026.3125)\n",
      "Best training loss: 1.3264133258417132e-07\n",
      "Best validation loss: 0.07580182701349258\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774340629577\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 170, 'TRAIN', -100017.734375)\n",
      "('epoch: %s %s  loss: %s', 171, 'TRAIN', -99958.921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1338682621717453\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.978873199224472\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 172, 'TRAIN', -99914.0078125)\n",
      "('epoch: %s %s  loss: %s', 173, 'TRAIN', -99728.46875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.09413806349039078\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 174, 'TRAIN', -99700.71875)\n",
      "('epoch: %s %s  loss: %s', 175, 'TRAIN', -100016.59375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1679123342037201\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9781689703464508\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 176, 'TRAIN', -99952.7734375)\n",
      "('epoch: %s %s  loss: %s', 177, 'TRAIN', -100130.9140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1991724669933319\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520786762238\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 178, 'TRAIN', -100129.203125)\n",
      "('epoch: %s %s  loss: %s', 179, 'TRAIN', -100129.328125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.21350812911987305\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9767605245113373\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 180, 'TRAIN', -100120.8359375)\n",
      "('epoch: %s %s  loss: %s', 181, 'TRAIN', -100121.828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1967184841632843\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 182, 'TRAIN', -100118.1953125)\n",
      "('epoch: %s %s  loss: %s', 183, 'TRAIN', -100109.1875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1803913116455078\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774221420288\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 184, 'TRAIN', -100085.875)\n",
      "('epoch: %s %s  loss: %s', 185, 'TRAIN', -100109.71875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.17329925298690796\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 186, 'TRAIN', -100086.0)\n",
      "('epoch: %s %s  loss: %s', 187, 'TRAIN', -100075.1875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.16046454012393951\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 188, 'TRAIN', -99988.2109375)\n",
      "('epoch: %s %s  loss: %s', 189, 'TRAIN', -99976.7734375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.15089921653270721\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 190, 'TRAIN', -99822.546875)\n",
      "('epoch: %s %s  loss: %s', 191, 'TRAIN', -99529.546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.09500973671674728\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 192, 'TRAIN', -100021.890625)\n",
      "('epoch: %s %s  loss: %s', 193, 'TRAIN', -100057.6015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.061610348522663116\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 194, 'TRAIN', -100067.0078125)\n",
      "('epoch: %s %s  loss: %s', 195, 'TRAIN', -100098.2578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.09723583608865738\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9901408195495606\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 196, 'TRAIN', -100127.6015625)\n",
      "('epoch: %s %s  loss: %s', 197, 'TRAIN', -100125.75)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.10520245134830475\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 198, 'TRAIN', -100130.6953125)\n",
      "('epoch: %s %s  loss: %s', 199, 'TRAIN', -100124.53125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2084047496318817\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520786762238\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 200, 'TRAIN', -100130.40625)\n",
      "('epoch: %s %s  loss: %s', 201, 'TRAIN', -100130.2421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.30068239569664\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9767605245113373\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 202, 'TRAIN', -100127.7578125)\n",
      "('epoch: %s %s  loss: %s', 203, 'TRAIN', -100119.140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.30185022950172424\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520786762238\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 204, 'TRAIN', -100100.0546875)\n",
      "('epoch: %s %s  loss: %s', 205, 'TRAIN', -100100.7734375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2233734428882599\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.974647855758667\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 206, 'TRAIN', -100055.78125)\n",
      "('epoch: %s %s  loss: %s', 207, 'TRAIN', -100080.6640625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2083262950181961\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520846366882\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 208, 'TRAIN', -100053.3359375)\n",
      "('epoch: %s %s  loss: %s', 209, 'TRAIN', -99945.3828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1955489218235016\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 210, 'TRAIN', -99319.28125)\n",
      "('epoch: %s %s  loss: %s', 211, 'TRAIN', -98492.390625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12948879599571228\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 212, 'TRAIN', -97740.359375)\n",
      "('epoch: %s %s  loss: %s', 213, 'TRAIN', -97715.8984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.192140132188797\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 214, 'TRAIN', -97674.2265625)\n",
      "('epoch: %s %s  loss: %s', 215, 'TRAIN', -98165.7421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.20774152874946594\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9774647533893586\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 216, 'TRAIN', -98792.46875)\n",
      "('epoch: %s %s  loss: %s', 217, 'TRAIN', -99880.625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.36588793992996216\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9683098495006561\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 218, 'TRAIN', -99719.203125)\n",
      "('epoch: %s %s  loss: %s', 219, 'TRAIN', -99954.796875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.43781349062919617\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9647887349128723\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 220, 'TRAIN', -100042.5625)\n",
      "('epoch: %s %s  loss: %s', 221, 'TRAIN', -100072.7890625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4740075170993805\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9647887349128723\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 222, 'TRAIN', -100057.015625)\n",
      "('epoch: %s %s  loss: %s', 223, 'TRAIN', -100017.046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.47928473353385925\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9647887349128723\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 224, 'TRAIN', -100000.9609375)\n",
      "('epoch: %s %s  loss: %s', 225, 'TRAIN', -99935.5625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.42401301860809326\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9661971807479859\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 226, 'TRAIN', -99889.15625)\n",
      "('epoch: %s %s  loss: %s', 227, 'TRAIN', -99828.4140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.35769593715667725\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 228, 'TRAIN', -99822.1015625)\n",
      "('epoch: %s %s  loss: %s', 229, 'TRAIN', -99709.3203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2945738136768341\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9718309640884399\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 230, 'TRAIN', -99681.296875)\n",
      "('epoch: %s %s  loss: %s', 231, 'TRAIN', -99550.8515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.18757779896259308\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9725351870059967\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 232, 'TRAIN', -99164.2265625)\n",
      "('epoch: %s %s  loss: %s', 233, 'TRAIN', -98494.140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1381240338087082\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.976056307554245\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 234, 'TRAIN', -98049.4765625)\n",
      "('epoch: %s %s  loss: %s', 235, 'TRAIN', -98109.265625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1567542850971222\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9774647533893586\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 236, 'TRAIN', -98135.015625)\n",
      "('epoch: %s %s  loss: %s', 237, 'TRAIN', -98758.40625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1829438954591751\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.977464747428894\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 238, 'TRAIN', -99330.1640625)\n",
      "('epoch: %s %s  loss: %s', 239, 'TRAIN', -99704.4765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.23087993264198303\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9760563015937805\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 240, 'TRAIN', -99819.4296875)\n",
      "('epoch: %s %s  loss: %s', 241, 'TRAIN', -100107.1640625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1577746719121933\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9823943376541138\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 242, 'TRAIN', -100135.6953125)\n",
      "('epoch: %s %s  loss: %s', 243, 'TRAIN', -100135.9375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.15900127589702606\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 244, 'TRAIN', -100123.265625)\n",
      "('epoch: %s %s  loss: %s', 245, 'TRAIN', -100128.8984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.15232695639133453\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 246, 'TRAIN', -100117.71875)\n",
      "('epoch: %s %s  loss: %s', 247, 'TRAIN', -100145.203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14423413574695587\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 248, 'TRAIN', -100127.234375)\n",
      "('epoch: %s %s  loss: %s', 249, 'TRAIN', -100139.3984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.16273240745067596\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 250, 'TRAIN', -100141.078125)\n",
      "('epoch: %s %s  loss: %s', 251, 'TRAIN', -100150.59375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.15590807795524597\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112531661987\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 252, 'TRAIN', -100148.8046875)\n",
      "('epoch: %s %s  loss: %s', 253, 'TRAIN', -100139.703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.17181213200092316\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 254, 'TRAIN', -100118.328125)\n",
      "('epoch: %s %s  loss: %s', 255, 'TRAIN', -100105.609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.17337392270565033\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 256, 'TRAIN', -100056.8984375)\n",
      "('epoch: %s %s  loss: %s', 257, 'TRAIN', -100033.703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.20177055895328522\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 258, 'TRAIN', -100018.6796875)\n",
      "('epoch: %s %s  loss: %s', 259, 'TRAIN', -99908.2109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2178909033536911\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 260, 'TRAIN', -99905.953125)\n",
      "('epoch: %s %s  loss: %s', 261, 'TRAIN', -99903.953125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1307227462530136\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 262, 'TRAIN', -99893.5703125)\n",
      "('epoch: %s %s  loss: %s', 263, 'TRAIN', -100012.5703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1182333305478096\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9510489702224731\n",
      "('epoch: %s %s  loss: %s', 264, 'TRAIN', -99778.65625)\n",
      "('epoch: %s %s  loss: %s', 265, 'TRAIN', -99861.671875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11362529546022415\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 266, 'TRAIN', -100103.84375)\n",
      "('epoch: %s %s  loss: %s', 267, 'TRAIN', -100125.7578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227880418300629\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 268, 'TRAIN', -100142.6171875)\n",
      "('epoch: %s %s  loss: %s', 269, 'TRAIN', -100133.25)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227049678564072\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 270, 'TRAIN', -100131.15625)\n",
      "('epoch: %s %s  loss: %s', 271, 'TRAIN', -100126.390625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227066814899445\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9901408195495606\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 272, 'TRAIN', -100124.8359375)\n",
      "('epoch: %s %s  loss: %s', 273, 'TRAIN', -100132.53125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11250767111778259\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9510489702224731\n",
      "('epoch: %s %s  loss: %s', 274, 'TRAIN', -100121.78125)\n",
      "('epoch: %s %s  loss: %s', 275, 'TRAIN', -100128.1015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11302606761455536\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 276, 'TRAIN', -100131.5390625)\n",
      "('epoch: %s %s  loss: %s', 277, 'TRAIN', -100112.84375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11273936182260513\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 278, 'TRAIN', -100083.0546875)\n",
      "('epoch: %s %s  loss: %s', 279, 'TRAIN', -100033.109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14465242624282837\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 280, 'TRAIN', -99967.3359375)\n",
      "('epoch: %s %s  loss: %s', 281, 'TRAIN', -99737.4140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.22470083832740784\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9823943376541138\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 282, 'TRAIN', -94281.359375)\n",
      "('epoch: %s %s  loss: %s', 283, 'TRAIN', -100121.0546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12449882179498672\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 284, 'TRAIN', -100135.171875)\n",
      "('epoch: %s %s  loss: %s', 285, 'TRAIN', -100119.9921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122724786400795\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9901408195495606\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 286, 'TRAIN', -100115.703125)\n",
      "('epoch: %s %s  loss: %s', 287, 'TRAIN', -100102.5234375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227069050073624\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 288, 'TRAIN', -100094.0703125)\n",
      "('epoch: %s %s  loss: %s', 289, 'TRAIN', -100090.546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227299273014069\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 290, 'TRAIN', -100096.1796875)\n",
      "('epoch: %s %s  loss: %s', 291, 'TRAIN', -100094.59375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227073520421982\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 292, 'TRAIN', -100096.875)\n",
      "('epoch: %s %s  loss: %s', 293, 'TRAIN', -100101.765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122707724571228\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 294, 'TRAIN', -100108.6015625)\n",
      "('epoch: %s %s  loss: %s', 295, 'TRAIN', -100092.90625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.08014007657766342\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 296, 'TRAIN', -100084.1484375)\n",
      "('epoch: %s %s  loss: %s', 297, 'TRAIN', -99989.8125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.07288839668035507\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 298, 'TRAIN', -99932.84375)\n",
      "('epoch: %s %s  loss: %s', 299, 'TRAIN', -99806.8203125)\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -99823.6171875)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -99833.234375)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -99851.9453125)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -99867.671875)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -99768.359375)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -99793.4609375)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -99816.78125)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -99842.2890625)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -99824.7109375)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -99792.2109375)\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -99798.59375)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -99784.390625)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -99809.9453125)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -99819.71875)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -99817.0625)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -99851.3828125)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -99794.375)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -99800.2734375)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -99852.53125)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -99843.3203125)\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -99821.8828125)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -99826.7421875)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -99859.7265625)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -99828.625)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -99823.8671875)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -99813.203125)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -99802.546875)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -99828.296875)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -99854.8984375)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -99825.28125)\n",
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "Best training loss: 0.04267369955778122\n",
      "Best validation loss: 0.05999360978603363\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9894366264343262\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 0.9866197109222412\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9720279574394226\n",
      "Test Accuracy (AVG): 0.7062937021255493\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9790209531784058\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -85147.6171875)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -92379.78125)\n",
      "Best training loss: 0.006212592124938965\n",
      "Best validation loss: 0.029368845745921135\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.7342657446861267\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -93260.9296875)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -91830.609375)\n",
      "Best training loss: 0.002294194884598255\n",
      "Best validation loss: 0.0422024242579937\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6573426723480225\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -89843.828125)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -88263.28125)\n",
      "Best training loss: 0.001449813018552959\n",
      "Best validation loss: 0.03148724138736725\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.8251748085021973\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.6713286638259888\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -87720.1796875)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -88012.8359375)\n",
      "Best training loss: 0.0016539425123482943\n",
      "Best validation loss: 0.03628622740507126\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.5664335489273071\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.32867133617401123\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -88790.5703125)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -89812.9453125)\n",
      "Best training loss: 0.0016792406095191836\n",
      "Best validation loss: 0.03452835604548454\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6363636255264282\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.45454543828964233\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -90991.109375)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -92086.203125)\n",
      "Best training loss: 0.001676914980635047\n",
      "Best validation loss: 0.03235539793968201\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7272727489471436\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.440559446811676\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -93092.234375)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -93977.359375)\n",
      "Best training loss: 0.0017757440218701959\n",
      "Best validation loss: 0.03960583731532097\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.5384615063667297\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -94774.203125)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -95409.8359375)\n",
      "Best training loss: 0.0015950554516166449\n",
      "Best validation loss: 0.03830025717616081\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.24475523829460144\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.2377622425556183\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -95937.25)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -96380.421875)\n",
      "Best training loss: 0.0007995793130248785\n",
      "Best validation loss: 0.03984445706009865\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.4825174808502197\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.307692289352417\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -96681.3671875)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -96849.296875)\n",
      "Best training loss: 0.0007492983713746071\n",
      "Best validation loss: 0.044703029096126556\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.2377622425556183\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.4335664212703705\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -97038.46875)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -97196.6640625)\n",
      "Best training loss: 0.00019007347873412073\n",
      "Best validation loss: 0.03808039426803589\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.6083915829658508\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.42657342553138733\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -97418.5859375)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -97650.34375)\n",
      "Best training loss: 6.753266643499956e-05\n",
      "Best validation loss: 0.04565800353884697\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9922534883022308\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.6083915829658508\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -97894.609375)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -98102.5)\n",
      "Best training loss: 1.2839267583331093e-05\n",
      "Best validation loss: 0.05688701570034027\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.6083915829658508\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.867132842540741\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -98296.203125)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -98480.7421875)\n",
      "Best training loss: 8.826735211187042e-06\n",
      "Best validation loss: 0.05199795216321945\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.6083915829658508\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.8951048851013184\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -98655.5859375)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -98805.6875)\n",
      "Best training loss: 2.0417975974851288e-05\n",
      "Best validation loss: 0.05096926540136337\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9020978808403015\n",
      "('epoch: %s %s  loss: %s', 30, 'TRAIN', -98942.6796875)\n",
      "('epoch: %s %s  loss: %s', 31, 'TRAIN', -99062.3984375)\n",
      "Best training loss: 1.242693451786181e-05\n",
      "Best validation loss: 0.030545298010110855\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9908450424671174\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 32, 'TRAIN', -99173.6640625)\n",
      "('epoch: %s %s  loss: %s', 33, 'TRAIN', -99110.6953125)\n",
      "Best training loss: 8.365708708879538e-06\n",
      "Best validation loss: 0.01697743870317936\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9908450424671174\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 34, 'TRAIN', -97514.671875)\n",
      "('epoch: %s %s  loss: %s', 35, 'TRAIN', -93474.9140625)\n",
      "Best training loss: 7.610304351146624e-07\n",
      "Best validation loss: 0.09842424094676971\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 36, 'TRAIN', -93810.359375)\n",
      "('epoch: %s %s  loss: %s', 37, 'TRAIN', -98076.7265625)\n",
      "Best training loss: 6.120188231761858e-07\n",
      "Best validation loss: 0.0605035237967968\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 38, 'TRAIN', -96337.296875)\n",
      "('epoch: %s %s  loss: %s', 39, 'TRAIN', -93016.4375)\n",
      "Best training loss: 5.1384972721280064e-06\n",
      "Best validation loss: 0.10478778183460236\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9922534883022308\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 40, 'TRAIN', -91399.9765625)\n",
      "('epoch: %s %s  loss: %s', 41, 'TRAIN', -96818.1484375)\n",
      "Best training loss: 3.7797078675794182e-06\n",
      "Best validation loss: 0.10425547510385513\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 42, 'TRAIN', -99312.4375)\n",
      "('epoch: %s %s  loss: %s', 43, 'TRAIN', -99730.9921875)\n",
      "Best training loss: 9.780462733033346e-07\n",
      "Best validation loss: 0.09979628026485443\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 44, 'TRAIN', -99797.234375)\n",
      "('epoch: %s %s  loss: %s', 45, 'TRAIN', -99832.09375)\n",
      "Best training loss: 8.378395932595595e-07\n",
      "Best validation loss: 0.10041715949773788\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 46, 'TRAIN', -99848.390625)\n",
      "('epoch: %s %s  loss: %s', 47, 'TRAIN', -99865.9375)\n",
      "Best training loss: 3.698035868637817e-07\n",
      "Best validation loss: 0.08049576729536057\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 48, 'TRAIN', -99885.84375)\n",
      "('epoch: %s %s  loss: %s', 49, 'TRAIN', -99908.0078125)\n",
      "Best training loss: 1.8825879521955358e-07\n",
      "Best validation loss: 0.12316551804542542\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 50, 'TRAIN', -99913.671875)\n",
      "('epoch: %s %s  loss: %s', 51, 'TRAIN', -99938.5)\n",
      "Best training loss: 1.7797466966840148e-07\n",
      "Best validation loss: 0.09014028310775757\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 52, 'TRAIN', -99954.5625)\n",
      "('epoch: %s %s  loss: %s', 53, 'TRAIN', -99950.0390625)\n",
      "Best training loss: 2.1827082719028112e-07\n",
      "Best validation loss: 0.07331850379705429\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 54, 'TRAIN', -99949.6875)\n",
      "('epoch: %s %s  loss: %s', 55, 'TRAIN', -99950.6640625)\n",
      "Best training loss: 4.3255761283944594e-07\n",
      "Best validation loss: 0.07914131879806519\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 56, 'TRAIN', -99920.2734375)\n",
      "('epoch: %s %s  loss: %s', 57, 'TRAIN', -99769.71875)\n",
      "Best training loss: 3.868054818667588e-07\n",
      "Best validation loss: 0.0849456936120987\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 58, 'TRAIN', -99600.6484375)\n",
      "('epoch: %s %s  loss: %s', 59, 'TRAIN', -99281.6015625)\n",
      "Best training loss: 2.1260485993934708e-07\n",
      "Best validation loss: 0.11227229982614517\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 60, 'TRAIN', -98697.75)\n",
      "('epoch: %s %s  loss: %s', 61, 'TRAIN', -98225.765625)\n",
      "Best training loss: 1.941355378676235e-07\n",
      "Best validation loss: 0.11227045208215714\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 62, 'TRAIN', -97495.1328125)\n",
      "('epoch: %s %s  loss: %s', 63, 'TRAIN', -97947.96875)\n",
      "Best training loss: 1.1962903556650417e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 64, 'TRAIN', -98339.4921875)\n",
      "('epoch: %s %s  loss: %s', 65, 'TRAIN', -98193.765625)\n",
      "Best training loss: 1.5194994773537474e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 66, 'TRAIN', -98029.8125)\n",
      "('epoch: %s %s  loss: %s', 67, 'TRAIN', -98496.171875)\n",
      "Best training loss: 1.7650560835136275e-07\n",
      "Best validation loss: 0.11227043718099594\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 68, 'TRAIN', -99778.0546875)\n",
      "('epoch: %s %s  loss: %s', 69, 'TRAIN', -99946.359375)\n",
      "Best training loss: 1.3411046495548362e-07\n",
      "Best validation loss: 0.1122705340385437\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 70, 'TRAIN', -100038.0234375)\n",
      "('epoch: %s %s  loss: %s', 71, 'TRAIN', -100025.640625)\n",
      "Best training loss: 1.200487957930818e-07\n",
      "Best validation loss: 0.11227066069841385\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9020978808403015\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 72, 'TRAIN', -100045.84375)\n",
      "('epoch: %s %s  loss: %s', 73, 'TRAIN', -100051.0703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122705340385437\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 74, 'TRAIN', -100056.0234375)\n",
      "('epoch: %s %s  loss: %s', 75, 'TRAIN', -100063.9921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227046698331833\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 76, 'TRAIN', -100080.3125)\n",
      "('epoch: %s %s  loss: %s', 77, 'TRAIN', -100070.5)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227070540189743\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 78, 'TRAIN', -100066.359375)\n",
      "('epoch: %s %s  loss: %s', 79, 'TRAIN', -100013.3515625)\n",
      "Best training loss: 1.1941916966407007e-07\n",
      "Best validation loss: 0.11227153241634369\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9090908765792847\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 80, 'TRAIN', -99878.0234375)\n",
      "('epoch: %s %s  loss: %s', 81, 'TRAIN', -99568.9765625)\n",
      "Best training loss: 1.2109816793781647e-07\n",
      "Best validation loss: 0.11227501928806305\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 82, 'TRAIN', -99168.2421875)\n",
      "('epoch: %s %s  loss: %s', 83, 'TRAIN', -98980.8671875)\n",
      "Best training loss: 1.1962903556650417e-07\n",
      "Best validation loss: 0.11227044463157654\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 84, 'TRAIN', -98502.4609375)\n",
      "('epoch: %s %s  loss: %s', 85, 'TRAIN', -98466.1015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227495223283768\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 86, 'TRAIN', -99430.9140625)\n",
      "('epoch: %s %s  loss: %s', 87, 'TRAIN', -98814.1640625)\n",
      "Best training loss: 1.263450570831992e-07\n",
      "Best validation loss: 0.11499697715044022\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 88, 'TRAIN', -99019.25)\n",
      "('epoch: %s %s  loss: %s', 89, 'TRAIN', -99823.9453125)\n",
      "Best training loss: 1.2277716621156287e-07\n",
      "Best validation loss: 0.1140463799238205\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 90, 'TRAIN', -100029.3671875)\n",
      "('epoch: %s %s  loss: %s', 91, 'TRAIN', -100059.1953125)\n",
      "Best training loss: 1.2424629858287517e-07\n",
      "Best validation loss: 0.11240960657596588\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 92, 'TRAIN', -100043.6875)\n",
      "('epoch: %s %s  loss: %s', 93, 'TRAIN', -100037.109375)\n",
      "Best training loss: 1.1941916966407007e-07\n",
      "Best validation loss: 0.11227148026227951\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 94, 'TRAIN', -100034.1875)\n",
      "('epoch: %s %s  loss: %s', 95, 'TRAIN', -100033.7421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227068305015564\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 96, 'TRAIN', -100040.5625)\n",
      "('epoch: %s %s  loss: %s', 97, 'TRAIN', -100044.515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227083951234818\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 98, 'TRAIN', -100053.90625)\n",
      "('epoch: %s %s  loss: %s', 99, 'TRAIN', -100057.7109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227049678564072\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 100, 'TRAIN', -100066.359375)\n",
      "('epoch: %s %s  loss: %s', 101, 'TRAIN', -100070.40625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227075755596161\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 102, 'TRAIN', -100068.578125)\n",
      "('epoch: %s %s  loss: %s', 103, 'TRAIN', -100069.2265625)\n",
      "Best training loss: 1.2046854180880473e-07\n",
      "Best validation loss: 0.11227080225944519\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 104, 'TRAIN', -99995.5546875)\n",
      "('epoch: %s %s  loss: %s', 105, 'TRAIN', -99921.0546875)\n",
      "Best training loss: 1.2676480309892213e-07\n",
      "Best validation loss: 0.11227047443389893\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 106, 'TRAIN', -99750.9140625)\n",
      "('epoch: %s %s  loss: %s', 107, 'TRAIN', -99474.4375)\n",
      "Best training loss: 1.320117206660143e-07\n",
      "Best validation loss: 0.1122707948088646\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 108, 'TRAIN', -99247.578125)\n",
      "('epoch: %s %s  loss: %s', 109, 'TRAIN', -99066.0234375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 110, 'TRAIN', -97525.75)\n",
      "('epoch: %s %s  loss: %s', 111, 'TRAIN', -95757.2109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227043718099594\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 112, 'TRAIN', -98311.8125)\n",
      "('epoch: %s %s  loss: %s', 113, 'TRAIN', -99234.0546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 114, 'TRAIN', -99740.390625)\n",
      "('epoch: %s %s  loss: %s', 115, 'TRAIN', -99978.6640625)\n",
      "Best training loss: 1.202586616955159e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 116, 'TRAIN', -100015.828125)\n",
      "('epoch: %s %s  loss: %s', 117, 'TRAIN', -100035.8125)\n",
      "Best training loss: 1.2991296216569026e-07\n",
      "Best validation loss: 0.1122705340385437\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 118, 'TRAIN', -100026.2421875)\n",
      "('epoch: %s %s  loss: %s', 119, 'TRAIN', -100025.5390625)\n",
      "Best training loss: 1.265549229856333e-07\n",
      "Best validation loss: 0.112270787358284\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 120, 'TRAIN', -100029.484375)\n",
      "('epoch: %s %s  loss: %s', 121, 'TRAIN', -100031.5078125)\n",
      "Best training loss: 1.2193767418011703e-07\n",
      "Best validation loss: 0.11227084696292877\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 122, 'TRAIN', -100042.4375)\n",
      "('epoch: %s %s  loss: %s', 123, 'TRAIN', -100042.1171875)\n",
      "Best training loss: 1.200487957930818e-07\n",
      "Best validation loss: 0.11227098107337952\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 124, 'TRAIN', -100048.34375)\n",
      "('epoch: %s %s  loss: %s', 125, 'TRAIN', -100054.15625)\n",
      "Best training loss: 1.213080480511053e-07\n",
      "Best validation loss: 0.11227293312549591\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 126, 'TRAIN', -100063.90625)\n",
      "('epoch: %s %s  loss: %s', 127, 'TRAIN', -100070.828125)\n",
      "Best training loss: 1.1941916966407007e-07\n",
      "Best validation loss: 0.11227203905582428\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 128, 'TRAIN', -100080.59375)\n",
      "('epoch: %s %s  loss: %s', 129, 'TRAIN', -100067.84375)\n",
      "Best training loss: 1.2424629858287517e-07\n",
      "Best validation loss: 0.11227090656757355\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 130, 'TRAIN', -100084.375)\n",
      "('epoch: %s %s  loss: %s', 131, 'TRAIN', -100000.4375)\n",
      "Best training loss: 1.278141894545115e-07\n",
      "Best validation loss: 0.11227700859308243\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 132, 'TRAIN', -99770.7109375)\n",
      "('epoch: %s %s  loss: %s', 133, 'TRAIN', -99384.1796875)\n",
      "Best training loss: 1.200487957930818e-07\n",
      "Best validation loss: 0.11228734999895096\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 134, 'TRAIN', -99238.6796875)\n",
      "('epoch: %s %s  loss: %s', 135, 'TRAIN', -99113.9140625)\n",
      "Best training loss: 1.19838915679793e-07\n",
      "Best validation loss: 0.11229771375656128\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9901408195495606\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 136, 'TRAIN', -99713.5859375)\n",
      "('epoch: %s %s  loss: %s', 137, 'TRAIN', -99148.421875)\n",
      "Best training loss: 1.1941916966407007e-07\n",
      "Best validation loss: 0.11227279156446457\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 138, 'TRAIN', -98523.453125)\n",
      "('epoch: %s %s  loss: %s', 139, 'TRAIN', -98556.5703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227254569530487\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 140, 'TRAIN', -99022.9921875)\n",
      "('epoch: %s %s  loss: %s', 141, 'TRAIN', -99498.671875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227453500032425\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 142, 'TRAIN', -99928.5)\n",
      "('epoch: %s %s  loss: %s', 143, 'TRAIN', -100024.8828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227110028266907\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 144, 'TRAIN', -100083.65625)\n",
      "('epoch: %s %s  loss: %s', 145, 'TRAIN', -100111.25)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227045953273773\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 146, 'TRAIN', -100118.0078125)\n",
      "('epoch: %s %s  loss: %s', 147, 'TRAIN', -100100.8515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227048188447952\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 148, 'TRAIN', -100121.90625)\n",
      "('epoch: %s %s  loss: %s', 149, 'TRAIN', -100120.0625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122707799077034\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 150, 'TRAIN', -100096.1015625)\n",
      "('epoch: %s %s  loss: %s', 151, 'TRAIN', -100097.0859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227098107337952\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 152, 'TRAIN', -100075.828125)\n",
      "('epoch: %s %s  loss: %s', 153, 'TRAIN', -100015.9609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227177828550339\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 154, 'TRAIN', -99974.484375)\n",
      "('epoch: %s %s  loss: %s', 155, 'TRAIN', -99941.4921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227156221866608\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 156, 'TRAIN', -99861.765625)\n",
      "('epoch: %s %s  loss: %s', 157, 'TRAIN', -99804.0859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227301508188248\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 158, 'TRAIN', -99665.125)\n",
      "('epoch: %s %s  loss: %s', 159, 'TRAIN', -99656.1328125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11229904741048813\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9908450424671174\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 160, 'TRAIN', -99606.8828125)\n",
      "('epoch: %s %s  loss: %s', 161, 'TRAIN', -99871.296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227398365736008\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 162, 'TRAIN', -99850.8046875)\n",
      "('epoch: %s %s  loss: %s', 163, 'TRAIN', -99793.3359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227494478225708\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 164, 'TRAIN', -100089.453125)\n",
      "('epoch: %s %s  loss: %s', 165, 'TRAIN', -100130.7578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227285116910934\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 166, 'TRAIN', -100113.75)\n",
      "('epoch: %s %s  loss: %s', 167, 'TRAIN', -100124.0625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11274652183055878\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 168, 'TRAIN', -100123.1875)\n",
      "('epoch: %s %s  loss: %s', 169, 'TRAIN', -100126.9921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11290771514177322\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 170, 'TRAIN', -100117.671875)\n",
      "('epoch: %s %s  loss: %s', 171, 'TRAIN', -100106.6015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11240990459918976\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 172, 'TRAIN', -100101.78125)\n",
      "('epoch: %s %s  loss: %s', 173, 'TRAIN', -100073.21875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11230310052633286\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 174, 'TRAIN', -100047.3984375)\n",
      "('epoch: %s %s  loss: %s', 175, 'TRAIN', -100038.5078125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11229633539915085\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 176, 'TRAIN', -99985.875)\n",
      "('epoch: %s %s  loss: %s', 177, 'TRAIN', -99897.4609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11233463883399963\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 178, 'TRAIN', -99831.140625)\n",
      "('epoch: %s %s  loss: %s', 179, 'TRAIN', -99718.6484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11247580498456955\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 180, 'TRAIN', -99618.4375)\n",
      "('epoch: %s %s  loss: %s', 181, 'TRAIN', -99553.8125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227433383464813\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 182, 'TRAIN', -99490.3203125)\n",
      "('epoch: %s %s  loss: %s', 183, 'TRAIN', -99384.625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227104812860489\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 184, 'TRAIN', -99452.7265625)\n",
      "('epoch: %s %s  loss: %s', 185, 'TRAIN', -99455.3984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11234947293996811\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 186, 'TRAIN', -99732.421875)\n",
      "('epoch: %s %s  loss: %s', 187, 'TRAIN', -99419.46875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.17236940562725067\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 188, 'TRAIN', -99053.5703125)\n",
      "('epoch: %s %s  loss: %s', 189, 'TRAIN', -99188.359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.194693461060524\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 190, 'TRAIN', -99702.8203125)\n",
      "('epoch: %s %s  loss: %s', 191, 'TRAIN', -99945.4765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.21771299839019775\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 192, 'TRAIN', -100028.4375)\n",
      "('epoch: %s %s  loss: %s', 193, 'TRAIN', -100056.984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.22577811777591705\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 194, 'TRAIN', -100065.859375)\n",
      "('epoch: %s %s  loss: %s', 195, 'TRAIN', -100063.78125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.22577811777591705\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 196, 'TRAIN', -100076.7890625)\n",
      "('epoch: %s %s  loss: %s', 197, 'TRAIN', -100081.78125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.17311163246631622\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 198, 'TRAIN', -100083.65625)\n",
      "('epoch: %s %s  loss: %s', 199, 'TRAIN', -100083.4453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.17453469336032867\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 200, 'TRAIN', -100079.3359375)\n",
      "('epoch: %s %s  loss: %s', 201, 'TRAIN', -100093.046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2208280861377716\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 202, 'TRAIN', -100030.7265625)\n",
      "('epoch: %s %s  loss: %s', 203, 'TRAIN', -99975.6015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1839725226163864\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 204, 'TRAIN', -99884.984375)\n",
      "('epoch: %s %s  loss: %s', 205, 'TRAIN', -99717.421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14248330891132355\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 206, 'TRAIN', -99333.0)\n",
      "('epoch: %s %s  loss: %s', 207, 'TRAIN', -99039.140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12119878828525543\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 208, 'TRAIN', -98708.1171875)\n",
      "('epoch: %s %s  loss: %s', 209, 'TRAIN', -98627.78125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11683037877082825\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 210, 'TRAIN', -97929.75)\n",
      "('epoch: %s %s  loss: %s', 211, 'TRAIN', -97766.2890625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14657318592071533\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 212, 'TRAIN', -96706.953125)\n",
      "('epoch: %s %s  loss: %s', 213, 'TRAIN', -98429.015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14157070219516754\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 214, 'TRAIN', -98860.1953125)\n",
      "('epoch: %s %s  loss: %s', 215, 'TRAIN', -99040.4296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14172187447547913\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 216, 'TRAIN', -99319.5703125)\n",
      "('epoch: %s %s  loss: %s', 217, 'TRAIN', -99565.28125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.16562123596668243\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 218, 'TRAIN', -99759.7734375)\n",
      "('epoch: %s %s  loss: %s', 219, 'TRAIN', -100007.09375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1459064781665802\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 220, 'TRAIN', -100095.859375)\n",
      "('epoch: %s %s  loss: %s', 221, 'TRAIN', -100107.2421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12666714191436768\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 222, 'TRAIN', -100101.875)\n",
      "('epoch: %s %s  loss: %s', 223, 'TRAIN', -100078.40625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11839987337589264\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 224, 'TRAIN', -100112.453125)\n",
      "('epoch: %s %s  loss: %s', 225, 'TRAIN', -100098.8046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11438057571649551\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 226, 'TRAIN', -100041.0625)\n",
      "('epoch: %s %s  loss: %s', 227, 'TRAIN', -100032.2890625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11357895284891129\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 228, 'TRAIN', -99920.015625)\n",
      "('epoch: %s %s  loss: %s', 229, 'TRAIN', -99930.4140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11610767245292664\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 230, 'TRAIN', -99832.7890625)\n",
      "('epoch: %s %s  loss: %s', 231, 'TRAIN', -99827.1953125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11283871531486511\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 232, 'TRAIN', -99875.15625)\n",
      "('epoch: %s %s  loss: %s', 233, 'TRAIN', -99771.5859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11316648125648499\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 234, 'TRAIN', -99750.1953125)\n",
      "('epoch: %s %s  loss: %s', 235, 'TRAIN', -99787.9765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.13087312877178192\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 236, 'TRAIN', -99619.3359375)\n",
      "('epoch: %s %s  loss: %s', 237, 'TRAIN', -99762.0625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1145557090640068\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 238, 'TRAIN', -99827.7578125)\n",
      "('epoch: %s %s  loss: %s', 239, 'TRAIN', -100060.2421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14769060909748077\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 240, 'TRAIN', -100077.203125)\n",
      "('epoch: %s %s  loss: %s', 241, 'TRAIN', -100089.84375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1818455159664154\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 242, 'TRAIN', -100065.5546875)\n",
      "('epoch: %s %s  loss: %s', 243, 'TRAIN', -100025.765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.15069885551929474\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 244, 'TRAIN', -99990.2265625)\n",
      "('epoch: %s %s  loss: %s', 245, 'TRAIN', -100069.734375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1366090178489685\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 246, 'TRAIN', -100041.9296875)\n",
      "('epoch: %s %s  loss: %s', 247, 'TRAIN', -100084.8203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12458900362253189\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 248, 'TRAIN', -100114.515625)\n",
      "('epoch: %s %s  loss: %s', 249, 'TRAIN', -100100.9453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12699466943740845\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 250, 'TRAIN', -100140.765625)\n",
      "('epoch: %s %s  loss: %s', 251, 'TRAIN', -100098.6796875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1165134385228157\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 252, 'TRAIN', -100103.9921875)\n",
      "('epoch: %s %s  loss: %s', 253, 'TRAIN', -100119.125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11309035122394562\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 254, 'TRAIN', -100085.234375)\n",
      "('epoch: %s %s  loss: %s', 255, 'TRAIN', -100081.9765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11245905607938766\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 256, 'TRAIN', -100056.984375)\n",
      "('epoch: %s %s  loss: %s', 257, 'TRAIN', -99976.0859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122780293226242\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9090908765792847\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 258, 'TRAIN', -99984.6953125)\n",
      "('epoch: %s %s  loss: %s', 259, 'TRAIN', -99857.4921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227227747440338\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 260, 'TRAIN', -99832.484375)\n",
      "('epoch: %s %s  loss: %s', 261, 'TRAIN', -99888.0234375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11234352737665176\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9908450424671174\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 262, 'TRAIN', -99788.8671875)\n",
      "('epoch: %s %s  loss: %s', 263, 'TRAIN', -99802.8828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11228261888027191\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 264, 'TRAIN', -99730.609375)\n",
      "('epoch: %s %s  loss: %s', 265, 'TRAIN', -100009.796875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.16597454249858856\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 266, 'TRAIN', -99764.875)\n",
      "('epoch: %s %s  loss: %s', 267, 'TRAIN', -99609.2734375)\n",
      "Best training loss: 1.1941916966407007e-07\n",
      "Best validation loss: 0.1143299788236618\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 268, 'TRAIN', -99852.9453125)\n",
      "('epoch: %s %s  loss: %s', 269, 'TRAIN', -100022.515625)\n",
      "Best training loss: 1.19838915679793e-07\n",
      "Best validation loss: 0.12884679436683655\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 270, 'TRAIN', -100024.2578125)\n",
      "('epoch: %s %s  loss: %s', 271, 'TRAIN', -100026.90625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.14891628921031952\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 272, 'TRAIN', -100022.8828125)\n",
      "('epoch: %s %s  loss: %s', 273, 'TRAIN', -100019.859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.16149987280368805\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 274, 'TRAIN', -100014.625)\n",
      "('epoch: %s %s  loss: %s', 275, 'TRAIN', -100020.84375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11377860605716705\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 276, 'TRAIN', -100028.1171875)\n",
      "('epoch: %s %s  loss: %s', 277, 'TRAIN', -100032.3125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11228467524051666\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 278, 'TRAIN', -100040.0703125)\n",
      "('epoch: %s %s  loss: %s', 279, 'TRAIN', -100046.8828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122719794511795\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9922534883022308\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 280, 'TRAIN', -100052.984375)\n",
      "('epoch: %s %s  loss: %s', 281, 'TRAIN', -100061.3203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1122901663184166\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 282, 'TRAIN', -100073.125)\n",
      "('epoch: %s %s  loss: %s', 283, 'TRAIN', -100081.5625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227074265480042\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 284, 'TRAIN', -100085.0)\n",
      "('epoch: %s %s  loss: %s', 285, 'TRAIN', -100089.578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227044463157654\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 286, 'TRAIN', -100091.0625)\n",
      "('epoch: %s %s  loss: %s', 287, 'TRAIN', -100084.328125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 288, 'TRAIN', -100081.8984375)\n",
      "('epoch: %s %s  loss: %s', 289, 'TRAIN', -99967.578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 290, 'TRAIN', -99979.3515625)\n",
      "('epoch: %s %s  loss: %s', 291, 'TRAIN', -99702.8984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 292, 'TRAIN', -99699.3359375)\n",
      "('epoch: %s %s  loss: %s', 293, 'TRAIN', -99575.8984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 294, 'TRAIN', -99433.171875)\n",
      "('epoch: %s %s  loss: %s', 295, 'TRAIN', -99813.3359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227042973041534\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 296, 'TRAIN', -100034.546875)\n",
      "('epoch: %s %s  loss: %s', 297, 'TRAIN', -100094.0234375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11227060109376907\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 298, 'TRAIN', -100118.5859375)\n",
      "('epoch: %s %s  loss: %s', 299, 'TRAIN', -100115.0)\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -100117.5078125)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -100113.640625)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -100121.5703125)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -100110.28125)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -100113.4296875)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -100116.2421875)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -100121.5703125)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -100115.703125)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -100115.3984375)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -100118.7421875)\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -100119.75)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -100118.6640625)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -100123.4921875)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -100111.9453125)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -100121.953125)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -100115.828125)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -100109.5546875)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -100119.8828125)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -100109.109375)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -100104.9453125)\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -100123.5546875)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -100116.46875)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -100122.6875)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -100123.4453125)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -100117.140625)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -100109.5234375)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -100122.8984375)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -100119.6015625)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -100118.6484375)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -100122.9296875)\n",
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "Best training loss: 0.040439195930957794\n",
      "Best validation loss: 0.05588371306657791\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9894366264343262\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 0.9866197109222412\n",
      "Best validation accuracy (AVG): 0.9852112531661987\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.8951048851013184\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9720279574394226\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -67392.21875)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -85344.421875)\n",
      "Best training loss: 0.0032820994965732098\n",
      "Best validation loss: 0.03708489611744881\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9090908765792847\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.7902097702026367\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -88433.296875)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -86530.3046875)\n",
      "Best training loss: 0.0011176328407600522\n",
      "Best validation loss: 0.034195464104413986\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.867132842540741\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3916083872318268\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -82881.703125)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -80000.1640625)\n",
      "Best training loss: 0.0006715110503137112\n",
      "Best validation loss: 0.03631894290447235\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.867132842540741\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.4755244851112366\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -79118.40625)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -79865.984375)\n",
      "Best training loss: 0.00039290552376769483\n",
      "Best validation loss: 0.042652275413274765\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.867132842540741\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.1818181872367859\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -81827.09375)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -84142.8828125)\n",
      "Best training loss: 0.00040200669900514185\n",
      "Best validation loss: 0.04317966476082802\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.21678321063518524\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.1258741319179535\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -86505.4609375)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -88714.1015625)\n",
      "Best training loss: 0.0004597200604621321\n",
      "Best validation loss: 0.04139700159430504\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9901408195495606\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.21678321063518524\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3776223659515381\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -90511.21875)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -92009.9375)\n",
      "Best training loss: 0.00048555200919508934\n",
      "Best validation loss: 0.04012196138501167\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.18881118297576904\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.14685314893722534\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -93124.8515625)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -93530.390625)\n",
      "Best training loss: 0.0006827067700214684\n",
      "Best validation loss: 0.04319288209080696\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9908450424671174\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.18881118297576904\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.1818181872367859\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -93789.9140625)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -93755.390625)\n",
      "Best training loss: 0.0009237976046279073\n",
      "Best validation loss: 0.04190719500184059\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.1538461446762085\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.28671327233314514\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -93860.8515625)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -93807.8125)\n",
      "Best training loss: 0.0007171522593125701\n",
      "Best validation loss: 0.04237987473607063\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.38461539149284363\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.1958041936159134\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -93947.3671875)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -94085.1640625)\n",
      "Best training loss: 0.0004951294977217913\n",
      "Best validation loss: 0.03397713601589203\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.32867133617401123\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.1818181872367859\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -94182.0546875)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -94190.515625)\n",
      "Best training loss: 0.00026210962096229196\n",
      "Best validation loss: 0.04182721674442291\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.1958041936159134\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.17482517659664154\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -94386.125)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -94527.53125)\n",
      "Best training loss: 8.613015961600468e-05\n",
      "Best validation loss: 0.049481604248285294\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.27272728085517883\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -94690.1015625)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -94853.984375)\n",
      "Best training loss: 3.182733053108677e-05\n",
      "Best validation loss: 0.0599108524620533\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.4825174808502197\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -95099.765625)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -95186.7421875)\n",
      "Best training loss: 1.1772315701819025e-05\n",
      "Best validation loss: 0.05586283281445503\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.5244755148887634\n",
      "('epoch: %s %s  loss: %s', 30, 'TRAIN', -95608.3671875)\n",
      "('epoch: %s %s  loss: %s', 31, 'TRAIN', -95930.8046875)\n",
      "Best training loss: 8.615308615844697e-06\n",
      "Best validation loss: 0.08103795349597931\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.983098566532135\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.6433566212654114\n",
      "('epoch: %s %s  loss: %s', 32, 'TRAIN', -96272.1796875)\n",
      "('epoch: %s %s  loss: %s', 33, 'TRAIN', -96566.359375)\n",
      "Best training loss: 1.5574833014397882e-05\n",
      "Best validation loss: 0.04457053542137146\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.6713286638259888\n",
      "('epoch: %s %s  loss: %s', 34, 'TRAIN', -96837.71875)\n",
      "('epoch: %s %s  loss: %s', 35, 'TRAIN', -97104.6953125)\n",
      "Best training loss: 1.3390721505857073e-05\n",
      "Best validation loss: 0.058999355882406235\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.6713286638259888\n",
      "('epoch: %s %s  loss: %s', 36, 'TRAIN', -97356.1328125)\n",
      "('epoch: %s %s  loss: %s', 37, 'TRAIN', -97694.0859375)\n",
      "Best training loss: 1.4325069059850648e-05\n",
      "Best validation loss: 0.06532090902328491\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9720279574394226\n",
      "Test Accuracy (AVG): 0.7272727489471436\n",
      "('epoch: %s %s  loss: %s', 38, 'TRAIN', -97962.59375)\n",
      "('epoch: %s %s  loss: %s', 39, 'TRAIN', -98206.1328125)\n",
      "Best training loss: 8.83376742422115e-06\n",
      "Best validation loss: 0.07216399908065796\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9720279574394226\n",
      "Test Accuracy (AVG): 0.6643356680870056\n",
      "('epoch: %s %s  loss: %s', 40, 'TRAIN', -98211.9921875)\n",
      "('epoch: %s %s  loss: %s', 41, 'TRAIN', -93290.515625)\n",
      "Best training loss: 8.725910447537899e-06\n",
      "Best validation loss: 0.07316094636917114\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.7552447319030762\n",
      "('epoch: %s %s  loss: %s', 42, 'TRAIN', -91136.75)\n",
      "('epoch: %s %s  loss: %s', 43, 'TRAIN', -97732.984375)\n",
      "Best training loss: 1.0640935215633363e-05\n",
      "Best validation loss: 0.0644582062959671\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.6713286638259888\n",
      "('epoch: %s %s  loss: %s', 44, 'TRAIN', -98594.40625)\n",
      "('epoch: %s %s  loss: %s', 45, 'TRAIN', -98686.9140625)\n",
      "Best training loss: 7.183803063526284e-06\n",
      "Best validation loss: 0.06528092175722122\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9753520786762238\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6433566212654114\n",
      "('epoch: %s %s  loss: %s', 46, 'TRAIN', -98774.1328125)\n",
      "('epoch: %s %s  loss: %s', 47, 'TRAIN', -98810.7265625)\n",
      "Best training loss: 3.287485014880076e-06\n",
      "Best validation loss: 0.07134156674146652\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774221420288\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6083915829658508\n",
      "('epoch: %s %s  loss: %s', 48, 'TRAIN', -98824.6953125)\n",
      "('epoch: %s %s  loss: %s', 49, 'TRAIN', -98825.78125)\n",
      "Best training loss: 8.388992682739627e-07\n",
      "Best validation loss: 0.07644537836313248\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9760563015937805\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.6223776340484619\n",
      "('epoch: %s %s  loss: %s', 50, 'TRAIN', -98864.6328125)\n",
      "('epoch: %s %s  loss: %s', 51, 'TRAIN', -98901.34375)\n",
      "Best training loss: 4.231136756516207e-07\n",
      "Best validation loss: 0.0572756752371788\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9781689763069152\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6013985872268677\n",
      "('epoch: %s %s  loss: %s', 52, 'TRAIN', -98913.40625)\n",
      "('epoch: %s %s  loss: %s', 53, 'TRAIN', -98950.1171875)\n",
      "Best training loss: 1.3144010608812096e-06\n",
      "Best validation loss: 0.0734330415725708\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.6013985872268677\n",
      "('epoch: %s %s  loss: %s', 54, 'TRAIN', -99003.3125)\n",
      "('epoch: %s %s  loss: %s', 55, 'TRAIN', -99040.3203125)\n",
      "Best training loss: 1.9190204056940274e-06\n",
      "Best validation loss: 0.08122419565916061\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.6503496170043945\n",
      "('epoch: %s %s  loss: %s', 56, 'TRAIN', -99079.078125)\n",
      "('epoch: %s %s  loss: %s', 57, 'TRAIN', -99148.0546875)\n",
      "Best training loss: 4.625029760063626e-06\n",
      "Best validation loss: 0.0659121572971344\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.748251736164093\n",
      "('epoch: %s %s  loss: %s', 58, 'TRAIN', -99203.1171875)\n",
      "('epoch: %s %s  loss: %s', 59, 'TRAIN', -99264.4609375)\n",
      "Best training loss: 2.9075847578496905e-06\n",
      "Best validation loss: 0.07615211606025696\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.8321678042411804\n",
      "('epoch: %s %s  loss: %s', 60, 'TRAIN', -99276.2578125)\n",
      "('epoch: %s %s  loss: %s', 61, 'TRAIN', -99383.21875)\n",
      "Best training loss: 2.351542661926942e-06\n",
      "Best validation loss: 0.07271862030029297\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9650349617004395\n",
      "Test Accuracy (AVG): 0.9020978808403015\n",
      "('epoch: %s %s  loss: %s', 62, 'TRAIN', -99275.9375)\n",
      "('epoch: %s %s  loss: %s', 63, 'TRAIN', -99284.2890625)\n",
      "Best training loss: 1.6238965372394887e-06\n",
      "Best validation loss: 0.06258846074342728\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774221420288\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9580419659614563\n",
      "Test Accuracy (AVG): 0.8951048851013184\n",
      "('epoch: %s %s  loss: %s', 64, 'TRAIN', -99163.8515625)\n",
      "('epoch: %s %s  loss: %s', 65, 'TRAIN', -98747.234375)\n",
      "Best training loss: 9.837162906478625e-07\n",
      "Best validation loss: 0.049310293048620224\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9774647533893586\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 66, 'TRAIN', -98342.1171875)\n",
      "('epoch: %s %s  loss: %s', 67, 'TRAIN', -97386.609375)\n",
      "Best training loss: 5.137815719535865e-07\n",
      "Best validation loss: 0.06693858653306961\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.977464759349823\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 68, 'TRAIN', -96485.390625)\n",
      "('epoch: %s %s  loss: %s', 69, 'TRAIN', -95545.4921875)\n",
      "Best training loss: 6.512588583973411e-07\n",
      "Best validation loss: 0.0681946873664856\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027834892273\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 70, 'TRAIN', -94470.4609375)\n",
      "('epoch: %s %s  loss: %s', 71, 'TRAIN', -96133.4140625)\n",
      "Best training loss: 1.114899646381673e-06\n",
      "Best validation loss: 0.06568106263875961\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 72, 'TRAIN', -97910.6484375)\n",
      "('epoch: %s %s  loss: %s', 73, 'TRAIN', -98385.5078125)\n",
      "Best training loss: 2.259895381939714e-06\n",
      "Best validation loss: 0.08490366488695145\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9845070242881775\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 74, 'TRAIN', -97158.9140625)\n",
      "('epoch: %s %s  loss: %s', 75, 'TRAIN', -99597.265625)\n",
      "Best training loss: 1.8695242260946543e-06\n",
      "Best validation loss: 0.0507897324860096\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 76, 'TRAIN', -99659.6640625)\n",
      "('epoch: %s %s  loss: %s', 77, 'TRAIN', -99624.8828125)\n",
      "Best training loss: 1.3079850305075524e-06\n",
      "Best validation loss: 0.05072423443198204\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 78, 'TRAIN', -99701.6015625)\n",
      "('epoch: %s %s  loss: %s', 79, 'TRAIN', -99660.390625)\n",
      "Best training loss: 8.491668950227904e-07\n",
      "Best validation loss: 0.04111991822719574\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 80, 'TRAIN', -99711.5078125)\n",
      "('epoch: %s %s  loss: %s', 81, 'TRAIN', -99719.1015625)\n",
      "Best training loss: 9.791011734705535e-07\n",
      "Best validation loss: 0.04733988270163536\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 82, 'TRAIN', -99723.046875)\n",
      "('epoch: %s %s  loss: %s', 83, 'TRAIN', -99743.4921875)\n",
      "Best training loss: 7.389857046291581e-07\n",
      "Best validation loss: 0.046219877898693085\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 84, 'TRAIN', -99751.265625)\n",
      "('epoch: %s %s  loss: %s', 85, 'TRAIN', -99781.6875)\n",
      "Best training loss: 8.617772095931286e-07\n",
      "Best validation loss: 0.06237056851387024\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 86, 'TRAIN', -99787.640625)\n",
      "('epoch: %s %s  loss: %s', 87, 'TRAIN', -99813.4453125)\n",
      "Best training loss: 6.117977591202362e-07\n",
      "Best validation loss: 0.046112626791000366\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 88, 'TRAIN', -99797.296875)\n",
      "('epoch: %s %s  loss: %s', 89, 'TRAIN', -99737.6015625)\n",
      "Best training loss: 4.6676538545398216e-07\n",
      "Best validation loss: 0.04212651029229164\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 90, 'TRAIN', -99661.234375)\n",
      "('epoch: %s %s  loss: %s', 91, 'TRAIN', -99525.125)\n",
      "Best training loss: 1.6769061517152295e-07\n",
      "Best validation loss: 0.045962855219841\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9859154701232911\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 92, 'TRAIN', -99334.40625)\n",
      "('epoch: %s %s  loss: %s', 93, 'TRAIN', -98994.5234375)\n",
      "Best training loss: 1.7398700435933279e-07\n",
      "Best validation loss: 0.04477387294173241\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901028156281\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 94, 'TRAIN', -98540.2578125)\n",
      "('epoch: %s %s  loss: %s', 95, 'TRAIN', -98186.8671875)\n",
      "Best training loss: 1.8636966103713348e-07\n",
      "Best validation loss: 0.06466257572174072\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 96, 'TRAIN', -96124.359375)\n",
      "('epoch: %s %s  loss: %s', 97, 'TRAIN', -97296.921875)\n",
      "Best training loss: 4.489298532917019e-07\n",
      "Best validation loss: 0.08589787036180496\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 98, 'TRAIN', -97195.953125)\n",
      "('epoch: %s %s  loss: %s', 99, 'TRAIN', -97042.9140625)\n",
      "Best training loss: 3.263573091771832e-07\n",
      "Best validation loss: 0.06883766502141953\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 100, 'TRAIN', -96515.6875)\n",
      "('epoch: %s %s  loss: %s', 101, 'TRAIN', -96270.1875)\n",
      "Best training loss: 4.4158369405522535e-07\n",
      "Best validation loss: 0.08494579046964645\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 102, 'TRAIN', -96507.234375)\n",
      "('epoch: %s %s  loss: %s', 103, 'TRAIN', -96672.0078125)\n",
      "Best training loss: 2.304441579781269e-07\n",
      "Best validation loss: 0.09141796827316284\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 104, 'TRAIN', -96946.46875)\n",
      "('epoch: %s %s  loss: %s', 105, 'TRAIN', -97765.671875)\n",
      "Best training loss: 1.6265360613942903e-07\n",
      "Best validation loss: 0.09436999261379242\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 106, 'TRAIN', -98060.4375)\n",
      "('epoch: %s %s  loss: %s', 107, 'TRAIN', -98369.9765625)\n",
      "Best training loss: 1.3264133258417132e-07\n",
      "Best validation loss: 0.09865081310272217\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 108, 'TRAIN', -99374.1953125)\n",
      "('epoch: %s %s  loss: %s', 109, 'TRAIN', -99183.671875)\n",
      "Best training loss: 1.6769072885836067e-07\n",
      "Best validation loss: 0.051464393734931946\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 110, 'TRAIN', -97484.2890625)\n",
      "('epoch: %s %s  loss: %s', 111, 'TRAIN', -95068.421875)\n",
      "Best training loss: 1.3893760808514344e-07\n",
      "Best validation loss: 0.05803254619240761\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112472057343\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 112, 'TRAIN', -98981.6015625)\n",
      "('epoch: %s %s  loss: %s', 113, 'TRAIN', -99371.3671875)\n",
      "Best training loss: 1.3620923766666237e-07\n",
      "Best validation loss: 0.08094472438097\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 114, 'TRAIN', -99308.7734375)\n",
      "('epoch: %s %s  loss: %s', 115, 'TRAIN', -99572.0859375)\n",
      "Best training loss: 1.4166599271447922e-07\n",
      "Best validation loss: 0.07124170660972595\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 116, 'TRAIN', -99696.8671875)\n",
      "('epoch: %s %s  loss: %s', 117, 'TRAIN', -99803.4921875)\n",
      "Best training loss: 1.60554947115088e-07\n",
      "Best validation loss: 0.081687793135643\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9859154760837555\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 118, 'TRAIN', -99677.5546875)\n",
      "('epoch: %s %s  loss: %s', 119, 'TRAIN', -99590.640625)\n",
      "Best training loss: 1.248759247118869e-07\n",
      "Best validation loss: 0.0721760019659996\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9859154701232911\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 120, 'TRAIN', -99445.0625)\n",
      "('epoch: %s %s  loss: %s', 121, 'TRAIN', -99410.1328125)\n",
      "Best training loss: 1.3557959732679592e-07\n",
      "Best validation loss: 0.08377677947282791\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.984507018327713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 122, 'TRAIN', -98826.34375)\n",
      "('epoch: %s %s  loss: %s', 123, 'TRAIN', -98797.171875)\n",
      "Best training loss: 1.380981302645523e-07\n",
      "Best validation loss: 0.05560116097331047\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 124, 'TRAIN', -99723.4921875)\n",
      "('epoch: %s %s  loss: %s', 125, 'TRAIN', -99556.0859375)\n",
      "Best training loss: 1.263450570831992e-07\n",
      "Best validation loss: 0.059961359947919846\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 126, 'TRAIN', -99541.640625)\n",
      "('epoch: %s %s  loss: %s', 127, 'TRAIN', -98370.546875)\n",
      "Best training loss: 1.977031161004561e-07\n",
      "Best validation loss: 0.027122296392917633\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 128, 'TRAIN', -96993.890625)\n",
      "('epoch: %s %s  loss: %s', 129, 'TRAIN', -98323.9765625)\n",
      "Best training loss: 2.604561473162903e-07\n",
      "Best validation loss: 0.062055815011262894\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.991549265384674\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 130, 'TRAIN', -98750.7109375)\n",
      "('epoch: %s %s  loss: %s', 131, 'TRAIN', -99262.46875)\n",
      "Best training loss: 2.8858261202913127e-07\n",
      "Best validation loss: 0.05366108939051628\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 132, 'TRAIN', -99399.3828125)\n",
      "('epoch: %s %s  loss: %s', 133, 'TRAIN', -99399.375)\n",
      "Best training loss: 2.138643253601913e-07\n",
      "Best validation loss: 0.04344901815056801\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 134, 'TRAIN', -99257.1015625)\n",
      "('epoch: %s %s  loss: %s', 135, 'TRAIN', -99504.984375)\n",
      "Best training loss: 1.534191369501059e-07\n",
      "Best validation loss: 0.041247427463531494\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 136, 'TRAIN', -99347.09375)\n",
      "('epoch: %s %s  loss: %s', 137, 'TRAIN', -99251.171875)\n",
      "Best training loss: 1.307524399862814e-07\n",
      "Best validation loss: 0.07415063679218292\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 138, 'TRAIN', -99283.015625)\n",
      "('epoch: %s %s  loss: %s', 139, 'TRAIN', -98923.046875)\n",
      "Best training loss: 1.5488821247799933e-07\n",
      "Best validation loss: 0.07783239334821701\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 140, 'TRAIN', -99145.25)\n",
      "('epoch: %s %s  loss: %s', 141, 'TRAIN', -98913.125)\n",
      "Best training loss: 1.2529567072760983e-07\n",
      "Best validation loss: 0.0883546844124794\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9838027954101562\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 142, 'TRAIN', -98363.9921875)\n",
      "('epoch: %s %s  loss: %s', 143, 'TRAIN', -97955.84375)\n",
      "Best training loss: 1.3432033085791772e-07\n",
      "Best validation loss: 0.12326212227344513\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 144, 'TRAIN', -97772.71875)\n",
      "('epoch: %s %s  loss: %s', 145, 'TRAIN', -96717.28125)\n",
      "Best training loss: 1.3515983710021828e-07\n",
      "Best validation loss: 0.13307058811187744\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 146, 'TRAIN', -96614.8203125)\n",
      "('epoch: %s %s  loss: %s', 147, 'TRAIN', -96618.390625)\n",
      "Best training loss: 1.3432034506877244e-07\n",
      "Best validation loss: 0.13344882428646088\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 148, 'TRAIN', -96333.203125)\n",
      "('epoch: %s %s  loss: %s', 149, 'TRAIN', -96114.9140625)\n",
      "Best training loss: 1.3201170645515958e-07\n",
      "Best validation loss: 0.11416184902191162\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 150, 'TRAIN', -97423.4921875)\n",
      "('epoch: %s %s  loss: %s', 151, 'TRAIN', -99176.6484375)\n",
      "Best training loss: 1.580363999664769e-07\n",
      "Best validation loss: 0.10337932407855988\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 152, 'TRAIN', -99175.8828125)\n",
      "('epoch: %s %s  loss: %s', 153, 'TRAIN', -98548.375)\n",
      "Best training loss: 3.179638952133246e-07\n",
      "Best validation loss: 0.08779772371053696\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 154, 'TRAIN', -98780.625)\n",
      "('epoch: %s %s  loss: %s', 155, 'TRAIN', -99187.71875)\n",
      "Best training loss: 3.5196362091483024e-07\n",
      "Best validation loss: 0.05316237360239029\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 156, 'TRAIN', -99712.28125)\n",
      "('epoch: %s %s  loss: %s', 157, 'TRAIN', -99879.4921875)\n",
      "Best training loss: 2.0546855239444994e-07\n",
      "Best validation loss: 0.02442762814462185\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 158, 'TRAIN', -99805.46875)\n",
      "('epoch: %s %s  loss: %s', 159, 'TRAIN', -99827.421875)\n",
      "Best training loss: 1.4544376369940437e-07\n",
      "Best validation loss: 0.028774989768862724\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 160, 'TRAIN', -99767.6015625)\n",
      "('epoch: %s %s  loss: %s', 161, 'TRAIN', -99785.9921875)\n",
      "Best training loss: 1.309623200995702e-07\n",
      "Best validation loss: 0.02910800278186798\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 162, 'TRAIN', -99825.5625)\n",
      "('epoch: %s %s  loss: %s', 163, 'TRAIN', -99769.140625)\n",
      "Best training loss: 2.069379263502924e-07\n",
      "Best validation loss: 0.042520347982645035\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 164, 'TRAIN', -99824.59375)\n",
      "('epoch: %s %s  loss: %s', 165, 'TRAIN', -99795.65625)\n",
      "Best training loss: 1.8804870194344403e-07\n",
      "Best validation loss: 0.03652559220790863\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 166, 'TRAIN', -99830.7734375)\n",
      "('epoch: %s %s  loss: %s', 167, 'TRAIN', -99783.5078125)\n",
      "Best training loss: 2.2687645184760186e-07\n",
      "Best validation loss: 0.06597048789262772\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 168, 'TRAIN', -99870.40625)\n",
      "('epoch: %s %s  loss: %s', 169, 'TRAIN', -99893.6171875)\n",
      "Best training loss: 2.816540813910251e-07\n",
      "Best validation loss: 0.08683089166879654\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 170, 'TRAIN', -99869.140625)\n",
      "('epoch: %s %s  loss: %s', 171, 'TRAIN', -99839.203125)\n",
      "Best training loss: 3.490249298465642e-07\n",
      "Best validation loss: 0.07779522985219955\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 172, 'TRAIN', -99833.9765625)\n",
      "('epoch: %s %s  loss: %s', 173, 'TRAIN', -99665.1484375)\n",
      "Best training loss: 4.879680659541918e-07\n",
      "Best validation loss: 0.09529206156730652\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 174, 'TRAIN', -99728.9296875)\n",
      "('epoch: %s %s  loss: %s', 175, 'TRAIN', -99263.1953125)\n",
      "Best training loss: 4.019155142032105e-07\n",
      "Best validation loss: 0.13333381712436676\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 176, 'TRAIN', -99357.5390625)\n",
      "('epoch: %s %s  loss: %s', 177, 'TRAIN', -99716.1015625)\n",
      "Best training loss: 1.3411046495548362e-07\n",
      "Best validation loss: 0.1618044227361679\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 178, 'TRAIN', -99731.7734375)\n",
      "('epoch: %s %s  loss: %s', 179, 'TRAIN', -99835.5703125)\n",
      "Best training loss: 1.2214754008255113e-07\n",
      "Best validation loss: 0.13803119957447052\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 180, 'TRAIN', -99913.3203125)\n",
      "('epoch: %s %s  loss: %s', 181, 'TRAIN', -100031.953125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.08526865392923355\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9845070242881775\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 182, 'TRAIN', -99996.1953125)\n",
      "('epoch: %s %s  loss: %s', 183, 'TRAIN', -100015.3515625)\n",
      "Best training loss: 1.1962903556650417e-07\n",
      "Best validation loss: 0.026058243587613106\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112531661987\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 184, 'TRAIN', -100014.7734375)\n",
      "('epoch: %s %s  loss: %s', 185, 'TRAIN', -100017.3984375)\n",
      "Best training loss: 1.217277940668282e-07\n",
      "Best validation loss: 0.014397120103240013\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9852112472057343\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9440559148788452\n",
      "('epoch: %s %s  loss: %s', 186, 'TRAIN', -99997.9375)\n",
      "('epoch: %s %s  loss: %s', 187, 'TRAIN', -100031.71875)\n",
      "Best training loss: 1.380981160536976e-07\n",
      "Best validation loss: 0.020527681335806847\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.983098566532135\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 188, 'TRAIN', -100009.28125)\n",
      "('epoch: %s %s  loss: %s', 189, 'TRAIN', -99986.5625)\n",
      "Best training loss: 1.3453022518206126e-07\n",
      "Best validation loss: 0.06557758152484894\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9823943376541138\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 190, 'TRAIN', -100000.359375)\n",
      "('epoch: %s %s  loss: %s', 191, 'TRAIN', -99801.2265625)\n",
      "Best training loss: 1.2823393547023443e-07\n",
      "Best validation loss: 0.07451638579368591\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 192, 'TRAIN', -99803.1171875)\n",
      "('epoch: %s %s  loss: %s', 193, 'TRAIN', -99563.3671875)\n",
      "Best training loss: 1.2193767418011703e-07\n",
      "Best validation loss: 0.10387060791254044\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.983098566532135\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 194, 'TRAIN', -99221.921875)\n",
      "('epoch: %s %s  loss: %s', 195, 'TRAIN', -98573.078125)\n",
      "Best training loss: 1.2046854180880473e-07\n",
      "Best validation loss: 0.10095818340778351\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 196, 'TRAIN', -97936.8828125)\n",
      "('epoch: %s %s  loss: %s', 197, 'TRAIN', -96859.4140625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.0987691581249237\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9788731932640076\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 198, 'TRAIN', -95738.0703125)\n",
      "('epoch: %s %s  loss: %s', 199, 'TRAIN', -86759.1484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1055421382188797\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 200, 'TRAIN', -93887.046875)\n",
      "('epoch: %s %s  loss: %s', 201, 'TRAIN', -82466.1484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.08785229921340942\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 202, 'TRAIN', -94592.0078125)\n",
      "('epoch: %s %s  loss: %s', 203, 'TRAIN', -96412.9453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.07362186908721924\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9510489702224731\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 204, 'TRAIN', -97328.0390625)\n",
      "('epoch: %s %s  loss: %s', 205, 'TRAIN', -98066.5625)\n",
      "Best training loss: 1.19838915679793e-07\n",
      "Best validation loss: 0.013022000901401043\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 206, 'TRAIN', -98807.234375)\n",
      "('epoch: %s %s  loss: %s', 207, 'TRAIN', -99130.0859375)\n",
      "Best training loss: 1.2046854180880473e-07\n",
      "Best validation loss: 0.01643337309360504\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 208, 'TRAIN', -99490.453125)\n",
      "('epoch: %s %s  loss: %s', 209, 'TRAIN', -99626.5)\n",
      "Best training loss: 1.5404876307911763e-07\n",
      "Best validation loss: 0.020463287830352783\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 210, 'TRAIN', -99738.7890625)\n",
      "('epoch: %s %s  loss: %s', 211, 'TRAIN', -99756.53125)\n",
      "Best training loss: 2.0043144388637302e-07\n",
      "Best validation loss: 0.04382216930389404\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 212, 'TRAIN', -99755.9921875)\n",
      "('epoch: %s %s  loss: %s', 213, 'TRAIN', -99834.53125)\n",
      "Best training loss: 3.0348275004143943e-07\n",
      "Best validation loss: 0.020510787144303322\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866196990013123\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 214, 'TRAIN', -99825.046875)\n",
      "('epoch: %s %s  loss: %s', 215, 'TRAIN', -99848.2734375)\n",
      "Best training loss: 4.915342515232624e-07\n",
      "Best validation loss: 0.020429376512765884\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 216, 'TRAIN', -99868.078125)\n",
      "('epoch: %s %s  loss: %s', 217, 'TRAIN', -99891.3984375)\n",
      "Best training loss: 8.193675284928759e-07\n",
      "Best validation loss: 0.026523103937506676\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 218, 'TRAIN', -99889.09375)\n",
      "('epoch: %s %s  loss: %s', 219, 'TRAIN', -99865.796875)\n",
      "Best training loss: 8.903062393983419e-07\n",
      "Best validation loss: 0.030733825638890266\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 220, 'TRAIN', -99879.5390625)\n",
      "('epoch: %s %s  loss: %s', 221, 'TRAIN', -99785.640625)\n",
      "Best training loss: 1.0575911346677458e-06\n",
      "Best validation loss: 0.04980415105819702\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 222, 'TRAIN', -99752.171875)\n",
      "('epoch: %s %s  loss: %s', 223, 'TRAIN', -99556.0078125)\n",
      "Best training loss: 6.592266004190606e-07\n",
      "Best validation loss: 0.06802017241716385\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9845070242881775\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 224, 'TRAIN', -99466.8671875)\n",
      "('epoch: %s %s  loss: %s', 225, 'TRAIN', -98914.515625)\n",
      "Best training loss: 5.100076805319986e-07\n",
      "Best validation loss: 0.07307186722755432\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9823943376541138\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 226, 'TRAIN', -98753.109375)\n",
      "('epoch: %s %s  loss: %s', 227, 'TRAIN', -98336.484375)\n",
      "Best training loss: 1.6181409989712847e-07\n",
      "Best validation loss: 0.0729886069893837\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.3636363744735718\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 228, 'TRAIN', -98276.359375)\n",
      "('epoch: %s %s  loss: %s', 229, 'TRAIN', -95726.1953125)\n",
      "Best training loss: 2.3233256740695651e-07\n",
      "Best validation loss: 0.07100237905979156\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 230, 'TRAIN', -81623.96875)\n",
      "('epoch: %s %s  loss: %s', 231, 'TRAIN', -88543.765625)\n",
      "Best training loss: 2.585673826160928e-07\n",
      "Best validation loss: 0.11232125014066696\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 232, 'TRAIN', -88141.671875)\n",
      "('epoch: %s %s  loss: %s', 233, 'TRAIN', -89272.8984375)\n",
      "Best training loss: 3.0620978463957726e-07\n",
      "Best validation loss: 0.09381874650716782\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 234, 'TRAIN', -90868.859375)\n",
      "('epoch: %s %s  loss: %s', 235, 'TRAIN', -94983.1875)\n",
      "Best training loss: 2.787163566608797e-07\n",
      "Best validation loss: 0.11265967041254044\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 236, 'TRAIN', -96849.96875)\n",
      "('epoch: %s %s  loss: %s', 237, 'TRAIN', -98431.875)\n",
      "Best training loss: 2.793453006688651e-07\n",
      "Best validation loss: 0.11234692484140396\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 238, 'TRAIN', -98636.515625)\n",
      "('epoch: %s %s  loss: %s', 239, 'TRAIN', -99121.5390625)\n",
      "Best training loss: 1.9119687522106688e-07\n",
      "Best validation loss: 0.1124202311038971\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9929577112197876\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 240, 'TRAIN', -99382.8359375)\n",
      "('epoch: %s %s  loss: %s', 241, 'TRAIN', -99574.6796875)\n",
      "Best training loss: 1.2907344171253499e-07\n",
      "Best validation loss: 0.11333663016557693\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 242, 'TRAIN', -99718.8203125)\n",
      "('epoch: %s %s  loss: %s', 243, 'TRAIN', -99703.4921875)\n",
      "Best training loss: 1.217277940668282e-07\n",
      "Best validation loss: 0.11511322855949402\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 244, 'TRAIN', -99801.828125)\n",
      "('epoch: %s %s  loss: %s', 245, 'TRAIN', -99867.5390625)\n",
      "Best training loss: 1.2109816793781647e-07\n",
      "Best validation loss: 0.11475208401679993\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.984507018327713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 246, 'TRAIN', -99773.71875)\n",
      "('epoch: %s %s  loss: %s', 247, 'TRAIN', -99651.5546875)\n",
      "Best training loss: 1.366289836823853e-07\n",
      "Best validation loss: 0.14852222800254822\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9816901087760925\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 248, 'TRAIN', -99640.7421875)\n",
      "('epoch: %s %s  loss: %s', 249, 'TRAIN', -99514.9921875)\n",
      "Best training loss: 1.756660026330792e-07\n",
      "Best validation loss: 0.16765649616718292\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 250, 'TRAIN', -99371.875)\n",
      "('epoch: %s %s  loss: %s', 251, 'TRAIN', -99252.9140625)\n",
      "Best training loss: 2.3191314824089204e-07\n",
      "Best validation loss: 0.13108250498771667\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9809858798980713\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 252, 'TRAIN', -99184.0546875)\n",
      "('epoch: %s %s  loss: %s', 253, 'TRAIN', -99100.0859375)\n",
      "Best training loss: 1.5719683688075747e-07\n",
      "Best validation loss: 0.16868211328983307\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9795774221420288\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 254, 'TRAIN', -98843.5234375)\n",
      "('epoch: %s %s  loss: %s', 255, 'TRAIN', -98495.5234375)\n",
      "Best training loss: 1.307524399862814e-07\n",
      "Best validation loss: 0.16622215509414673\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98028165102005\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 256, 'TRAIN', -98090.2890625)\n",
      "('epoch: %s %s  loss: %s', 257, 'TRAIN', -96994.7421875)\n",
      "Best training loss: 1.3411047916633834e-07\n",
      "Best validation loss: 0.22729332745075226\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9767605304718018\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 258, 'TRAIN', -96991.671875)\n",
      "('epoch: %s %s  loss: %s', 259, 'TRAIN', -95187.390625)\n",
      "Best training loss: 1.807030116651731e-07\n",
      "Best validation loss: 0.209341898560524\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9788731932640076\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9732394099235535\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 260, 'TRAIN', -93194.28125)\n",
      "('epoch: %s %s  loss: %s', 261, 'TRAIN', -99692.375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11453695595264435\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 262, 'TRAIN', -99729.984375)\n",
      "('epoch: %s %s  loss: %s', 263, 'TRAIN', -99907.9140625)\n",
      "Best training loss: 1.234067923405746e-07\n",
      "Best validation loss: 0.114202119410038\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 264, 'TRAIN', -99894.2890625)\n",
      "('epoch: %s %s  loss: %s', 265, 'TRAIN', -99897.1640625)\n",
      "Best training loss: 1.2550555084089865e-07\n",
      "Best validation loss: 0.11507697403430939\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 266, 'TRAIN', -99869.6640625)\n",
      "('epoch: %s %s  loss: %s', 267, 'TRAIN', -99821.2734375)\n",
      "Best training loss: 1.2697468321221095e-07\n",
      "Best validation loss: 0.08947540074586868\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9090908765792847\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 268, 'TRAIN', -99903.171875)\n",
      "('epoch: %s %s  loss: %s', 269, 'TRAIN', -99883.9921875)\n",
      "Best training loss: 1.2508580482517573e-07\n",
      "Best validation loss: 0.07587011158466339\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9020978808403015\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 270, 'TRAIN', -99847.140625)\n",
      "('epoch: %s %s  loss: %s', 271, 'TRAIN', -99848.9140625)\n",
      "Best training loss: 1.246660445985981e-07\n",
      "Best validation loss: 0.08233311772346497\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.988732373714447\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9020978808403015\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 272, 'TRAIN', -99754.0859375)\n",
      "('epoch: %s %s  loss: %s', 273, 'TRAIN', -99779.8125)\n",
      "Best training loss: 1.280240553569456e-07\n",
      "Best validation loss: 0.113090381026268\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9894365966320038\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9090908765792847\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 274, 'TRAIN', -99675.296875)\n",
      "('epoch: %s %s  loss: %s', 275, 'TRAIN', -99568.59375)\n",
      "Best training loss: 1.200487957930818e-07\n",
      "Best validation loss: 0.11318548023700714\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 276, 'TRAIN', -99606.0078125)\n",
      "('epoch: %s %s  loss: %s', 277, 'TRAIN', -99482.921875)\n",
      "Best training loss: 1.234067923405746e-07\n",
      "Best validation loss: 0.11275877058506012\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9090908765792847\n",
      "('epoch: %s %s  loss: %s', 278, 'TRAIN', -99045.171875)\n",
      "('epoch: %s %s  loss: %s', 279, 'TRAIN', -98843.6328125)\n",
      "Best training loss: 1.1962903556650417e-07\n",
      "Best validation loss: 0.11580196022987366\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9090908765792847\n",
      "('epoch: %s %s  loss: %s', 280, 'TRAIN', -99277.7421875)\n",
      "('epoch: %s %s  loss: %s', 281, 'TRAIN', -98934.8984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.12275878340005875\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "('epoch: %s %s  loss: %s', 282, 'TRAIN', -98809.1953125)\n",
      "('epoch: %s %s  loss: %s', 283, 'TRAIN', -98458.046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11287401616573334\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 284, 'TRAIN', -98163.78125)\n",
      "('epoch: %s %s  loss: %s', 285, 'TRAIN', -97706.6796875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11229251325130463\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866196990013123\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 286, 'TRAIN', -97838.8984375)\n",
      "('epoch: %s %s  loss: %s', 287, 'TRAIN', -97835.078125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11250432580709457\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 288, 'TRAIN', -98957.3515625)\n",
      "('epoch: %s %s  loss: %s', 289, 'TRAIN', -97837.21875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11800040304660797\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 290, 'TRAIN', -96026.8828125)\n",
      "('epoch: %s %s  loss: %s', 291, 'TRAIN', -94091.0)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.13246560096740723\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.98591548204422\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.98591548204422\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 292, 'TRAIN', -91448.359375)\n",
      "('epoch: %s %s  loss: %s', 293, 'TRAIN', -89644.0390625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1147165447473526\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9880281507968902\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9300699234008789\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 294, 'TRAIN', -87549.4609375)\n",
      "('epoch: %s %s  loss: %s', 295, 'TRAIN', -90338.2578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11355207860469818\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9873239278793335\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9370629191398621\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 296, 'TRAIN', -95610.7109375)\n",
      "('epoch: %s %s  loss: %s', 297, 'TRAIN', -97852.375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.11531711369752884\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 1.0\n",
      "Best validation accuracy: 0.9929577112197876\n",
      "Best training accuracy (AVG): 1.0\n",
      "Best validation accuracy (AVG): 0.9866197049617768\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 298, 'TRAIN', -99081.2109375)\n",
      "('epoch: %s %s  loss: %s', 299, 'TRAIN', -99591.6015625)\n",
      "WITH VAL\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9440559148788452\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -99567.953125)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -99469.9453125)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -99628.7734375)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -99620.7890625)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -99515.765625)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -99585.796875)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -99616.3125)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -99675.546875)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -99552.2421875)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -99606.3359375)\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -99455.9765625)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -99480.1796875)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -99669.78125)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -99502.9765625)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -99689.140625)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -99541.703125)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -99589.328125)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -99543.90625)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -99650.1640625)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -99665.7578125)\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -99665.265625)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -99517.6875)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -99591.4296875)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -99725.03125)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -99565.953125)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -99701.3984375)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -99590.9921875)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -99662.8359375)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -99713.28125)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -99506.328125)\n"
     ]
    }
   ],
   "source": [
    "funnel_config.trainer.epochs = 300\n",
    "tl_lists = []\n",
    "vl_lists = []\n",
    "ta_lists = []\n",
    "va_lists = []\n",
    "out_dicts1 = []\n",
    "task = \"breastcancer\"\n",
    "for div in [1, 0.5, 0.2]:\n",
    "    funnel_config = set_task(funnel_config, task, div, c)\n",
    "    funnel_config.model.input_dim = 171\n",
    "    out_dict = train_dds(funnel_config)\n",
    "    out_dicts1.append(out_dict)\n",
    "    tl_lists.append([x.item() for x in out_dict[-1][\"training_loss\"]])\n",
    "    vl_lists.append([x.item() for x in out_dict[-1][\"validation_loss\"]])\n",
    "    ta_lists.append([x.item() for x in out_dict[-1][\"training_acc\"]])\n",
    "    va_lists.append([x.item() for x in out_dict[-1][\"validation_acc\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T11:46:17.923740Z",
     "end_time": "2023-05-13T17:56:02.820262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x14e12a0b0>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Combine the lists\n",
    "labels = [\"5\", \"3\", \"2\"]#, \"10\", \"15\", \"20\"]\n",
    "colors = [\"blue\", \"orange\", \"green\"]#, \"red\", \"purple\", \"yellow\"]\n",
    "d_list = [np.array(out_dicts1[0][-1][\"elbo\"])+100000, np.array(out_dicts1[1][-1][\"elbo\"])+100000, np.array(out_dicts1[2][-1][\"elbo\"])+100000]\n",
    "# Plot the data\n",
    "for i, (acc, label, color) in enumerate(zip(d_list, labels, colors)):\n",
    "    plt.plot(acc, label=label, color=color)\n",
    "\n",
    "# Add a horizontal line at y = -1\n",
    "#plt.axhline(y=-0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Add labels and legend\n",
    "#plt.yscale('log')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Breast cancer ELBO loss\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T12:09:23.220055Z",
     "end_time": "2023-05-14T12:09:23.437058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "Best training loss: 0.0006845255265943706\n",
      "Best validation loss: 0.13864555954933167\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9161971688270569\n",
      "Best validation accuracy (AVG): 0.9387323677539825\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -40090.0)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -61546.546875)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -69375.1015625)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -70965.3125)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -70437.1171875)\n",
      "Best training loss: 1.0629554481056402e-06\n",
      "Best validation loss: 0.13857713341712952\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9330985724925995\n",
      "Best validation accuracy (AVG): 0.9507042109966278\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -69791.8984375)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -67196.9921875)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -60505.6953125)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -53466.22265625)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -47899.578125)\n",
      "Best training loss: 2.5580348506082373e-07\n",
      "Best validation loss: 0.12909619510173798\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9288732349872589\n",
      "Best validation accuracy (AVG): 0.9507042169570923\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -46837.515625)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -49550.6171875)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -52732.625)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -55117.3046875)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -55747.5078125)\n",
      "Best training loss: 2.4363562260987237e-06\n",
      "Best validation loss: 0.12432125210762024\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9323943555355072\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -54023.5859375)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -47879.71484375)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -41204.53125)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -35843.2734375)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -32793.0703125)\n",
      "Best training loss: 7.470874606951838e-06\n",
      "Best validation loss: 0.1194121390581131\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9274647772312165\n",
      "Best validation accuracy (AVG): 0.9528168857097625\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -30409.810546875)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -28531.3671875)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -26469.28125)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -22744.236328125)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -20471.58203125)\n",
      "Best training loss: 5.146116563992109e-06\n",
      "Best validation loss: 0.22039835155010223\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.923591536283493\n",
      "Best validation accuracy (AVG): 0.9598591268062592\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -18004.068359375)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -17249.4765625)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -16537.103515625)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -16844.45703125)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -17458.80078125)\n",
      "Best training loss: 3.5564869449444814e-06\n",
      "Best validation loss: 0.2102309912443161\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9274647653102874\n",
      "Best validation accuracy (AVG): 0.9591549038887024\n",
      "('epoch: %s %s  loss: %s', 30, 'TRAIN', -17440.580078125)\n",
      "('epoch: %s %s  loss: %s', 31, 'TRAIN', -18393.37109375)\n",
      "('epoch: %s %s  loss: %s', 32, 'TRAIN', -18841.28125)\n",
      "('epoch: %s %s  loss: %s', 33, 'TRAIN', -18804.021484375)\n",
      "('epoch: %s %s  loss: %s', 34, 'TRAIN', -19156.4609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.19852152466773987\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9288732290267945\n",
      "Best validation accuracy (AVG): 0.9570422410964966\n",
      "('epoch: %s %s  loss: %s', 35, 'TRAIN', -19533.9609375)\n",
      "('epoch: %s %s  loss: %s', 36, 'TRAIN', -19403.1875)\n",
      "('epoch: %s %s  loss: %s', 37, 'TRAIN', -20444.76171875)\n",
      "('epoch: %s %s  loss: %s', 38, 'TRAIN', -20549.98046875)\n",
      "('epoch: %s %s  loss: %s', 39, 'TRAIN', -20807.26171875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.21661128103733063\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9292253494262696\n",
      "Best validation accuracy (AVG): 0.9499999701976776\n",
      "('epoch: %s %s  loss: %s', 40, 'TRAIN', -21150.53515625)\n",
      "('epoch: %s %s  loss: %s', 41, 'TRAIN', -21450.203125)\n",
      "('epoch: %s %s  loss: %s', 42, 'TRAIN', -22180.931640625)\n",
      "('epoch: %s %s  loss: %s', 43, 'TRAIN', -21586.5859375)\n",
      "('epoch: %s %s  loss: %s', 44, 'TRAIN', -21417.037109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1949891895055771\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9313380241394043\n",
      "Best validation accuracy (AVG): 0.9471830666065216\n",
      "('epoch: %s %s  loss: %s', 45, 'TRAIN', -20642.177734375)\n",
      "('epoch: %s %s  loss: %s', 46, 'TRAIN', -19069.70703125)\n",
      "('epoch: %s %s  loss: %s', 47, 'TRAIN', -16506.154296875)\n",
      "('epoch: %s %s  loss: %s', 48, 'TRAIN', -14380.3251953125)\n",
      "('epoch: %s %s  loss: %s', 49, 'TRAIN', -12724.232421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7266305088996887\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9366196990013123\n",
      "Best training accuracy (AVG): 0.9140844941139221\n",
      "Best validation accuracy (AVG): 0.9366196990013123\n",
      "('epoch: %s %s  loss: %s', 50, 'TRAIN', -11556.216796875)\n",
      "('epoch: %s %s  loss: %s', 51, 'TRAIN', -8627.7734375)\n",
      "('epoch: %s %s  loss: %s', 52, 'TRAIN', -3629.832763671875)\n",
      "('epoch: %s %s  loss: %s', 53, 'TRAIN', -4798.96630859375)\n",
      "('epoch: %s %s  loss: %s', 54, 'TRAIN', -8667.4228515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0141628980636597\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9366196990013123\n",
      "Best training accuracy (AVG): 0.9158450663089752\n",
      "Best validation accuracy (AVG): 0.934507030248642\n",
      "('epoch: %s %s  loss: %s', 55, 'TRAIN', -11320.6083984375)\n",
      "('epoch: %s %s  loss: %s', 56, 'TRAIN', -13032.42578125)\n",
      "('epoch: %s %s  loss: %s', 57, 'TRAIN', -14436.9169921875)\n",
      "('epoch: %s %s  loss: %s', 58, 'TRAIN', -15948.888671875)\n",
      "('epoch: %s %s  loss: %s', 59, 'TRAIN', -16871.009765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7575571537017822\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9327464580535889\n",
      "Best validation accuracy (AVG): 0.9436619281768799\n",
      "('epoch: %s %s  loss: %s', 60, 'TRAIN', -17449.26953125)\n",
      "('epoch: %s %s  loss: %s', 61, 'TRAIN', -17062.33203125)\n",
      "('epoch: %s %s  loss: %s', 62, 'TRAIN', -17011.15625)\n",
      "('epoch: %s %s  loss: %s', 63, 'TRAIN', -16991.234375)\n",
      "('epoch: %s %s  loss: %s', 64, 'TRAIN', -17402.81640625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.3617551028728485\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.9408450603485108\n",
      "Best validation accuracy (AVG): 0.9605633556842804\n",
      "('epoch: %s %s  loss: %s', 65, 'TRAIN', -17602.201171875)\n",
      "('epoch: %s %s  loss: %s', 66, 'TRAIN', -18756.130859375)\n",
      "('epoch: %s %s  loss: %s', 67, 'TRAIN', -19111.736328125)\n",
      "('epoch: %s %s  loss: %s', 68, 'TRAIN', -19568.9921875)\n",
      "('epoch: %s %s  loss: %s', 69, 'TRAIN', -20264.59765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2810761332511902\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.9390844941139221\n",
      "Best validation accuracy (AVG): 0.9654929518699646\n",
      "('epoch: %s %s  loss: %s', 70, 'TRAIN', -21231.005859375)\n",
      "('epoch: %s %s  loss: %s', 71, 'TRAIN', -21657.16015625)\n",
      "('epoch: %s %s  loss: %s', 72, 'TRAIN', -21674.455078125)\n",
      "('epoch: %s %s  loss: %s', 73, 'TRAIN', -22881.267578125)\n",
      "('epoch: %s %s  loss: %s', 74, 'TRAIN', -23020.36328125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.24446554481983185\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.9383802711963654\n",
      "Best validation accuracy (AVG): 0.9661971807479859\n",
      "('epoch: %s %s  loss: %s', 75, 'TRAIN', -22826.98828125)\n",
      "('epoch: %s %s  loss: %s', 76, 'TRAIN', -23946.666015625)\n",
      "('epoch: %s %s  loss: %s', 77, 'TRAIN', -23653.96875)\n",
      "('epoch: %s %s  loss: %s', 78, 'TRAIN', -24570.15625)\n",
      "('epoch: %s %s  loss: %s', 79, 'TRAIN', -24580.537109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.20908313989639282\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.9387323796749115\n",
      "Best validation accuracy (AVG): 0.9669014036655426\n",
      "('epoch: %s %s  loss: %s', 80, 'TRAIN', -24824.0703125)\n",
      "('epoch: %s %s  loss: %s', 81, 'TRAIN', -25044.296875)\n",
      "('epoch: %s %s  loss: %s', 82, 'TRAIN', -24180.501953125)\n",
      "('epoch: %s %s  loss: %s', 83, 'TRAIN', -24621.13671875)\n",
      "('epoch: %s %s  loss: %s', 84, 'TRAIN', -24386.521484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.22436945140361786\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.9401408314704895\n",
      "Best validation accuracy (AVG): 0.9661971807479859\n",
      "('epoch: %s %s  loss: %s', 85, 'TRAIN', -23527.306640625)\n",
      "('epoch: %s %s  loss: %s', 86, 'TRAIN', -23708.224609375)\n",
      "('epoch: %s %s  loss: %s', 87, 'TRAIN', -23818.962890625)\n",
      "('epoch: %s %s  loss: %s', 88, 'TRAIN', -23542.46484375)\n",
      "('epoch: %s %s  loss: %s', 89, 'TRAIN', -23136.83203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2962530553340912\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.935915470123291\n",
      "Best validation accuracy (AVG): 0.9654929578304291\n",
      "('epoch: %s %s  loss: %s', 90, 'TRAIN', -22933.58203125)\n",
      "('epoch: %s %s  loss: %s', 91, 'TRAIN', -22769.298828125)\n",
      "('epoch: %s %s  loss: %s', 92, 'TRAIN', -22796.732421875)\n",
      "('epoch: %s %s  loss: %s', 93, 'TRAIN', -22468.78125)\n",
      "('epoch: %s %s  loss: %s', 94, 'TRAIN', -21717.357421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.37098151445388794\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9355633556842804\n",
      "Best validation accuracy (AVG): 0.9598591327667236\n",
      "('epoch: %s %s  loss: %s', 95, 'TRAIN', -21334.361328125)\n",
      "('epoch: %s %s  loss: %s', 96, 'TRAIN', -20778.1328125)\n",
      "('epoch: %s %s  loss: %s', 97, 'TRAIN', -20265.60546875)\n",
      "('epoch: %s %s  loss: %s', 98, 'TRAIN', -19875.673828125)\n",
      "('epoch: %s %s  loss: %s', 99, 'TRAIN', -19820.2734375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.37942755222320557\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9334506690502167\n",
      "Best validation accuracy (AVG): 0.9542253315448761\n",
      "('epoch: %s %s  loss: %s', 100, 'TRAIN', -19826.388671875)\n",
      "('epoch: %s %s  loss: %s', 101, 'TRAIN', -19186.580078125)\n",
      "('epoch: %s %s  loss: %s', 102, 'TRAIN', -18980.72265625)\n",
      "('epoch: %s %s  loss: %s', 103, 'TRAIN', -18924.22265625)\n",
      "('epoch: %s %s  loss: %s', 104, 'TRAIN', -18834.876953125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.39689913392066956\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9306338012218476\n",
      "Best validation accuracy (AVG): 0.9528168857097625\n",
      "('epoch: %s %s  loss: %s', 105, 'TRAIN', -18854.548828125)\n",
      "('epoch: %s %s  loss: %s', 106, 'TRAIN', -18437.314453125)\n",
      "('epoch: %s %s  loss: %s', 107, 'TRAIN', -18351.39453125)\n",
      "('epoch: %s %s  loss: %s', 108, 'TRAIN', -18057.42578125)\n",
      "('epoch: %s %s  loss: %s', 109, 'TRAIN', -18153.177734375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5962136387825012\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9295774579048157\n",
      "Best validation accuracy (AVG): 0.9464788377285004\n",
      "('epoch: %s %s  loss: %s', 110, 'TRAIN', -17874.61328125)\n",
      "('epoch: %s %s  loss: %s', 111, 'TRAIN', -17912.533203125)\n",
      "('epoch: %s %s  loss: %s', 112, 'TRAIN', -18008.583984375)\n",
      "('epoch: %s %s  loss: %s', 113, 'TRAIN', -17810.2890625)\n",
      "('epoch: %s %s  loss: %s', 114, 'TRAIN', -17778.6484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7459284663200378\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9292253494262696\n",
      "Best validation accuracy (AVG): 0.9436619281768799\n",
      "('epoch: %s %s  loss: %s', 115, 'TRAIN', -17671.03515625)\n",
      "('epoch: %s %s  loss: %s', 116, 'TRAIN', -17690.716796875)\n",
      "('epoch: %s %s  loss: %s', 117, 'TRAIN', -17709.587890625)\n",
      "('epoch: %s %s  loss: %s', 118, 'TRAIN', -17486.494140625)\n",
      "('epoch: %s %s  loss: %s', 119, 'TRAIN', -17014.30859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7737340331077576\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9239436388015747\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 120, 'TRAIN', -17152.736328125)\n",
      "('epoch: %s %s  loss: %s', 121, 'TRAIN', -17017.82421875)\n",
      "('epoch: %s %s  loss: %s', 122, 'TRAIN', -16852.576171875)\n",
      "('epoch: %s %s  loss: %s', 123, 'TRAIN', -17038.154296875)\n",
      "('epoch: %s %s  loss: %s', 124, 'TRAIN', -16794.1640625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7599946856498718\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9260563254356384\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9214788615703583\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 125, 'TRAIN', -16897.033203125)\n",
      "('epoch: %s %s  loss: %s', 126, 'TRAIN', -16858.61328125)\n",
      "('epoch: %s %s  loss: %s', 127, 'TRAIN', -16916.19921875)\n",
      "('epoch: %s %s  loss: %s', 128, 'TRAIN', -16965.861328125)\n",
      "('epoch: %s %s  loss: %s', 129, 'TRAIN', -16953.21484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7725659608840942\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9204225301742553\n",
      "Best validation accuracy (AVG): 0.9429577052593231\n",
      "('epoch: %s %s  loss: %s', 130, 'TRAIN', -16855.9453125)\n",
      "('epoch: %s %s  loss: %s', 131, 'TRAIN', -16999.494140625)\n",
      "('epoch: %s %s  loss: %s', 132, 'TRAIN', -17495.4375)\n",
      "('epoch: %s %s  loss: %s', 133, 'TRAIN', -17215.63671875)\n",
      "('epoch: %s %s  loss: %s', 134, 'TRAIN', -17281.794921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7739689350128174\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9211267590522766\n",
      "Best validation accuracy (AVG): 0.9429577052593231\n",
      "('epoch: %s %s  loss: %s', 135, 'TRAIN', -17669.388671875)\n",
      "('epoch: %s %s  loss: %s', 136, 'TRAIN', -17344.240234375)\n",
      "('epoch: %s %s  loss: %s', 137, 'TRAIN', -17681.962890625)\n",
      "('epoch: %s %s  loss: %s', 138, 'TRAIN', -17323.8203125)\n",
      "('epoch: %s %s  loss: %s', 139, 'TRAIN', -17510.248046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7317861914634705\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9232394218444824\n",
      "Best validation accuracy (AVG): 0.9436619281768799\n",
      "('epoch: %s %s  loss: %s', 140, 'TRAIN', -17495.28125)\n",
      "('epoch: %s %s  loss: %s', 141, 'TRAIN', -17891.59765625)\n",
      "('epoch: %s %s  loss: %s', 142, 'TRAIN', -17771.19921875)\n",
      "('epoch: %s %s  loss: %s', 143, 'TRAIN', -17744.583984375)\n",
      "('epoch: %s %s  loss: %s', 144, 'TRAIN', -17601.25)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7131844758987427\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9239436447620392\n",
      "Best validation accuracy (AVG): 0.9436619281768799\n",
      "('epoch: %s %s  loss: %s', 145, 'TRAIN', -17834.38671875)\n",
      "('epoch: %s %s  loss: %s', 146, 'TRAIN', -18135.126953125)\n",
      "('epoch: %s %s  loss: %s', 147, 'TRAIN', -17972.513671875)\n",
      "('epoch: %s %s  loss: %s', 148, 'TRAIN', -17961.060546875)\n",
      "('epoch: %s %s  loss: %s', 149, 'TRAIN', -17861.521484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7459314465522766\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.926408439874649\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 150, 'TRAIN', -17669.681640625)\n",
      "('epoch: %s %s  loss: %s', 151, 'TRAIN', -17411.865234375)\n",
      "('epoch: %s %s  loss: %s', 152, 'TRAIN', -17777.00390625)\n",
      "('epoch: %s %s  loss: %s', 153, 'TRAIN', -17648.8984375)\n",
      "('epoch: %s %s  loss: %s', 154, 'TRAIN', -17589.353515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7523654103279114\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9292253494262696\n",
      "Best validation accuracy (AVG): 0.9436619281768799\n",
      "('epoch: %s %s  loss: %s', 155, 'TRAIN', -17404.056640625)\n",
      "('epoch: %s %s  loss: %s', 156, 'TRAIN', -17423.416015625)\n",
      "('epoch: %s %s  loss: %s', 157, 'TRAIN', -17641.1015625)\n",
      "('epoch: %s %s  loss: %s', 158, 'TRAIN', -17217.46875)\n",
      "('epoch: %s %s  loss: %s', 159, 'TRAIN', -17420.95703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7475177049636841\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.930633795261383\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 160, 'TRAIN', -17330.748046875)\n",
      "('epoch: %s %s  loss: %s', 161, 'TRAIN', -17251.12109375)\n",
      "('epoch: %s %s  loss: %s', 162, 'TRAIN', -17181.59765625)\n",
      "('epoch: %s %s  loss: %s', 163, 'TRAIN', -17075.671875)\n",
      "('epoch: %s %s  loss: %s', 164, 'TRAIN', -16887.740234375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6989958882331848\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9313380181789398\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 165, 'TRAIN', -17036.97265625)\n",
      "('epoch: %s %s  loss: %s', 166, 'TRAIN', -17066.0)\n",
      "('epoch: %s %s  loss: %s', 167, 'TRAIN', -16815.623046875)\n",
      "('epoch: %s %s  loss: %s', 168, 'TRAIN', -17127.302734375)\n",
      "('epoch: %s %s  loss: %s', 169, 'TRAIN', -17241.412109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6654903292655945\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9309859097003936\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 170, 'TRAIN', -17092.236328125)\n",
      "('epoch: %s %s  loss: %s', 171, 'TRAIN', -16982.267578125)\n",
      "('epoch: %s %s  loss: %s', 172, 'TRAIN', -17257.388671875)\n",
      "('epoch: %s %s  loss: %s', 173, 'TRAIN', -17110.521484375)\n",
      "('epoch: %s %s  loss: %s', 174, 'TRAIN', -17098.2109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6460186839103699\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9292253494262696\n",
      "Best validation accuracy (AVG): 0.9457746148109436\n",
      "('epoch: %s %s  loss: %s', 175, 'TRAIN', -17121.888671875)\n",
      "('epoch: %s %s  loss: %s', 176, 'TRAIN', -17191.701171875)\n",
      "('epoch: %s %s  loss: %s', 177, 'TRAIN', -17334.375)\n",
      "('epoch: %s %s  loss: %s', 178, 'TRAIN', -17404.49609375)\n",
      "('epoch: %s %s  loss: %s', 179, 'TRAIN', -17142.85546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6224948167800903\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9306338012218476\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 180, 'TRAIN', -17348.09375)\n",
      "('epoch: %s %s  loss: %s', 181, 'TRAIN', -16796.767578125)\n",
      "('epoch: %s %s  loss: %s', 182, 'TRAIN', -17091.6484375)\n",
      "('epoch: %s %s  loss: %s', 183, 'TRAIN', -17205.9375)\n",
      "('epoch: %s %s  loss: %s', 184, 'TRAIN', -16989.73046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6224148869514465\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9316901326179504\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 185, 'TRAIN', -16991.150390625)\n",
      "('epoch: %s %s  loss: %s', 186, 'TRAIN', -17199.6328125)\n",
      "('epoch: %s %s  loss: %s', 187, 'TRAIN', -16896.388671875)\n",
      "('epoch: %s %s  loss: %s', 188, 'TRAIN', -16689.302734375)\n",
      "('epoch: %s %s  loss: %s', 189, 'TRAIN', -17024.388671875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.682628870010376\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9316901326179504\n",
      "Best validation accuracy (AVG): 0.9464788377285004\n",
      "('epoch: %s %s  loss: %s', 190, 'TRAIN', -17188.4609375)\n",
      "('epoch: %s %s  loss: %s', 191, 'TRAIN', -16873.73046875)\n",
      "('epoch: %s %s  loss: %s', 192, 'TRAIN', -16955.09375)\n",
      "('epoch: %s %s  loss: %s', 193, 'TRAIN', -16825.9375)\n",
      "('epoch: %s %s  loss: %s', 194, 'TRAIN', -16623.93359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6819155812263489\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9316901385784149\n",
      "Best validation accuracy (AVG): 0.9464788377285004\n",
      "('epoch: %s %s  loss: %s', 195, 'TRAIN', -16747.431640625)\n",
      "('epoch: %s %s  loss: %s', 196, 'TRAIN', -16881.724609375)\n",
      "('epoch: %s %s  loss: %s', 197, 'TRAIN', -16718.06640625)\n",
      "('epoch: %s %s  loss: %s', 198, 'TRAIN', -16791.671875)\n",
      "('epoch: %s %s  loss: %s', 199, 'TRAIN', -16589.943359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.681193470954895\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9320422530174255\n",
      "Best validation accuracy (AVG): 0.9457746088504791\n",
      "('epoch: %s %s  loss: %s', 200, 'TRAIN', -16801.23828125)\n",
      "('epoch: %s %s  loss: %s', 201, 'TRAIN', -16746.83203125)\n",
      "('epoch: %s %s  loss: %s', 202, 'TRAIN', -16711.271484375)\n",
      "('epoch: %s %s  loss: %s', 203, 'TRAIN', -16575.833984375)\n",
      "('epoch: %s %s  loss: %s', 204, 'TRAIN', -16713.8203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6716309189796448\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9316901385784149\n",
      "Best validation accuracy (AVG): 0.9464788377285004\n",
      "('epoch: %s %s  loss: %s', 205, 'TRAIN', -16471.24609375)\n",
      "('epoch: %s %s  loss: %s', 206, 'TRAIN', -16594.19140625)\n",
      "('epoch: %s %s  loss: %s', 207, 'TRAIN', -16521.333984375)\n",
      "('epoch: %s %s  loss: %s', 208, 'TRAIN', -16654.654296875)\n",
      "('epoch: %s %s  loss: %s', 209, 'TRAIN', -16578.31640625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6557937264442444\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.930281686782837\n",
      "Best validation accuracy (AVG): 0.9464788377285004\n",
      "('epoch: %s %s  loss: %s', 210, 'TRAIN', -16525.58984375)\n",
      "('epoch: %s %s  loss: %s', 211, 'TRAIN', -16635.529296875)\n",
      "('epoch: %s %s  loss: %s', 212, 'TRAIN', -16290.22265625)\n",
      "('epoch: %s %s  loss: %s', 213, 'TRAIN', -16061.8505859375)\n",
      "('epoch: %s %s  loss: %s', 214, 'TRAIN', -16462.529296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6447482705116272\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9313380241394043\n",
      "Best validation accuracy (AVG): 0.9457746088504791\n",
      "('epoch: %s %s  loss: %s', 215, 'TRAIN', -16191.5048828125)\n",
      "('epoch: %s %s  loss: %s', 216, 'TRAIN', -16558.720703125)\n",
      "('epoch: %s %s  loss: %s', 217, 'TRAIN', -16697.572265625)\n",
      "('epoch: %s %s  loss: %s', 218, 'TRAIN', -16648.85546875)\n",
      "('epoch: %s %s  loss: %s', 219, 'TRAIN', -16453.15625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6211150288581848\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9327464699745178\n",
      "Best validation accuracy (AVG): 0.9457746088504791\n",
      "('epoch: %s %s  loss: %s', 220, 'TRAIN', -16468.396484375)\n",
      "('epoch: %s %s  loss: %s', 221, 'TRAIN', -16377.4609375)\n",
      "('epoch: %s %s  loss: %s', 222, 'TRAIN', -16475.70703125)\n",
      "('epoch: %s %s  loss: %s', 223, 'TRAIN', -16641.740234375)\n",
      "('epoch: %s %s  loss: %s', 224, 'TRAIN', -16519.80859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.612683117389679\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.933098578453064\n",
      "Best validation accuracy (AVG): 0.9457746088504791\n",
      "('epoch: %s %s  loss: %s', 225, 'TRAIN', -16426.201171875)\n",
      "('epoch: %s %s  loss: %s', 226, 'TRAIN', -16095.8818359375)\n",
      "('epoch: %s %s  loss: %s', 227, 'TRAIN', -16354.5185546875)\n",
      "('epoch: %s %s  loss: %s', 228, 'TRAIN', -16506.82421875)\n",
      "('epoch: %s %s  loss: %s', 229, 'TRAIN', -16527.39453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6022693514823914\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9327464699745178\n",
      "Best validation accuracy (AVG): 0.9464788377285004\n",
      "('epoch: %s %s  loss: %s', 230, 'TRAIN', -16710.62109375)\n",
      "('epoch: %s %s  loss: %s', 231, 'TRAIN', -16629.404296875)\n",
      "('epoch: %s %s  loss: %s', 232, 'TRAIN', -16424.650390625)\n",
      "('epoch: %s %s  loss: %s', 233, 'TRAIN', -16275.314453125)\n",
      "('epoch: %s %s  loss: %s', 234, 'TRAIN', -16128.1669921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6828551888465881\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9323943614959717\n",
      "Best validation accuracy (AVG): 0.9450703799724579\n",
      "('epoch: %s %s  loss: %s', 235, 'TRAIN', -16271.8994140625)\n",
      "('epoch: %s %s  loss: %s', 236, 'TRAIN', -16346.72265625)\n",
      "('epoch: %s %s  loss: %s', 237, 'TRAIN', -16107.1025390625)\n",
      "('epoch: %s %s  loss: %s', 238, 'TRAIN', -16444.09375)\n",
      "('epoch: %s %s  loss: %s', 239, 'TRAIN', -15994.326171875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7116445302963257\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9313380241394043\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 240, 'TRAIN', -16175.9150390625)\n",
      "('epoch: %s %s  loss: %s', 241, 'TRAIN', -15810.1708984375)\n",
      "('epoch: %s %s  loss: %s', 242, 'TRAIN', -15808.708984375)\n",
      "('epoch: %s %s  loss: %s', 243, 'TRAIN', -15916.0849609375)\n",
      "('epoch: %s %s  loss: %s', 244, 'TRAIN', -15789.626953125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7016585469245911\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9436619281768799\n",
      "Best training accuracy (AVG): 0.9288732349872589\n",
      "Best validation accuracy (AVG): 0.9436619281768799\n",
      "('epoch: %s %s  loss: %s', 245, 'TRAIN', -15490.7890625)\n",
      "('epoch: %s %s  loss: %s', 246, 'TRAIN', -15633.822265625)\n",
      "('epoch: %s %s  loss: %s', 247, 'TRAIN', -15501.2509765625)\n",
      "('epoch: %s %s  loss: %s', 248, 'TRAIN', -15554.451171875)\n",
      "('epoch: %s %s  loss: %s', 249, 'TRAIN', -15406.548828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6886971592903137\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9288732349872589\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 250, 'TRAIN', -15186.8828125)\n",
      "('epoch: %s %s  loss: %s', 251, 'TRAIN', -15261.1708984375)\n",
      "('epoch: %s %s  loss: %s', 252, 'TRAIN', -15137.09765625)\n",
      "('epoch: %s %s  loss: %s', 253, 'TRAIN', -15161.9931640625)\n",
      "('epoch: %s %s  loss: %s', 254, 'TRAIN', -15248.4404296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6858706474304199\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9278168916702271\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 255, 'TRAIN', -15304.6845703125)\n",
      "('epoch: %s %s  loss: %s', 256, 'TRAIN', -15243.9453125)\n",
      "('epoch: %s %s  loss: %s', 257, 'TRAIN', -15093.6142578125)\n",
      "('epoch: %s %s  loss: %s', 258, 'TRAIN', -15128.1708984375)\n",
      "('epoch: %s %s  loss: %s', 259, 'TRAIN', -15151.80859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6849110126495361\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9278168916702271\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 260, 'TRAIN', -15223.5888671875)\n",
      "('epoch: %s %s  loss: %s', 261, 'TRAIN', -15118.3203125)\n",
      "('epoch: %s %s  loss: %s', 262, 'TRAIN', -15137.783203125)\n",
      "('epoch: %s %s  loss: %s', 263, 'TRAIN', -15216.2509765625)\n",
      "('epoch: %s %s  loss: %s', 264, 'TRAIN', -15473.4892578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6839084625244141\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9278168916702271\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 265, 'TRAIN', -15469.5234375)\n",
      "('epoch: %s %s  loss: %s', 266, 'TRAIN', -15423.8916015625)\n",
      "('epoch: %s %s  loss: %s', 267, 'TRAIN', -15446.8486328125)\n",
      "('epoch: %s %s  loss: %s', 268, 'TRAIN', -15527.7060546875)\n",
      "('epoch: %s %s  loss: %s', 269, 'TRAIN', -15628.72265625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6867230534553528\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9281690061092377\n",
      "Best validation accuracy (AVG): 0.9450703799724579\n",
      "('epoch: %s %s  loss: %s', 270, 'TRAIN', -15715.9140625)\n",
      "('epoch: %s %s  loss: %s', 271, 'TRAIN', -15358.0947265625)\n",
      "('epoch: %s %s  loss: %s', 272, 'TRAIN', -15385.7802734375)\n",
      "('epoch: %s %s  loss: %s', 273, 'TRAIN', -15241.408203125)\n",
      "('epoch: %s %s  loss: %s', 274, 'TRAIN', -15781.7509765625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.6958770751953125\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9281690061092377\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 275, 'TRAIN', -15509.09375)\n",
      "('epoch: %s %s  loss: %s', 276, 'TRAIN', -15589.443359375)\n",
      "('epoch: %s %s  loss: %s', 277, 'TRAIN', -15866.623046875)\n",
      "('epoch: %s %s  loss: %s', 278, 'TRAIN', -15566.4443359375)\n",
      "('epoch: %s %s  loss: %s', 279, 'TRAIN', -15682.3486328125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7097165584564209\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9292253494262696\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 280, 'TRAIN', -15519.134765625)\n",
      "('epoch: %s %s  loss: %s', 281, 'TRAIN', -15306.7548828125)\n",
      "('epoch: %s %s  loss: %s', 282, 'TRAIN', -15088.072265625)\n",
      "('epoch: %s %s  loss: %s', 283, 'TRAIN', -15277.9453125)\n",
      "('epoch: %s %s  loss: %s', 284, 'TRAIN', -15437.0302734375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7269049882888794\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9285211205482483\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 285, 'TRAIN', -15202.6826171875)\n",
      "('epoch: %s %s  loss: %s', 286, 'TRAIN', -15040.7353515625)\n",
      "('epoch: %s %s  loss: %s', 287, 'TRAIN', -15163.70703125)\n",
      "('epoch: %s %s  loss: %s', 288, 'TRAIN', -15301.77734375)\n",
      "('epoch: %s %s  loss: %s', 289, 'TRAIN', -15221.6904296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7233282923698425\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9285211205482483\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 290, 'TRAIN', -15341.13671875)\n",
      "('epoch: %s %s  loss: %s', 291, 'TRAIN', -15230.87109375)\n",
      "('epoch: %s %s  loss: %s', 292, 'TRAIN', -15047.626953125)\n",
      "('epoch: %s %s  loss: %s', 293, 'TRAIN', -15086.5703125)\n",
      "('epoch: %s %s  loss: %s', 294, 'TRAIN', -15027.466796875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.718723714351654\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9281690061092377\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 295, 'TRAIN', -15065.9169921875)\n",
      "('epoch: %s %s  loss: %s', 296, 'TRAIN', -15128.5986328125)\n",
      "('epoch: %s %s  loss: %s', 297, 'TRAIN', -15261.9208984375)\n",
      "('epoch: %s %s  loss: %s', 298, 'TRAIN', -15261.4814453125)\n",
      "('epoch: %s %s  loss: %s', 299, 'TRAIN', -15284.9521484375)\n",
      "WITH VAL\n",
      "Test Accuracy: 0.8461538553237915\n",
      "Test Accuracy (AVG): 0.8531468510627747\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9300699234008789\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -15075.05859375)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -15123.73046875)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -15267.8974609375)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -15493.4228515625)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -15246.6904296875)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -14992.724609375)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -15147.3837890625)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -15254.7685546875)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -15189.947265625)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -15127.3173828125)\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -15293.0908203125)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -15269.78515625)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -15410.8203125)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -15205.9921875)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -15292.7294921875)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -15140.1494140625)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -15133.1181640625)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -15153.5947265625)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -15365.8330078125)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -15367.9990234375)\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -15177.9384765625)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -15241.314453125)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -15214.04296875)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -15151.654296875)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -15470.92578125)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -15171.986328125)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -15200.6328125)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -14976.4541015625)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -15072.8056640625)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -15211.55859375)\n",
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "Best training loss: 0.0005923219723626971\n",
      "Best validation loss: 0.14271387457847595\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9144366085529327\n",
      "Best validation accuracy (AVG): 0.9387323737144471\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -21411.115234375)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -41167.39453125)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -51002.1640625)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -52900.31640625)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -51599.2890625)\n",
      "Best training loss: 1.7235861378139816e-06\n",
      "Best validation loss: 0.14428240060806274\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9323943555355072\n",
      "Best validation accuracy (AVG): 0.9556337833404541\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -49439.05078125)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -44753.80859375)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -34201.546875)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -26668.306640625)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -23731.845703125)\n",
      "Best training loss: 1.5894573834884795e-07\n",
      "Best validation loss: 0.1228586733341217\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.931690126657486\n",
      "Best validation accuracy (AVG): 0.9542253375053406\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -25002.193359375)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -29373.818359375)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -32466.671875)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -33992.52734375)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -32716.58203125)\n",
      "Best training loss: 2.7021128516935278e-06\n",
      "Best validation loss: 0.10589618235826492\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9436619281768799\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9355633556842804\n",
      "Best validation accuracy (AVG): 0.9549295604228973\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -29049.146484375)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -19923.853515625)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -11793.4033203125)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -4977.6552734375)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -1793.955810546875)\n",
      "Best training loss: 2.451266482239589e-06\n",
      "Best validation loss: 0.11247315257787704\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9260563254356384\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.923591536283493\n",
      "Best validation accuracy (AVG): 0.9478872954845429\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -347.34051513671875)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', 363.63232421875)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', 650.8734130859375)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', 1418.4617919921875)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', 2164.20263671875)\n",
      "Best training loss: 4.933983655064367e-05\n",
      "Best validation loss: 0.22969317436218262\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9190140783786773\n",
      "Best validation accuracy (AVG): 0.9521126627922059\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', 2881.61865234375)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', 2485.80712890625)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', 1404.320068359375)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', 101.94956970214844)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -844.2619018554688)\n",
      "Best training loss: 4.6690428234796855e-07\n",
      "Best validation loss: 0.19150038063526154\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9306337893009186\n",
      "Best validation accuracy (AVG): 0.9612675905227661\n",
      "('epoch: %s %s  loss: %s', 30, 'TRAIN', -1780.6221923828125)\n",
      "('epoch: %s %s  loss: %s', 31, 'TRAIN', -2998.251220703125)\n",
      "('epoch: %s %s  loss: %s', 32, 'TRAIN', -3134.24658203125)\n",
      "('epoch: %s %s  loss: %s', 33, 'TRAIN', -2926.12109375)\n",
      "('epoch: %s %s  loss: %s', 34, 'TRAIN', -2955.862060546875)\n",
      "Best training loss: 6.159169743114035e-07\n",
      "Best validation loss: 0.1979132890701294\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9292253434658051\n",
      "Best validation accuracy (AVG): 0.9612675905227661\n",
      "('epoch: %s %s  loss: %s', 35, 'TRAIN', -3300.16259765625)\n",
      "('epoch: %s %s  loss: %s', 36, 'TRAIN', -3492.529296875)\n",
      "('epoch: %s %s  loss: %s', 37, 'TRAIN', -3559.351806640625)\n",
      "('epoch: %s %s  loss: %s', 38, 'TRAIN', -3324.7041015625)\n",
      "('epoch: %s %s  loss: %s', 39, 'TRAIN', -3533.82861328125)\n",
      "Best training loss: 1.2914340175029793e-07\n",
      "Best validation loss: 0.15126383304595947\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9299295723438263\n",
      "Best validation accuracy (AVG): 0.9633802771568298\n",
      "('epoch: %s %s  loss: %s', 40, 'TRAIN', -3656.21044921875)\n",
      "('epoch: %s %s  loss: %s', 41, 'TRAIN', -3458.866943359375)\n",
      "('epoch: %s %s  loss: %s', 42, 'TRAIN', -3762.19921875)\n",
      "('epoch: %s %s  loss: %s', 43, 'TRAIN', -3444.76025390625)\n",
      "('epoch: %s %s  loss: %s', 44, 'TRAIN', -3435.423583984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.1852477490901947\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9313380181789398\n",
      "Best validation accuracy (AVG): 0.9612675905227661\n",
      "('epoch: %s %s  loss: %s', 45, 'TRAIN', -3506.865966796875)\n",
      "('epoch: %s %s  loss: %s', 46, 'TRAIN', -3106.09912109375)\n",
      "('epoch: %s %s  loss: %s', 47, 'TRAIN', -3024.9912109375)\n",
      "('epoch: %s %s  loss: %s', 48, 'TRAIN', -2762.859619140625)\n",
      "('epoch: %s %s  loss: %s', 49, 'TRAIN', -2234.885498046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.188959002494812\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9718309640884399\n",
      "Best training accuracy (AVG): 0.9309859097003936\n",
      "Best validation accuracy (AVG): 0.9633802711963654\n",
      "('epoch: %s %s  loss: %s', 50, 'TRAIN', -1914.01123046875)\n",
      "('epoch: %s %s  loss: %s', 51, 'TRAIN', -1438.6605224609375)\n",
      "('epoch: %s %s  loss: %s', 52, 'TRAIN', -961.7362670898438)\n",
      "('epoch: %s %s  loss: %s', 53, 'TRAIN', -734.7155151367188)\n",
      "('epoch: %s %s  loss: %s', 54, 'TRAIN', -597.6881713867188)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.30196937918663025\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9278168857097626\n",
      "Best validation accuracy (AVG): 0.9584506809711456\n",
      "('epoch: %s %s  loss: %s', 55, 'TRAIN', -108.61358642578125)\n",
      "('epoch: %s %s  loss: %s', 56, 'TRAIN', 231.53855895996094)\n",
      "('epoch: %s %s  loss: %s', 57, 'TRAIN', 670.2752685546875)\n",
      "('epoch: %s %s  loss: %s', 58, 'TRAIN', 2206.49755859375)\n",
      "('epoch: %s %s  loss: %s', 59, 'TRAIN', 7046.12451171875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.9348764419555664\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9084506630897522\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.9077464461326599\n",
      "Best validation accuracy (AVG): 0.9295774698257446\n",
      "('epoch: %s %s  loss: %s', 60, 'TRAIN', 14033.4765625)\n",
      "('epoch: %s %s  loss: %s', 61, 'TRAIN', 14645.455078125)\n",
      "('epoch: %s %s  loss: %s', 62, 'TRAIN', 10799.54296875)\n",
      "('epoch: %s %s  loss: %s', 63, 'TRAIN', 6396.19580078125)\n",
      "('epoch: %s %s  loss: %s', 64, 'TRAIN', 3297.825439453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.9194468855857849\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9366196990013123\n",
      "Best training accuracy (AVG): 0.9161971807479858\n",
      "Best validation accuracy (AVG): 0.9316901385784149\n",
      "('epoch: %s %s  loss: %s', 65, 'TRAIN', 1459.6383056640625)\n",
      "('epoch: %s %s  loss: %s', 66, 'TRAIN', 246.3776397705078)\n",
      "('epoch: %s %s  loss: %s', 67, 'TRAIN', -561.9769897460938)\n",
      "('epoch: %s %s  loss: %s', 68, 'TRAIN', -759.732177734375)\n",
      "('epoch: %s %s  loss: %s', 69, 'TRAIN', -842.8203735351562)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.589152455329895\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9197183012962341\n",
      "Best validation accuracy (AVG): 0.9443661570549011\n",
      "('epoch: %s %s  loss: %s', 70, 'TRAIN', -858.9613037109375)\n",
      "('epoch: %s %s  loss: %s', 71, 'TRAIN', -1013.5659790039062)\n",
      "('epoch: %s %s  loss: %s', 72, 'TRAIN', -1043.0194091796875)\n",
      "('epoch: %s %s  loss: %s', 73, 'TRAIN', -1072.904052734375)\n",
      "('epoch: %s %s  loss: %s', 74, 'TRAIN', -1119.9072265625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5029511451721191\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9260563254356384\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9242957532405853\n",
      "Best validation accuracy (AVG): 0.9507042169570923\n",
      "('epoch: %s %s  loss: %s', 75, 'TRAIN', -1305.4180908203125)\n",
      "('epoch: %s %s  loss: %s', 76, 'TRAIN', -1475.59716796875)\n",
      "('epoch: %s %s  loss: %s', 77, 'TRAIN', -1375.10546875)\n",
      "('epoch: %s %s  loss: %s', 78, 'TRAIN', -1607.768310546875)\n",
      "('epoch: %s %s  loss: %s', 79, 'TRAIN', -1639.4283447265625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.468877911567688\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9295774579048157\n",
      "Best validation accuracy (AVG): 0.9521126627922059\n",
      "('epoch: %s %s  loss: %s', 80, 'TRAIN', -1595.442626953125)\n",
      "('epoch: %s %s  loss: %s', 81, 'TRAIN', -1799.53564453125)\n",
      "('epoch: %s %s  loss: %s', 82, 'TRAIN', -1735.5760498046875)\n",
      "('epoch: %s %s  loss: %s', 83, 'TRAIN', -1801.94677734375)\n",
      "('epoch: %s %s  loss: %s', 84, 'TRAIN', -1808.5892333984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.44309690594673157\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9316901206970215\n",
      "Best validation accuracy (AVG): 0.9563380122184754\n",
      "('epoch: %s %s  loss: %s', 85, 'TRAIN', -1889.6287841796875)\n",
      "('epoch: %s %s  loss: %s', 86, 'TRAIN', -1751.2115478515625)\n",
      "('epoch: %s %s  loss: %s', 87, 'TRAIN', -1857.6097412109375)\n",
      "('epoch: %s %s  loss: %s', 88, 'TRAIN', -1681.4410400390625)\n",
      "('epoch: %s %s  loss: %s', 89, 'TRAIN', -1733.2625732421875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4154946506023407\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.930281686782837\n",
      "Best validation accuracy (AVG): 0.9563380062580109\n",
      "('epoch: %s %s  loss: %s', 90, 'TRAIN', -1623.3798828125)\n",
      "('epoch: %s %s  loss: %s', 91, 'TRAIN', -1622.568359375)\n",
      "('epoch: %s %s  loss: %s', 92, 'TRAIN', -1548.7874755859375)\n",
      "('epoch: %s %s  loss: %s', 93, 'TRAIN', -1566.08154296875)\n",
      "('epoch: %s %s  loss: %s', 94, 'TRAIN', -1555.6790771484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4563746154308319\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9302816808223724\n",
      "Best validation accuracy (AVG): 0.9542253315448761\n",
      "('epoch: %s %s  loss: %s', 95, 'TRAIN', -1477.654296875)\n",
      "('epoch: %s %s  loss: %s', 96, 'TRAIN', -1438.88427734375)\n",
      "('epoch: %s %s  loss: %s', 97, 'TRAIN', -1483.182373046875)\n",
      "('epoch: %s %s  loss: %s', 98, 'TRAIN', -1381.7408447265625)\n",
      "('epoch: %s %s  loss: %s', 99, 'TRAIN', -1401.8778076171875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5146597027778625\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9264084339141846\n",
      "Best validation accuracy (AVG): 0.9542253315448761\n",
      "('epoch: %s %s  loss: %s', 100, 'TRAIN', -1374.14208984375)\n",
      "('epoch: %s %s  loss: %s', 101, 'TRAIN', -1409.2447509765625)\n",
      "('epoch: %s %s  loss: %s', 102, 'TRAIN', -1383.2310791015625)\n",
      "('epoch: %s %s  loss: %s', 103, 'TRAIN', -1405.3587646484375)\n",
      "('epoch: %s %s  loss: %s', 104, 'TRAIN', -1398.6204833984375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4990406334400177\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9260563254356384\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9225351929664611\n",
      "Best validation accuracy (AVG): 0.9528168857097625\n",
      "('epoch: %s %s  loss: %s', 105, 'TRAIN', -1408.46533203125)\n",
      "('epoch: %s %s  loss: %s', 106, 'TRAIN', -1397.0045166015625)\n",
      "('epoch: %s %s  loss: %s', 107, 'TRAIN', -1409.162353515625)\n",
      "('epoch: %s %s  loss: %s', 108, 'TRAIN', -1406.8653564453125)\n",
      "('epoch: %s %s  loss: %s', 109, 'TRAIN', -1431.2255859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4819364845752716\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9204225301742553\n",
      "Best validation accuracy (AVG): 0.9521126627922059\n",
      "('epoch: %s %s  loss: %s', 110, 'TRAIN', -1429.028564453125)\n",
      "('epoch: %s %s  loss: %s', 111, 'TRAIN', -1428.6807861328125)\n",
      "('epoch: %s %s  loss: %s', 112, 'TRAIN', -1469.99755859375)\n",
      "('epoch: %s %s  loss: %s', 113, 'TRAIN', -1469.194091796875)\n",
      "('epoch: %s %s  loss: %s', 114, 'TRAIN', -1474.90478515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.49166491627693176\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9204225242137909\n",
      "Best validation accuracy (AVG): 0.9521126627922059\n",
      "('epoch: %s %s  loss: %s', 115, 'TRAIN', -1481.558837890625)\n",
      "('epoch: %s %s  loss: %s', 116, 'TRAIN', -1498.62158203125)\n",
      "('epoch: %s %s  loss: %s', 117, 'TRAIN', -1498.85205078125)\n",
      "('epoch: %s %s  loss: %s', 118, 'TRAIN', -1521.4420166015625)\n",
      "('epoch: %s %s  loss: %s', 119, 'TRAIN', -1543.4293212890625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4964841306209564\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9204225301742553\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 120, 'TRAIN', -1542.32958984375)\n",
      "('epoch: %s %s  loss: %s', 121, 'TRAIN', -1526.26025390625)\n",
      "('epoch: %s %s  loss: %s', 122, 'TRAIN', -1550.316650390625)\n",
      "('epoch: %s %s  loss: %s', 123, 'TRAIN', -1571.23779296875)\n",
      "('epoch: %s %s  loss: %s', 124, 'TRAIN', -1573.495849609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4880235195159912\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9204225242137909\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 125, 'TRAIN', -1584.693603515625)\n",
      "('epoch: %s %s  loss: %s', 126, 'TRAIN', -1596.3153076171875)\n",
      "('epoch: %s %s  loss: %s', 127, 'TRAIN', -1610.2413330078125)\n",
      "('epoch: %s %s  loss: %s', 128, 'TRAIN', -1602.3575439453125)\n",
      "('epoch: %s %s  loss: %s', 129, 'TRAIN', -1645.193603515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.48914042115211487\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9186619639396667\n",
      "Best validation accuracy (AVG): 0.9507042169570923\n",
      "('epoch: %s %s  loss: %s', 130, 'TRAIN', -1623.613037109375)\n",
      "('epoch: %s %s  loss: %s', 131, 'TRAIN', -1640.5103759765625)\n",
      "('epoch: %s %s  loss: %s', 132, 'TRAIN', -1660.6556396484375)\n",
      "('epoch: %s %s  loss: %s', 133, 'TRAIN', -1648.8131103515625)\n",
      "('epoch: %s %s  loss: %s', 134, 'TRAIN', -1672.177978515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.483136385679245\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9183098554611206\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 135, 'TRAIN', -1672.2105712890625)\n",
      "('epoch: %s %s  loss: %s', 136, 'TRAIN', -1678.644775390625)\n",
      "('epoch: %s %s  loss: %s', 137, 'TRAIN', -1680.3798828125)\n",
      "('epoch: %s %s  loss: %s', 138, 'TRAIN', -1695.357421875)\n",
      "('epoch: %s %s  loss: %s', 139, 'TRAIN', -1719.0784912109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5161973834037781\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9176056325435639\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 140, 'TRAIN', -1701.0753173828125)\n",
      "('epoch: %s %s  loss: %s', 141, 'TRAIN', -1709.601806640625)\n",
      "('epoch: %s %s  loss: %s', 142, 'TRAIN', -1729.3546142578125)\n",
      "('epoch: %s %s  loss: %s', 143, 'TRAIN', -1751.5208740234375)\n",
      "('epoch: %s %s  loss: %s', 144, 'TRAIN', -1716.5740966796875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5123652219772339\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9176056325435639\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 145, 'TRAIN', -1744.9244384765625)\n",
      "('epoch: %s %s  loss: %s', 146, 'TRAIN', -1766.216064453125)\n",
      "('epoch: %s %s  loss: %s', 147, 'TRAIN', -1759.6895751953125)\n",
      "('epoch: %s %s  loss: %s', 148, 'TRAIN', -1754.148681640625)\n",
      "('epoch: %s %s  loss: %s', 149, 'TRAIN', -1753.1046142578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.511199951171875\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9172535181045532\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 150, 'TRAIN', -1783.62841796875)\n",
      "('epoch: %s %s  loss: %s', 151, 'TRAIN', -1769.278564453125)\n",
      "('epoch: %s %s  loss: %s', 152, 'TRAIN', -1777.560302734375)\n",
      "('epoch: %s %s  loss: %s', 153, 'TRAIN', -1770.4503173828125)\n",
      "('epoch: %s %s  loss: %s', 154, 'TRAIN', -1791.5687255859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5088366270065308\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9161971747875214\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 155, 'TRAIN', -1797.883056640625)\n",
      "('epoch: %s %s  loss: %s', 156, 'TRAIN', -1774.880859375)\n",
      "('epoch: %s %s  loss: %s', 157, 'TRAIN', -1794.6895751953125)\n",
      "('epoch: %s %s  loss: %s', 158, 'TRAIN', -1802.783447265625)\n",
      "('epoch: %s %s  loss: %s', 159, 'TRAIN', -1798.5238037109375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5026481747627258\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9154929518699646\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 160, 'TRAIN', -1796.5599365234375)\n",
      "('epoch: %s %s  loss: %s', 161, 'TRAIN', -1797.1058349609375)\n",
      "('epoch: %s %s  loss: %s', 162, 'TRAIN', -1814.1954345703125)\n",
      "('epoch: %s %s  loss: %s', 163, 'TRAIN', -1807.9422607421875)\n",
      "('epoch: %s %s  loss: %s', 164, 'TRAIN', -1814.2523193359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5037207007408142\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9140844941139221\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 165, 'TRAIN', -1809.77587890625)\n",
      "('epoch: %s %s  loss: %s', 166, 'TRAIN', -1844.630126953125)\n",
      "('epoch: %s %s  loss: %s', 167, 'TRAIN', -1812.163818359375)\n",
      "('epoch: %s %s  loss: %s', 168, 'TRAIN', -1824.1080322265625)\n",
      "('epoch: %s %s  loss: %s', 169, 'TRAIN', -1828.8985595703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4933779537677765\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9144366025924683\n",
      "Best validation accuracy (AVG): 0.9507042109966278\n",
      "('epoch: %s %s  loss: %s', 170, 'TRAIN', -1824.5238037109375)\n",
      "('epoch: %s %s  loss: %s', 171, 'TRAIN', -1820.1220703125)\n",
      "('epoch: %s %s  loss: %s', 172, 'TRAIN', -1845.3685302734375)\n",
      "('epoch: %s %s  loss: %s', 173, 'TRAIN', -1816.72509765625)\n",
      "('epoch: %s %s  loss: %s', 174, 'TRAIN', -1835.389892578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.47618430852890015\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9225351810455322\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9144366025924683\n",
      "Best validation accuracy (AVG): 0.9507042109966278\n",
      "('epoch: %s %s  loss: %s', 175, 'TRAIN', -1843.5020751953125)\n",
      "('epoch: %s %s  loss: %s', 176, 'TRAIN', -1847.134033203125)\n",
      "('epoch: %s %s  loss: %s', 177, 'TRAIN', -1854.635498046875)\n",
      "('epoch: %s %s  loss: %s', 178, 'TRAIN', -1839.934326171875)\n",
      "('epoch: %s %s  loss: %s', 179, 'TRAIN', -1859.4102783203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.47287750244140625\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9140844941139221\n",
      "Best validation accuracy (AVG): 0.9514084398746491\n",
      "('epoch: %s %s  loss: %s', 180, 'TRAIN', -1866.9176025390625)\n",
      "('epoch: %s %s  loss: %s', 181, 'TRAIN', -1868.754638671875)\n",
      "('epoch: %s %s  loss: %s', 182, 'TRAIN', -1866.1826171875)\n",
      "('epoch: %s %s  loss: %s', 183, 'TRAIN', -1849.9368896484375)\n",
      "('epoch: %s %s  loss: %s', 184, 'TRAIN', -1866.8341064453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.47845539450645447\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9144366085529327\n",
      "Best validation accuracy (AVG): 0.9507042050361634\n",
      "('epoch: %s %s  loss: %s', 185, 'TRAIN', -1857.845703125)\n",
      "('epoch: %s %s  loss: %s', 186, 'TRAIN', -1854.029296875)\n",
      "('epoch: %s %s  loss: %s', 187, 'TRAIN', -1839.46728515625)\n",
      "('epoch: %s %s  loss: %s', 188, 'TRAIN', -1846.202392578125)\n",
      "('epoch: %s %s  loss: %s', 189, 'TRAIN', -1839.145263671875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4962047040462494\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9126760363578796\n",
      "Best validation accuracy (AVG): 0.949999988079071\n",
      "('epoch: %s %s  loss: %s', 190, 'TRAIN', -1843.1688232421875)\n",
      "('epoch: %s %s  loss: %s', 191, 'TRAIN', -1832.47021484375)\n",
      "('epoch: %s %s  loss: %s', 192, 'TRAIN', -1862.9315185546875)\n",
      "('epoch: %s %s  loss: %s', 193, 'TRAIN', -1833.7916259765625)\n",
      "('epoch: %s %s  loss: %s', 194, 'TRAIN', -1837.751220703125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5012864470481873\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9130281507968903\n",
      "Best validation accuracy (AVG): 0.949999988079071\n",
      "('epoch: %s %s  loss: %s', 195, 'TRAIN', -1831.9818115234375)\n",
      "('epoch: %s %s  loss: %s', 196, 'TRAIN', -1848.7764892578125)\n",
      "('epoch: %s %s  loss: %s', 197, 'TRAIN', -1853.6318359375)\n",
      "('epoch: %s %s  loss: %s', 198, 'TRAIN', -1849.6767578125)\n",
      "('epoch: %s %s  loss: %s', 199, 'TRAIN', -1851.9801025390625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5090595483779907\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9116196930408478\n",
      "Best validation accuracy (AVG): 0.949999988079071\n",
      "('epoch: %s %s  loss: %s', 200, 'TRAIN', -1861.988037109375)\n",
      "('epoch: %s %s  loss: %s', 201, 'TRAIN', -1847.5247802734375)\n",
      "('epoch: %s %s  loss: %s', 202, 'TRAIN', -1869.0565185546875)\n",
      "('epoch: %s %s  loss: %s', 203, 'TRAIN', -1856.24658203125)\n",
      "('epoch: %s %s  loss: %s', 204, 'TRAIN', -1860.346435546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5397858023643494\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9109154641628265\n",
      "Best validation accuracy (AVG): 0.9485915303230286\n",
      "('epoch: %s %s  loss: %s', 205, 'TRAIN', -1845.10693359375)\n",
      "('epoch: %s %s  loss: %s', 206, 'TRAIN', -1852.78564453125)\n",
      "('epoch: %s %s  loss: %s', 207, 'TRAIN', -1865.9176025390625)\n",
      "('epoch: %s %s  loss: %s', 208, 'TRAIN', -1856.883544921875)\n",
      "('epoch: %s %s  loss: %s', 209, 'TRAIN', -1882.8956298828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5359987020492554\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9112675786018372\n",
      "Best validation accuracy (AVG): 0.9485915303230286\n",
      "('epoch: %s %s  loss: %s', 210, 'TRAIN', -1871.2281494140625)\n",
      "('epoch: %s %s  loss: %s', 211, 'TRAIN', -1860.842041015625)\n",
      "('epoch: %s %s  loss: %s', 212, 'TRAIN', -1876.62158203125)\n",
      "('epoch: %s %s  loss: %s', 213, 'TRAIN', -1868.8953857421875)\n",
      "('epoch: %s %s  loss: %s', 214, 'TRAIN', -1860.0140380859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.540389358997345\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9119718074798584\n",
      "Best validation accuracy (AVG): 0.9492957592010498\n",
      "('epoch: %s %s  loss: %s', 215, 'TRAIN', -1877.358642578125)\n",
      "('epoch: %s %s  loss: %s', 216, 'TRAIN', -1892.09912109375)\n",
      "('epoch: %s %s  loss: %s', 217, 'TRAIN', -1857.985595703125)\n",
      "('epoch: %s %s  loss: %s', 218, 'TRAIN', -1879.5465087890625)\n",
      "('epoch: %s %s  loss: %s', 219, 'TRAIN', -1881.934326171875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.53668612241745\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.912323921918869\n",
      "Best validation accuracy (AVG): 0.9507042169570923\n",
      "('epoch: %s %s  loss: %s', 220, 'TRAIN', -1902.92041015625)\n",
      "('epoch: %s %s  loss: %s', 221, 'TRAIN', -1873.32470703125)\n",
      "('epoch: %s %s  loss: %s', 222, 'TRAIN', -1889.7525634765625)\n",
      "('epoch: %s %s  loss: %s', 223, 'TRAIN', -1903.2315673828125)\n",
      "('epoch: %s %s  loss: %s', 224, 'TRAIN', -1892.3690185546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5438887476921082\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.912323921918869\n",
      "Best validation accuracy (AVG): 0.949999988079071\n",
      "('epoch: %s %s  loss: %s', 225, 'TRAIN', -1911.934326171875)\n",
      "('epoch: %s %s  loss: %s', 226, 'TRAIN', -1907.225830078125)\n",
      "('epoch: %s %s  loss: %s', 227, 'TRAIN', -1910.871826171875)\n",
      "('epoch: %s %s  loss: %s', 228, 'TRAIN', -1894.1173095703125)\n",
      "('epoch: %s %s  loss: %s', 229, 'TRAIN', -1887.5211181640625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5333624482154846\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9112675786018372\n",
      "Best validation accuracy (AVG): 0.9485915303230286\n",
      "('epoch: %s %s  loss: %s', 230, 'TRAIN', -1892.48486328125)\n",
      "('epoch: %s %s  loss: %s', 231, 'TRAIN', -1893.6356201171875)\n",
      "('epoch: %s %s  loss: %s', 232, 'TRAIN', -1897.7281494140625)\n",
      "('epoch: %s %s  loss: %s', 233, 'TRAIN', -1899.46435546875)\n",
      "('epoch: %s %s  loss: %s', 234, 'TRAIN', -1927.4083251953125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5213462710380554\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9112675786018372\n",
      "Best validation accuracy (AVG): 0.9478872954845429\n",
      "('epoch: %s %s  loss: %s', 235, 'TRAIN', -1892.454833984375)\n",
      "('epoch: %s %s  loss: %s', 236, 'TRAIN', -1899.650390625)\n",
      "('epoch: %s %s  loss: %s', 237, 'TRAIN', -1899.556884765625)\n",
      "('epoch: %s %s  loss: %s', 238, 'TRAIN', -1914.0743408203125)\n",
      "('epoch: %s %s  loss: %s', 239, 'TRAIN', -1891.279296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5265310406684875\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9109154641628265\n",
      "Best validation accuracy (AVG): 0.9471830725669861\n",
      "('epoch: %s %s  loss: %s', 240, 'TRAIN', -1893.001953125)\n",
      "('epoch: %s %s  loss: %s', 241, 'TRAIN', -1892.9658203125)\n",
      "('epoch: %s %s  loss: %s', 242, 'TRAIN', -1901.0902099609375)\n",
      "('epoch: %s %s  loss: %s', 243, 'TRAIN', -1886.67431640625)\n",
      "('epoch: %s %s  loss: %s', 244, 'TRAIN', -1907.1585693359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5325981378555298\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9105633497238159\n",
      "Best validation accuracy (AVG): 0.9471830725669861\n",
      "('epoch: %s %s  loss: %s', 245, 'TRAIN', -1892.140625)\n",
      "('epoch: %s %s  loss: %s', 246, 'TRAIN', -1901.0789794921875)\n",
      "('epoch: %s %s  loss: %s', 247, 'TRAIN', -1911.2205810546875)\n",
      "('epoch: %s %s  loss: %s', 248, 'TRAIN', -1894.430908203125)\n",
      "('epoch: %s %s  loss: %s', 249, 'TRAIN', -1915.2236328125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5367770195007324\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9105633497238159\n",
      "Best validation accuracy (AVG): 0.9471830725669861\n",
      "('epoch: %s %s  loss: %s', 250, 'TRAIN', -1908.0240478515625)\n",
      "('epoch: %s %s  loss: %s', 251, 'TRAIN', -1906.29833984375)\n",
      "('epoch: %s %s  loss: %s', 252, 'TRAIN', -1923.5068359375)\n",
      "('epoch: %s %s  loss: %s', 253, 'TRAIN', -1918.1025390625)\n",
      "('epoch: %s %s  loss: %s', 254, 'TRAIN', -1901.56396484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5191351771354675\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9112675786018372\n",
      "Best validation accuracy (AVG): 0.9478873014450073\n",
      "('epoch: %s %s  loss: %s', 255, 'TRAIN', -1923.3265380859375)\n",
      "('epoch: %s %s  loss: %s', 256, 'TRAIN', -1934.3204345703125)\n",
      "('epoch: %s %s  loss: %s', 257, 'TRAIN', -1924.36279296875)\n",
      "('epoch: %s %s  loss: %s', 258, 'TRAIN', -1938.18701171875)\n",
      "('epoch: %s %s  loss: %s', 259, 'TRAIN', -1949.8818359375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5314856767654419\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9119718074798584\n",
      "Best validation accuracy (AVG): 0.9478873014450073\n",
      "('epoch: %s %s  loss: %s', 260, 'TRAIN', -1942.69775390625)\n",
      "('epoch: %s %s  loss: %s', 261, 'TRAIN', -1931.7054443359375)\n",
      "('epoch: %s %s  loss: %s', 262, 'TRAIN', -1951.47705078125)\n",
      "('epoch: %s %s  loss: %s', 263, 'TRAIN', -1942.7847900390625)\n",
      "('epoch: %s %s  loss: %s', 264, 'TRAIN', -1956.893310546875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5357460975646973\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9116196930408478\n",
      "Best validation accuracy (AVG): 0.9478873014450073\n",
      "('epoch: %s %s  loss: %s', 265, 'TRAIN', -1950.48779296875)\n",
      "('epoch: %s %s  loss: %s', 266, 'TRAIN', -1948.547119140625)\n",
      "('epoch: %s %s  loss: %s', 267, 'TRAIN', -1957.8154296875)\n",
      "('epoch: %s %s  loss: %s', 268, 'TRAIN', -1947.7222900390625)\n",
      "('epoch: %s %s  loss: %s', 269, 'TRAIN', -1940.4068603515625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.542222797870636\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9116196930408478\n",
      "Best validation accuracy (AVG): 0.9478873014450073\n",
      "('epoch: %s %s  loss: %s', 270, 'TRAIN', -1943.1600341796875)\n",
      "('epoch: %s %s  loss: %s', 271, 'TRAIN', -1919.5133056640625)\n",
      "('epoch: %s %s  loss: %s', 272, 'TRAIN', -1931.1761474609375)\n",
      "('epoch: %s %s  loss: %s', 273, 'TRAIN', -1910.262451171875)\n",
      "('epoch: %s %s  loss: %s', 274, 'TRAIN', -1908.70849609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5268025994300842\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9105633556842804\n",
      "Best validation accuracy (AVG): 0.9478873014450073\n",
      "('epoch: %s %s  loss: %s', 275, 'TRAIN', -1911.7825927734375)\n",
      "('epoch: %s %s  loss: %s', 276, 'TRAIN', -1906.0078125)\n",
      "('epoch: %s %s  loss: %s', 277, 'TRAIN', -1894.5390625)\n",
      "('epoch: %s %s  loss: %s', 278, 'TRAIN', -1912.9873046875)\n",
      "('epoch: %s %s  loss: %s', 279, 'TRAIN', -1871.4652099609375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5229088068008423\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9091549098491669\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 280, 'TRAIN', -1893.2835693359375)\n",
      "('epoch: %s %s  loss: %s', 281, 'TRAIN', -1893.0325927734375)\n",
      "('epoch: %s %s  loss: %s', 282, 'TRAIN', -1890.806884765625)\n",
      "('epoch: %s %s  loss: %s', 283, 'TRAIN', -1875.592529296875)\n",
      "('epoch: %s %s  loss: %s', 284, 'TRAIN', -1866.8514404296875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5353233218193054\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9119718074798584\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.908098578453064\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 285, 'TRAIN', -1880.4224853515625)\n",
      "('epoch: %s %s  loss: %s', 286, 'TRAIN', -1873.9720458984375)\n",
      "('epoch: %s %s  loss: %s', 287, 'TRAIN', -1890.5294189453125)\n",
      "('epoch: %s %s  loss: %s', 288, 'TRAIN', -1886.3663330078125)\n",
      "('epoch: %s %s  loss: %s', 289, 'TRAIN', -1873.4962158203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5479474067687988\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9119718074798584\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9077464640140533\n",
      "Best validation accuracy (AVG): 0.9450703859329224\n",
      "('epoch: %s %s  loss: %s', 290, 'TRAIN', -1873.1663818359375)\n",
      "('epoch: %s %s  loss: %s', 291, 'TRAIN', -1884.3060302734375)\n",
      "('epoch: %s %s  loss: %s', 292, 'TRAIN', -1884.0452880859375)\n",
      "('epoch: %s %s  loss: %s', 293, 'TRAIN', -1884.203857421875)\n",
      "('epoch: %s %s  loss: %s', 294, 'TRAIN', -1887.184814453125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5546636581420898\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9119718074798584\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9077464640140533\n",
      "Best validation accuracy (AVG): 0.9457746148109436\n",
      "('epoch: %s %s  loss: %s', 295, 'TRAIN', -1886.7939453125)\n",
      "('epoch: %s %s  loss: %s', 296, 'TRAIN', -1899.859375)\n",
      "('epoch: %s %s  loss: %s', 297, 'TRAIN', -1882.545166015625)\n",
      "('epoch: %s %s  loss: %s', 298, 'TRAIN', -1880.3240966796875)\n",
      "('epoch: %s %s  loss: %s', 299, 'TRAIN', -1879.841064453125)\n",
      "WITH VAL\n",
      "Test Accuracy: 0.867132842540741\n",
      "Test Accuracy (AVG): 0.9370629191398621\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9230769276618958\n",
      "Test Accuracy (AVG): 0.8251748085021973\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -1890.66064453125)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -1876.2979736328125)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -1887.679931640625)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -1881.1766357421875)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -1889.24658203125)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -1885.453857421875)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -1888.9510498046875)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -1872.964599609375)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -1874.6409912109375)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -1870.638671875)\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -1878.56640625)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -1873.0826416015625)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -1888.7254638671875)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -1866.2708740234375)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -1890.0947265625)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -1875.1656494140625)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -1879.1363525390625)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -1873.13134765625)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -1882.6983642578125)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -1875.3905029296875)\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -1872.625732421875)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -1860.521484375)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -1869.351318359375)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -1872.164794921875)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -1880.80078125)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -1891.4056396484375)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -1857.861572265625)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -1871.0511474609375)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -1867.35888671875)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -1892.554443359375)\n",
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "Best training loss: 0.0008931408519856632\n",
      "Best validation loss: 0.16292335093021393\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9154929518699646\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9066901326179504\n",
      "Best validation accuracy (AVG): 0.9330985724925995\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -3784.797119140625)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -9933.611328125)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -18411.84765625)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -23163.361328125)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -23095.578125)\n",
      "Best training loss: 5.513452379091177e-07\n",
      "Best validation loss: 0.1314968317747116\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9309859097003936\n",
      "Best validation accuracy (AVG): 0.9499999701976776\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -21971.232421875)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -18791.44140625)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -11958.20703125)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -7808.8525390625)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -6476.03515625)\n",
      "Best training loss: 1.7881399116959074e-07\n",
      "Best validation loss: 0.15262818336486816\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9299295663833618\n",
      "Best validation accuracy (AVG): 0.9535211145877838\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -5537.01220703125)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -6979.185546875)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -7742.34375)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -5619.84912109375)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -3963.687255859375)\n",
      "Best training loss: 5.016739237362344e-07\n",
      "Best validation loss: 0.12219064682722092\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9647887349128723\n",
      "Best training accuracy (AVG): 0.9327464640140534\n",
      "Best validation accuracy (AVG): 0.9549295723438262\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -2295.47509765625)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -92.84039306640625)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', 2175.736572265625)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', 3734.720703125)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', 4599.92041015625)\n",
      "Best training loss: 2.086163704007049e-07\n",
      "Best validation loss: 0.18826061487197876\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.927464771270752\n",
      "Best validation accuracy (AVG): 0.9471830666065216\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', 3938.671142578125)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', 3395.88525390625)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', 2678.109130859375)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', 2349.97216796875)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', 1826.2879638671875)\n",
      "Best training loss: 5.828772555105388e-05\n",
      "Best validation loss: 0.6443953514099121\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8919013857841491\n",
      "Best validation accuracy (AVG): 0.9169013917446136\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', 1502.0032958984375)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', 1238.4580078125)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', 1162.4217529296875)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', 973.1931762695312)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', 885.8541870117188)\n",
      "Best training loss: 0.0004011112032458186\n",
      "Best validation loss: 0.7068315148353577\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8873239159584045\n",
      "Best validation accuracy: 0.9154929518699646\n",
      "Best training accuracy (AVG): 0.869366180896759\n",
      "Best validation accuracy (AVG): 0.8999999940395356\n",
      "('epoch: %s %s  loss: %s', 30, 'TRAIN', 825.735107421875)\n",
      "('epoch: %s %s  loss: %s', 31, 'TRAIN', 745.7020263671875)\n",
      "('epoch: %s %s  loss: %s', 32, 'TRAIN', 703.34765625)\n",
      "('epoch: %s %s  loss: %s', 33, 'TRAIN', 624.85400390625)\n",
      "('epoch: %s %s  loss: %s', 34, 'TRAIN', 527.7831420898438)\n",
      "Best training loss: 0.012772764079272747\n",
      "Best validation loss: 1.008319616317749\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8767605423927307\n",
      "Best validation accuracy: 0.9154929518699646\n",
      "Best training accuracy (AVG): 0.8183098495006561\n",
      "Best validation accuracy (AVG): 0.8570422410964966\n",
      "('epoch: %s %s  loss: %s', 35, 'TRAIN', 509.6228332519531)\n",
      "('epoch: %s %s  loss: %s', 36, 'TRAIN', 455.1795959472656)\n",
      "('epoch: %s %s  loss: %s', 37, 'TRAIN', 454.09332275390625)\n",
      "('epoch: %s %s  loss: %s', 38, 'TRAIN', 362.4956359863281)\n",
      "('epoch: %s %s  loss: %s', 39, 'TRAIN', 403.5589599609375)\n",
      "Best training loss: 0.10130143165588379\n",
      "Best validation loss: 1.1410092115402222\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8661971688270569\n",
      "Best validation accuracy: 0.9154929518699646\n",
      "Best training accuracy (AVG): 0.7742957651615143\n",
      "Best validation accuracy (AVG): 0.8176056265830993\n",
      "('epoch: %s %s  loss: %s', 40, 'TRAIN', 348.75762939453125)\n",
      "('epoch: %s %s  loss: %s', 41, 'TRAIN', 333.1438293457031)\n",
      "('epoch: %s %s  loss: %s', 42, 'TRAIN', 322.73382568359375)\n",
      "('epoch: %s %s  loss: %s', 43, 'TRAIN', 317.3388366699219)\n",
      "('epoch: %s %s  loss: %s', 44, 'TRAIN', 284.0704650878906)\n",
      "Best training loss: 0.9460409879684448\n",
      "Best validation loss: 1.0631537437438965\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8732393980026245\n",
      "Best validation accuracy: 0.9084506630897522\n",
      "Best training accuracy (AVG): 0.7640844821929932\n",
      "Best validation accuracy (AVG): 0.7894366025924683\n",
      "('epoch: %s %s  loss: %s', 45, 'TRAIN', 279.613525390625)\n",
      "('epoch: %s %s  loss: %s', 46, 'TRAIN', 259.76641845703125)\n",
      "('epoch: %s %s  loss: %s', 47, 'TRAIN', 243.8139190673828)\n",
      "('epoch: %s %s  loss: %s', 48, 'TRAIN', 232.03025817871094)\n",
      "('epoch: %s %s  loss: %s', 49, 'TRAIN', 252.37648010253906)\n",
      "Best training loss: 0.6569886207580566\n",
      "Best validation loss: 1.0039223432540894\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8732393980026245\n",
      "Best validation accuracy: 0.9084506630897522\n",
      "Best training accuracy (AVG): 0.7922535121440888\n",
      "Best validation accuracy (AVG): 0.8176056206226349\n",
      "('epoch: %s %s  loss: %s', 50, 'TRAIN', 212.51019287109375)\n",
      "('epoch: %s %s  loss: %s', 51, 'TRAIN', 182.33822631835938)\n",
      "('epoch: %s %s  loss: %s', 52, 'TRAIN', 202.5536651611328)\n",
      "('epoch: %s %s  loss: %s', 53, 'TRAIN', 174.6112823486328)\n",
      "('epoch: %s %s  loss: %s', 54, 'TRAIN', 178.21441650390625)\n",
      "Best training loss: 1.343206763267517\n",
      "Best validation loss: 0.9088695645332336\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8802816867828369\n",
      "Best validation accuracy: 0.9084506630897522\n",
      "Best training accuracy (AVG): 0.8514084339141845\n",
      "Best validation accuracy (AVG): 0.8859154760837555\n",
      "('epoch: %s %s  loss: %s', 55, 'TRAIN', 178.9378204345703)\n",
      "('epoch: %s %s  loss: %s', 56, 'TRAIN', 161.14187622070312)\n",
      "('epoch: %s %s  loss: %s', 57, 'TRAIN', 180.142822265625)\n",
      "('epoch: %s %s  loss: %s', 58, 'TRAIN', 148.149658203125)\n",
      "('epoch: %s %s  loss: %s', 59, 'TRAIN', 175.97885131835938)\n",
      "Best training loss: 0.8468836545944214\n",
      "Best validation loss: 0.8125763535499573\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8802816867828369\n",
      "Best validation accuracy: 0.9154929518699646\n",
      "Best training accuracy (AVG): 0.8690140664577484\n",
      "Best validation accuracy (AVG): 0.9021126568317414\n",
      "('epoch: %s %s  loss: %s', 60, 'TRAIN', 144.52545166015625)\n",
      "('epoch: %s %s  loss: %s', 61, 'TRAIN', 164.7054901123047)\n",
      "('epoch: %s %s  loss: %s', 62, 'TRAIN', 212.13504028320312)\n",
      "('epoch: %s %s  loss: %s', 63, 'TRAIN', 196.75653076171875)\n",
      "('epoch: %s %s  loss: %s', 64, 'TRAIN', 223.9479217529297)\n",
      "Best training loss: 0.00019971704750787467\n",
      "Best validation loss: 0.6450037956237793\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8922535002231597\n",
      "Best validation accuracy (AVG): 0.9204225182533264\n",
      "('epoch: %s %s  loss: %s', 65, 'TRAIN', 304.218994140625)\n",
      "('epoch: %s %s  loss: %s', 66, 'TRAIN', 386.7095947265625)\n",
      "('epoch: %s %s  loss: %s', 67, 'TRAIN', 609.9443969726562)\n",
      "('epoch: %s %s  loss: %s', 68, 'TRAIN', 933.3584594726562)\n",
      "('epoch: %s %s  loss: %s', 69, 'TRAIN', 1487.593505859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4018012583255768\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9260563254356384\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9179577469825745\n",
      "Best validation accuracy (AVG): 0.9345070362091065\n",
      "('epoch: %s %s  loss: %s', 70, 'TRAIN', 2173.544677734375)\n",
      "('epoch: %s %s  loss: %s', 71, 'TRAIN', 2613.51220703125)\n",
      "('epoch: %s %s  loss: %s', 72, 'TRAIN', 2917.715576171875)\n",
      "('epoch: %s %s  loss: %s', 73, 'TRAIN', 4939.7509765625)\n",
      "('epoch: %s %s  loss: %s', 74, 'TRAIN', 25576.416015625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.283138394355774\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9154929518699646\n",
      "Best training accuracy (AVG): 0.9190140962600708\n",
      "Best validation accuracy (AVG): 0.9112675786018372\n",
      "('epoch: %s %s  loss: %s', 75, 'TRAIN', 51851.1640625)\n",
      "('epoch: %s %s  loss: %s', 76, 'TRAIN', 24805.29296875)\n",
      "('epoch: %s %s  loss: %s', 77, 'TRAIN', 9082.0244140625)\n",
      "('epoch: %s %s  loss: %s', 78, 'TRAIN', 4245.744140625)\n",
      "('epoch: %s %s  loss: %s', 79, 'TRAIN', 2798.077880859375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.4115046560764313\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9281690061092377\n",
      "Best validation accuracy (AVG): 0.9457746207714081\n",
      "('epoch: %s %s  loss: %s', 80, 'TRAIN', 2317.0)\n",
      "('epoch: %s %s  loss: %s', 81, 'TRAIN', 2167.875732421875)\n",
      "('epoch: %s %s  loss: %s', 82, 'TRAIN', 1890.98193359375)\n",
      "('epoch: %s %s  loss: %s', 83, 'TRAIN', 1495.304931640625)\n",
      "('epoch: %s %s  loss: %s', 84, 'TRAIN', 1119.5213623046875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.32157325744628906\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.933098554611206\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9316901206970215\n",
      "Best validation accuracy (AVG): 0.9528168857097625\n",
      "('epoch: %s %s  loss: %s', 85, 'TRAIN', 320.6230163574219)\n",
      "('epoch: %s %s  loss: %s', 86, 'TRAIN', -9.726250648498535)\n",
      "('epoch: %s %s  loss: %s', 87, 'TRAIN', -213.51168823242188)\n",
      "('epoch: %s %s  loss: %s', 88, 'TRAIN', -413.31182861328125)\n",
      "('epoch: %s %s  loss: %s', 89, 'TRAIN', -594.378173828125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.2702801525592804\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9401408433914185\n",
      "Best validation accuracy: 0.9577464461326599\n",
      "Best training accuracy (AVG): 0.9352112412452698\n",
      "Best validation accuracy (AVG): 0.9521126627922059\n",
      "('epoch: %s %s  loss: %s', 90, 'TRAIN', -456.505126953125)\n",
      "('epoch: %s %s  loss: %s', 91, 'TRAIN', -214.19622802734375)\n",
      "('epoch: %s %s  loss: %s', 92, 'TRAIN', -140.62879943847656)\n",
      "('epoch: %s %s  loss: %s', 93, 'TRAIN', 55.815940856933594)\n",
      "('epoch: %s %s  loss: %s', 94, 'TRAIN', 150.83668518066406)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.36016809940338135\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9366196990013123\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9327464520931243\n",
      "Best validation accuracy (AVG): 0.9485915303230286\n",
      "('epoch: %s %s  loss: %s', 95, 'TRAIN', 216.40147399902344)\n",
      "('epoch: %s %s  loss: %s', 96, 'TRAIN', 246.555908203125)\n",
      "('epoch: %s %s  loss: %s', 97, 'TRAIN', 266.6630554199219)\n",
      "('epoch: %s %s  loss: %s', 98, 'TRAIN', 257.8896789550781)\n",
      "('epoch: %s %s  loss: %s', 99, 'TRAIN', 229.7296142578125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.5370984077453613\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9295774698257446\n",
      "Best validation accuracy: 0.9507042169570923\n",
      "Best training accuracy (AVG): 0.9271126687526703\n",
      "Best validation accuracy (AVG): 0.9422534942626953\n",
      "('epoch: %s %s  loss: %s', 100, 'TRAIN', 228.4468231201172)\n",
      "('epoch: %s %s  loss: %s', 101, 'TRAIN', 202.92263793945312)\n",
      "('epoch: %s %s  loss: %s', 102, 'TRAIN', 191.00228881835938)\n",
      "('epoch: %s %s  loss: %s', 103, 'TRAIN', 177.77381896972656)\n",
      "('epoch: %s %s  loss: %s', 104, 'TRAIN', 178.94869995117188)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.7897449135780334\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9190140962600708\n",
      "Best validation accuracy: 0.9366196990013123\n",
      "Best training accuracy (AVG): 0.9147887229919434\n",
      "Best validation accuracy (AVG): 0.9338028073310852\n",
      "('epoch: %s %s  loss: %s', 105, 'TRAIN', 182.75035095214844)\n",
      "('epoch: %s %s  loss: %s', 106, 'TRAIN', 205.56710815429688)\n",
      "('epoch: %s %s  loss: %s', 107, 'TRAIN', 287.31768798828125)\n",
      "('epoch: %s %s  loss: %s', 108, 'TRAIN', 430.60076904296875)\n",
      "('epoch: %s %s  loss: %s', 109, 'TRAIN', 664.3212890625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0362308025360107\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8908450603485107\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8908450603485107\n",
      "Best validation accuracy (AVG): 0.9295774698257446\n",
      "('epoch: %s %s  loss: %s', 110, 'TRAIN', 992.321044921875)\n",
      "('epoch: %s %s  loss: %s', 111, 'TRAIN', 1390.9625244140625)\n",
      "('epoch: %s %s  loss: %s', 112, 'TRAIN', 1779.58447265625)\n",
      "('epoch: %s %s  loss: %s', 113, 'TRAIN', 2027.6669921875)\n",
      "('epoch: %s %s  loss: %s', 114, 'TRAIN', 2129.946533203125)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0628697872161865\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8802816867828369\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8799295723438263\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 115, 'TRAIN', 2029.5113525390625)\n",
      "('epoch: %s %s  loss: %s', 116, 'TRAIN', 1790.9896240234375)\n",
      "('epoch: %s %s  loss: %s', 117, 'TRAIN', 1499.7041015625)\n",
      "('epoch: %s %s  loss: %s', 118, 'TRAIN', 1202.0272216796875)\n",
      "('epoch: %s %s  loss: %s', 119, 'TRAIN', 937.6521606445312)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 0.9969098567962646\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8873239159584045\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8816901266574859\n",
      "Best validation accuracy (AVG): 0.9218309640884399\n",
      "('epoch: %s %s  loss: %s', 120, 'TRAIN', 711.4417724609375)\n",
      "('epoch: %s %s  loss: %s', 121, 'TRAIN', 532.7122802734375)\n",
      "('epoch: %s %s  loss: %s', 122, 'TRAIN', 440.6621398925781)\n",
      "('epoch: %s %s  loss: %s', 123, 'TRAIN', 373.7834167480469)\n",
      "('epoch: %s %s  loss: %s', 124, 'TRAIN', 314.8752746582031)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0464752912521362\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8908450603485107\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8855633437633514\n",
      "Best validation accuracy (AVG): 0.924647867679596\n",
      "('epoch: %s %s  loss: %s', 125, 'TRAIN', 257.7622375488281)\n",
      "('epoch: %s %s  loss: %s', 126, 'TRAIN', 213.19210815429688)\n",
      "('epoch: %s %s  loss: %s', 127, 'TRAIN', 179.65158081054688)\n",
      "('epoch: %s %s  loss: %s', 128, 'TRAIN', 146.34486389160156)\n",
      "('epoch: %s %s  loss: %s', 129, 'TRAIN', 115.49503326416016)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0482127666473389\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8919013977050781\n",
      "Best validation accuracy (AVG): 0.9267605543136597\n",
      "('epoch: %s %s  loss: %s', 130, 'TRAIN', 91.93798065185547)\n",
      "('epoch: %s %s  loss: %s', 131, 'TRAIN', 70.54795837402344)\n",
      "('epoch: %s %s  loss: %s', 132, 'TRAIN', 55.816551208496094)\n",
      "('epoch: %s %s  loss: %s', 133, 'TRAIN', 47.26457977294922)\n",
      "('epoch: %s %s  loss: %s', 134, 'TRAIN', 33.41145324707031)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0490268468856812\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8947183132171631\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 135, 'TRAIN', 25.69951629638672)\n",
      "('epoch: %s %s  loss: %s', 136, 'TRAIN', 13.359285354614258)\n",
      "('epoch: %s %s  loss: %s', 137, 'TRAIN', 7.785900115966797)\n",
      "('epoch: %s %s  loss: %s', 138, 'TRAIN', 2.704071044921875)\n",
      "('epoch: %s %s  loss: %s', 139, 'TRAIN', 3.5775210857391357)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.049163579940796\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 140, 'TRAIN', -2.852900505065918)\n",
      "('epoch: %s %s  loss: %s', 141, 'TRAIN', 0.2746028006076813)\n",
      "('epoch: %s %s  loss: %s', 142, 'TRAIN', -2.7671988010406494)\n",
      "('epoch: %s %s  loss: %s', 143, 'TRAIN', -4.6938252449035645)\n",
      "('epoch: %s %s  loss: %s', 144, 'TRAIN', -3.437258005142212)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0524753332138062\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 145, 'TRAIN', -6.7543439865112305)\n",
      "('epoch: %s %s  loss: %s', 146, 'TRAIN', -3.230734348297119)\n",
      "('epoch: %s %s  loss: %s', 147, 'TRAIN', -3.308573007583618)\n",
      "('epoch: %s %s  loss: %s', 148, 'TRAIN', 1.2902426719665527)\n",
      "('epoch: %s %s  loss: %s', 149, 'TRAIN', 2.498037815093994)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.056742548942566\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 150, 'TRAIN', -0.9968319535255432)\n",
      "('epoch: %s %s  loss: %s', 151, 'TRAIN', 3.1956429481506348)\n",
      "('epoch: %s %s  loss: %s', 152, 'TRAIN', 5.924002170562744)\n",
      "('epoch: %s %s  loss: %s', 153, 'TRAIN', 4.979910373687744)\n",
      "('epoch: %s %s  loss: %s', 154, 'TRAIN', 6.847555160522461)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0616223812103271\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 155, 'TRAIN', 7.883300304412842)\n",
      "('epoch: %s %s  loss: %s', 156, 'TRAIN', 13.35019302368164)\n",
      "('epoch: %s %s  loss: %s', 157, 'TRAIN', 7.27255916595459)\n",
      "('epoch: %s %s  loss: %s', 158, 'TRAIN', 11.06466293334961)\n",
      "('epoch: %s %s  loss: %s', 159, 'TRAIN', 10.350281715393066)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0649126768112183\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 160, 'TRAIN', 9.218363761901855)\n",
      "('epoch: %s %s  loss: %s', 161, 'TRAIN', 8.540444374084473)\n",
      "('epoch: %s %s  loss: %s', 162, 'TRAIN', 6.191084861755371)\n",
      "('epoch: %s %s  loss: %s', 163, 'TRAIN', 5.447905540466309)\n",
      "('epoch: %s %s  loss: %s', 164, 'TRAIN', 3.548241376876831)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0664160251617432\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 165, 'TRAIN', 1.4080578088760376)\n",
      "('epoch: %s %s  loss: %s', 166, 'TRAIN', 0.19749610126018524)\n",
      "('epoch: %s %s  loss: %s', 167, 'TRAIN', -4.391152858734131)\n",
      "('epoch: %s %s  loss: %s', 168, 'TRAIN', -7.870731353759766)\n",
      "('epoch: %s %s  loss: %s', 169, 'TRAIN', -6.0526509284973145)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0676683187484741\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8947183132171631\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 170, 'TRAIN', -5.727319717407227)\n",
      "('epoch: %s %s  loss: %s', 171, 'TRAIN', -4.551207542419434)\n",
      "('epoch: %s %s  loss: %s', 172, 'TRAIN', -2.5166122913360596)\n",
      "('epoch: %s %s  loss: %s', 173, 'TRAIN', -1.8445662260055542)\n",
      "('epoch: %s %s  loss: %s', 174, 'TRAIN', -0.8450121283531189)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0573984384536743\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8943661987781525\n",
      "Best validation accuracy (AVG): 0.924647867679596\n",
      "('epoch: %s %s  loss: %s', 175, 'TRAIN', -4.794553756713867)\n",
      "('epoch: %s %s  loss: %s', 176, 'TRAIN', -4.5153679847717285)\n",
      "('epoch: %s %s  loss: %s', 177, 'TRAIN', -6.852210521697998)\n",
      "('epoch: %s %s  loss: %s', 178, 'TRAIN', -7.156404495239258)\n",
      "('epoch: %s %s  loss: %s', 179, 'TRAIN', -13.508199691772461)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0712840557098389\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8947183072566987\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 180, 'TRAIN', -11.535240173339844)\n",
      "('epoch: %s %s  loss: %s', 181, 'TRAIN', -14.702764511108398)\n",
      "('epoch: %s %s  loss: %s', 182, 'TRAIN', -21.228559494018555)\n",
      "('epoch: %s %s  loss: %s', 183, 'TRAIN', -23.278423309326172)\n",
      "('epoch: %s %s  loss: %s', 184, 'TRAIN', -27.833166122436523)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0741162300109863\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8947183072566987\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 185, 'TRAIN', -27.51828956604004)\n",
      "('epoch: %s %s  loss: %s', 186, 'TRAIN', -28.514347076416016)\n",
      "('epoch: %s %s  loss: %s', 187, 'TRAIN', -34.6743049621582)\n",
      "('epoch: %s %s  loss: %s', 188, 'TRAIN', -34.71807098388672)\n",
      "('epoch: %s %s  loss: %s', 189, 'TRAIN', -36.017154693603516)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0746532678604126\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 190, 'TRAIN', -39.18315124511719)\n",
      "('epoch: %s %s  loss: %s', 191, 'TRAIN', -40.89523696899414)\n",
      "('epoch: %s %s  loss: %s', 192, 'TRAIN', -46.26215744018555)\n",
      "('epoch: %s %s  loss: %s', 193, 'TRAIN', -45.21161651611328)\n",
      "('epoch: %s %s  loss: %s', 194, 'TRAIN', -45.80502700805664)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0760300159454346\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 195, 'TRAIN', -49.727203369140625)\n",
      "('epoch: %s %s  loss: %s', 196, 'TRAIN', -45.74632263183594)\n",
      "('epoch: %s %s  loss: %s', 197, 'TRAIN', -46.44893264770508)\n",
      "('epoch: %s %s  loss: %s', 198, 'TRAIN', -51.069889068603516)\n",
      "('epoch: %s %s  loss: %s', 199, 'TRAIN', -51.72874069213867)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0743390321731567\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 200, 'TRAIN', -54.14789962768555)\n",
      "('epoch: %s %s  loss: %s', 201, 'TRAIN', -56.2209358215332)\n",
      "('epoch: %s %s  loss: %s', 202, 'TRAIN', -52.50811004638672)\n",
      "('epoch: %s %s  loss: %s', 203, 'TRAIN', -60.169281005859375)\n",
      "('epoch: %s %s  loss: %s', 204, 'TRAIN', -60.444515228271484)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0645980834960938\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 205, 'TRAIN', -64.87080383300781)\n",
      "('epoch: %s %s  loss: %s', 206, 'TRAIN', -63.04404830932617)\n",
      "('epoch: %s %s  loss: %s', 207, 'TRAIN', -65.19588470458984)\n",
      "('epoch: %s %s  loss: %s', 208, 'TRAIN', -69.00242614746094)\n",
      "('epoch: %s %s  loss: %s', 209, 'TRAIN', -66.06568908691406)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.05192232131958\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.895774644613266\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 210, 'TRAIN', -67.94799041748047)\n",
      "('epoch: %s %s  loss: %s', 211, 'TRAIN', -72.11792755126953)\n",
      "('epoch: %s %s  loss: %s', 212, 'TRAIN', -73.37201690673828)\n",
      "('epoch: %s %s  loss: %s', 213, 'TRAIN', -74.50479125976562)\n",
      "('epoch: %s %s  loss: %s', 214, 'TRAIN', -76.7586669921875)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0404906272888184\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.895774644613266\n",
      "Best validation accuracy (AVG): 0.924647867679596\n",
      "('epoch: %s %s  loss: %s', 215, 'TRAIN', -75.3467788696289)\n",
      "('epoch: %s %s  loss: %s', 216, 'TRAIN', -77.26789855957031)\n",
      "('epoch: %s %s  loss: %s', 217, 'TRAIN', -78.13844299316406)\n",
      "('epoch: %s %s  loss: %s', 218, 'TRAIN', -81.46065521240234)\n",
      "('epoch: %s %s  loss: %s', 219, 'TRAIN', -80.80449676513672)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0292925834655762\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8961267590522766\n",
      "Best validation accuracy (AVG): 0.924647867679596\n",
      "('epoch: %s %s  loss: %s', 220, 'TRAIN', -81.61846160888672)\n",
      "('epoch: %s %s  loss: %s', 221, 'TRAIN', -86.04326629638672)\n",
      "('epoch: %s %s  loss: %s', 222, 'TRAIN', -82.26900482177734)\n",
      "('epoch: %s %s  loss: %s', 223, 'TRAIN', -81.8107681274414)\n",
      "('epoch: %s %s  loss: %s', 224, 'TRAIN', -77.2440414428711)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0833333730697632\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8957746386528015\n",
      "Best validation accuracy (AVG): 0.9239436388015747\n",
      "('epoch: %s %s  loss: %s', 225, 'TRAIN', -72.83979034423828)\n",
      "('epoch: %s %s  loss: %s', 226, 'TRAIN', -72.99999237060547)\n",
      "('epoch: %s %s  loss: %s', 227, 'TRAIN', -68.05060577392578)\n",
      "('epoch: %s %s  loss: %s', 228, 'TRAIN', -64.6341323852539)\n",
      "('epoch: %s %s  loss: %s', 229, 'TRAIN', -64.87403869628906)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.1233981847763062\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8957746386528015\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 230, 'TRAIN', -62.14822769165039)\n",
      "('epoch: %s %s  loss: %s', 231, 'TRAIN', -62.1305046081543)\n",
      "('epoch: %s %s  loss: %s', 232, 'TRAIN', -59.807106018066406)\n",
      "('epoch: %s %s  loss: %s', 233, 'TRAIN', -59.75279235839844)\n",
      "('epoch: %s %s  loss: %s', 234, 'TRAIN', -61.12493896484375)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.1247340440750122\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8954225361347199\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 235, 'TRAIN', -63.03095626831055)\n",
      "('epoch: %s %s  loss: %s', 236, 'TRAIN', -64.0005874633789)\n",
      "('epoch: %s %s  loss: %s', 237, 'TRAIN', -61.465946197509766)\n",
      "('epoch: %s %s  loss: %s', 238, 'TRAIN', -57.131996154785156)\n",
      "('epoch: %s %s  loss: %s', 239, 'TRAIN', -54.71390151977539)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.1276534795761108\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 240, 'TRAIN', -53.118492126464844)\n",
      "('epoch: %s %s  loss: %s', 241, 'TRAIN', -54.188899993896484)\n",
      "('epoch: %s %s  loss: %s', 242, 'TRAIN', -54.90049362182617)\n",
      "('epoch: %s %s  loss: %s', 243, 'TRAIN', -52.18775177001953)\n",
      "('epoch: %s %s  loss: %s', 244, 'TRAIN', -56.77586364746094)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.1276532411575317\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8947183132171631\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 245, 'TRAIN', -51.9869499206543)\n",
      "('epoch: %s %s  loss: %s', 246, 'TRAIN', -59.97444152832031)\n",
      "('epoch: %s %s  loss: %s', 247, 'TRAIN', -59.94676208496094)\n",
      "('epoch: %s %s  loss: %s', 248, 'TRAIN', -63.68613052368164)\n",
      "('epoch: %s %s  loss: %s', 249, 'TRAIN', -63.30321502685547)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.1011347770690918\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.8978872895240784\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8950704216957093\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 250, 'TRAIN', -66.49729919433594)\n",
      "('epoch: %s %s  loss: %s', 251, 'TRAIN', -67.63249969482422)\n",
      "('epoch: %s %s  loss: %s', 252, 'TRAIN', -74.40760040283203)\n",
      "('epoch: %s %s  loss: %s', 253, 'TRAIN', -75.8288345336914)\n",
      "('epoch: %s %s  loss: %s', 254, 'TRAIN', -76.4602279663086)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0906941890716553\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.895774644613266\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 255, 'TRAIN', -81.55899047851562)\n",
      "('epoch: %s %s  loss: %s', 256, 'TRAIN', -82.45829010009766)\n",
      "('epoch: %s %s  loss: %s', 257, 'TRAIN', -84.82679748535156)\n",
      "('epoch: %s %s  loss: %s', 258, 'TRAIN', -90.61913299560547)\n",
      "('epoch: %s %s  loss: %s', 259, 'TRAIN', -93.03227996826172)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0932625532150269\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9014084339141846\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.895774644613266\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 260, 'TRAIN', -96.20044708251953)\n",
      "('epoch: %s %s  loss: %s', 261, 'TRAIN', -97.34434509277344)\n",
      "('epoch: %s %s  loss: %s', 262, 'TRAIN', -102.36964416503906)\n",
      "('epoch: %s %s  loss: %s', 263, 'TRAIN', -101.76535034179688)\n",
      "('epoch: %s %s  loss: %s', 264, 'TRAIN', -103.29035186767578)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0919729471206665\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9049295783042908\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.8975352108478546\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 265, 'TRAIN', -104.23384857177734)\n",
      "('epoch: %s %s  loss: %s', 266, 'TRAIN', -109.0016098022461)\n",
      "('epoch: %s %s  loss: %s', 267, 'TRAIN', -108.8517074584961)\n",
      "('epoch: %s %s  loss: %s', 268, 'TRAIN', -110.46044158935547)\n",
      "('epoch: %s %s  loss: %s', 269, 'TRAIN', -112.1988525390625)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0933843851089478\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9049295783042908\n",
      "Best validation accuracy: 0.9295774698257446\n",
      "Best training accuracy (AVG): 0.897183096408844\n",
      "Best validation accuracy (AVG): 0.9232394099235535\n",
      "('epoch: %s %s  loss: %s', 270, 'TRAIN', -115.76327514648438)\n",
      "('epoch: %s %s  loss: %s', 271, 'TRAIN', -115.52093505859375)\n",
      "('epoch: %s %s  loss: %s', 272, 'TRAIN', -118.02603912353516)\n",
      "('epoch: %s %s  loss: %s', 273, 'TRAIN', -119.52941131591797)\n",
      "('epoch: %s %s  loss: %s', 274, 'TRAIN', -121.58676147460938)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0945980548858643\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9049295783042908\n",
      "Best validation accuracy: 0.9225351810455322\n",
      "Best training accuracy (AVG): 0.8968309819698334\n",
      "Best validation accuracy (AVG): 0.9225351810455322\n",
      "('epoch: %s %s  loss: %s', 275, 'TRAIN', -120.9687728881836)\n",
      "('epoch: %s %s  loss: %s', 276, 'TRAIN', -125.43215942382812)\n",
      "('epoch: %s %s  loss: %s', 277, 'TRAIN', -127.17877197265625)\n",
      "('epoch: %s %s  loss: %s', 278, 'TRAIN', -124.39127349853516)\n",
      "('epoch: %s %s  loss: %s', 279, 'TRAIN', -121.01505279541016)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.1127347946166992\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9049295783042908\n",
      "Best validation accuracy: 0.9225351810455322\n",
      "Best training accuracy (AVG): 0.8968309879302978\n",
      "Best validation accuracy (AVG): 0.9225351810455322\n",
      "('epoch: %s %s  loss: %s', 280, 'TRAIN', -118.00493621826172)\n",
      "('epoch: %s %s  loss: %s', 281, 'TRAIN', -115.22245788574219)\n",
      "('epoch: %s %s  loss: %s', 282, 'TRAIN', -112.0151596069336)\n",
      "('epoch: %s %s  loss: %s', 283, 'TRAIN', -109.48723602294922)\n",
      "('epoch: %s %s  loss: %s', 284, 'TRAIN', -109.08633422851562)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0636579990386963\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9084506630897522\n",
      "Best validation accuracy: 0.9225351810455322\n",
      "Best training accuracy (AVG): 0.8968309819698334\n",
      "Best validation accuracy (AVG): 0.9225351810455322\n",
      "('epoch: %s %s  loss: %s', 285, 'TRAIN', -106.66809844970703)\n",
      "('epoch: %s %s  loss: %s', 286, 'TRAIN', -103.7003173828125)\n",
      "('epoch: %s %s  loss: %s', 287, 'TRAIN', -103.9937515258789)\n",
      "('epoch: %s %s  loss: %s', 288, 'TRAIN', -101.02104949951172)\n",
      "('epoch: %s %s  loss: %s', 289, 'TRAIN', -99.08861541748047)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.083821177482605\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9084506630897522\n",
      "Best validation accuracy: 0.9225351810455322\n",
      "Best training accuracy (AVG): 0.8961267590522766\n",
      "Best validation accuracy (AVG): 0.9225351810455322\n",
      "('epoch: %s %s  loss: %s', 290, 'TRAIN', -100.24664306640625)\n",
      "('epoch: %s %s  loss: %s', 291, 'TRAIN', -99.52574157714844)\n",
      "('epoch: %s %s  loss: %s', 292, 'TRAIN', -95.28128814697266)\n",
      "('epoch: %s %s  loss: %s', 293, 'TRAIN', -97.14907836914062)\n",
      "('epoch: %s %s  loss: %s', 294, 'TRAIN', -95.73258209228516)\n",
      "Best training loss: 1.1920928955078125e-07\n",
      "Best validation loss: 1.0565519332885742\n",
      "1000\n",
      "1000\n",
      "Best training accuracy: 0.9084506630897522\n",
      "Best validation accuracy: 0.9225351810455322\n",
      "Best training accuracy (AVG): 0.8964788675308227\n",
      "Best validation accuracy (AVG): 0.9225351810455322\n",
      "('epoch: %s %s  loss: %s', 295, 'TRAIN', -97.59830474853516)\n",
      "('epoch: %s %s  loss: %s', 296, 'TRAIN', -98.65582275390625)\n",
      "('epoch: %s %s  loss: %s', 297, 'TRAIN', -102.16781616210938)\n",
      "('epoch: %s %s  loss: %s', 298, 'TRAIN', -99.05570983886719)\n",
      "('epoch: %s %s  loss: %s', 299, 'TRAIN', -101.69935607910156)\n",
      "WITH VAL\n",
      "Test Accuracy: 0.8951048851013184\n",
      "Test Accuracy (AVG): 0.9160839319229126\n",
      "WITH TRAIN\n",
      "Test Accuracy: 0.9160839319229126\n",
      "Test Accuracy (AVG): 0.9230769276618958\n",
      "('epoch: %s %s  loss: %s', 0, 'TRAIN', -101.25106048583984)\n",
      "('epoch: %s %s  loss: %s', 1, 'TRAIN', -103.38646697998047)\n",
      "('epoch: %s %s  loss: %s', 2, 'TRAIN', -101.68094635009766)\n",
      "('epoch: %s %s  loss: %s', 3, 'TRAIN', -103.14183044433594)\n",
      "('epoch: %s %s  loss: %s', 4, 'TRAIN', -101.82138061523438)\n",
      "('epoch: %s %s  loss: %s', 5, 'TRAIN', -101.24266052246094)\n",
      "('epoch: %s %s  loss: %s', 6, 'TRAIN', -103.9299087524414)\n",
      "('epoch: %s %s  loss: %s', 7, 'TRAIN', -100.71778106689453)\n",
      "('epoch: %s %s  loss: %s', 8, 'TRAIN', -99.05381774902344)\n",
      "('epoch: %s %s  loss: %s', 9, 'TRAIN', -102.30679321289062)\n",
      "('epoch: %s %s  loss: %s', 10, 'TRAIN', -101.29263305664062)\n",
      "('epoch: %s %s  loss: %s', 11, 'TRAIN', -105.36414337158203)\n",
      "('epoch: %s %s  loss: %s', 12, 'TRAIN', -99.94220733642578)\n",
      "('epoch: %s %s  loss: %s', 13, 'TRAIN', -101.57783508300781)\n",
      "('epoch: %s %s  loss: %s', 14, 'TRAIN', -102.34861755371094)\n",
      "('epoch: %s %s  loss: %s', 15, 'TRAIN', -99.19942474365234)\n",
      "('epoch: %s %s  loss: %s', 16, 'TRAIN', -102.79594421386719)\n",
      "('epoch: %s %s  loss: %s', 17, 'TRAIN', -99.16930389404297)\n",
      "('epoch: %s %s  loss: %s', 18, 'TRAIN', -103.49829864501953)\n",
      "('epoch: %s %s  loss: %s', 19, 'TRAIN', -98.93840789794922)\n",
      "('epoch: %s %s  loss: %s', 20, 'TRAIN', -99.49192810058594)\n",
      "('epoch: %s %s  loss: %s', 21, 'TRAIN', -98.36311340332031)\n",
      "('epoch: %s %s  loss: %s', 22, 'TRAIN', -101.0255355834961)\n",
      "('epoch: %s %s  loss: %s', 23, 'TRAIN', -103.11685180664062)\n",
      "('epoch: %s %s  loss: %s', 24, 'TRAIN', -103.91903686523438)\n",
      "('epoch: %s %s  loss: %s', 25, 'TRAIN', -102.05461120605469)\n",
      "('epoch: %s %s  loss: %s', 26, 'TRAIN', -101.69953155517578)\n",
      "('epoch: %s %s  loss: %s', 27, 'TRAIN', -101.98225402832031)\n",
      "('epoch: %s %s  loss: %s', 28, 'TRAIN', -103.96214294433594)\n",
      "('epoch: %s %s  loss: %s', 29, 'TRAIN', -102.54840850830078)\n"
     ]
    }
   ],
   "source": [
    "funnel_config.trainer.epochs = 300\n",
    "tl_lists = []\n",
    "vl_lists = []\n",
    "ta_lists = []\n",
    "va_lists = []\n",
    "out_dicts1 = []\n",
    "task = \"breastcancer\"\n",
    "for div in [1, 0.5, 0.2]:\n",
    "    funnel_config = set_task(funnel_config, task, div, c)\n",
    "    funnel_config.model.input_dim = 171\n",
    "    out_dict = train_dds(funnel_config)\n",
    "    out_dicts1.append(out_dict)\n",
    "    tl_lists.append([x.item() for x in out_dict[-1][\"training_loss\"]])\n",
    "    vl_lists.append([x.item() for x in out_dict[-1][\"validation_loss\"]])\n",
    "    ta_lists.append([x.item() for x in out_dict[-1][\"training_acc\"]])\n",
    "    va_lists.append([x.item() for x in out_dict[-1][\"validation_acc\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T04:40:52.171784Z",
     "end_time": "2023-05-06T07:16:39.528815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9225351810455322, 0.9401408433914185, 0.933098554611206, 0.9401408433914185, 0.933098554611206, 0.9295774698257446, 0.933098554611206, 0.9366196990013123, 0.933098554611206, 0.9401408433914185, 0.9190140962600708, 0.9190140962600708, 0.9401408433914185, 0.9436619281768799, 0.9436619281768799, 0.9401408433914185, 0.9436619281768799, 0.9436619281768799, 0.9401408433914185, 0.9401408433914185, 0.9366196990013123, 0.9366196990013123, 0.933098554611206, 0.933098554611206, 0.9295774698257446, 0.9260563254356384, 0.9225351810455322, 0.9295774698257446, 0.9295774698257446, 0.9295774698257446, 0.9295774698257446, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9436619281768799, 0.9436619281768799, 0.9436619281768799, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9401408433914185, 0.9366196990013123], [0.9190140962600708, 0.9401408433914185, 0.9401408433914185, 0.9436619281768799, 0.9260563254356384, 0.9225351810455322, 0.9366196990013123, 0.933098554611206, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9366196990013123, 0.9084506630897522, 0.9190140962600708, 0.9225351810455322, 0.9260563254356384, 0.933098554611206, 0.933098554611206, 0.933098554611206, 0.933098554611206, 0.933098554611206, 0.9260563254356384, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9225351810455322, 0.9190140962600708, 0.9190140962600708, 0.9225351810455322, 0.9225351810455322, 0.9190140962600708, 0.9190140962600708, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9190140962600708, 0.9190140962600708, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9154929518699646, 0.9119718074798584, 0.9119718074798584, 0.9119718074798584], [0.9154929518699646, 0.9366196990013123, 0.933098554611206, 0.9366196990013123, 0.9366196990013123, 0.9014084339141846, 0.8873239159584045, 0.8767605423927307, 0.8661971688270569, 0.8732393980026245, 0.8732393980026245, 0.8802816867828369, 0.8802816867828369, 0.9014084339141846, 0.9260563254356384, 0.9190140962600708, 0.933098554611206, 0.933098554611206, 0.9401408433914185, 0.9366196990013123, 0.9295774698257446, 0.9190140962600708, 0.8908450603485107, 0.8802816867828369, 0.8873239159584045, 0.8908450603485107, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.9014084339141846, 0.9014084339141846, 0.9014084339141846, 0.8978872895240784, 0.8978872895240784, 0.9014084339141846, 0.8978872895240784, 0.8978872895240784, 0.8978872895240784, 0.9014084339141846, 0.9014084339141846, 0.9049295783042908, 0.9049295783042908, 0.9049295783042908, 0.9049295783042908, 0.9084506630897522, 0.9084506630897522, 0.9084506630897522]]\n"
     ]
    }
   ],
   "source": [
    "print(ta_lists)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T01:51:52.029363Z",
     "end_time": "2023-05-09T01:51:52.052414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x14e19d240>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the lists\n",
    "labels = [\"σ = 1\", \"σ = 0.5\", \"σ = 0.2\"]#, \"10\", \"15\", \"20\"]\n",
    "colors = [\"blue\", \"orange\", \"green\"]#, \"red\", \"purple\", \"yellow\"]\n",
    "\n",
    "# Plot the data\n",
    "xax = range(1,301,2)\n",
    "# for i, (acc, label, color) in enumerate(zip(va_lists, labels, colors)):\n",
    "#     plt.plot(xax,acc, label=label, color=color)\n",
    "\n",
    "for i, (acc, label, color) in enumerate(zip(ta_lists, labels, colors)):\n",
    "    plt.plot(xax,acc, label=label, color=color)\n",
    "\n",
    "# Add a horizontal line at y = -1\n",
    "#plt.axhline(y=-0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Add labels and legend\n",
    "#plt.yscale('log')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Breast cancer mini-batch accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# print(len(va_lists[0]))\n",
    "#\n",
    "# SNOOP = [1, 3, 6, 30, 60]\n",
    "# for idx in SNOOP:\n",
    "#     for i in (ta_lists):\n",
    "#         k = i\n",
    "#         k = sorted(k, reverse=True)\n",
    "#         print(sum(k[:idx])/idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T12:12:25.742047Z",
     "end_time": "2023-05-14T12:12:26.171822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9436619281768799, 0.9577464461326599], [0.9507042169570923, 0.9647887349128723]]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T04:40:08.135071Z",
     "end_time": "2023-05-06T04:40:08.140915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x139dd8af0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Combine the lists\n",
    "labels = [\"1\", \"0.5\", \"0.2\"]#, \"10\", \"15\", \"20\"]\n",
    "colors = [\"blue\", \"orange\", \"green\"]#, \"red\", \"purple\", \"yellow\"]\n",
    "d_list = [np.array(out_dicts1[0][-1][\"elbo\"])+100000, np.array(out_dicts1[1][-1][\"elbo\"])+100000, np.array(out_dicts1[2][-1][\"elbo\"])+100000]\n",
    "# Plot the data\n",
    "for i, (acc, label, color) in enumerate(zip(d_list, labels, colors)):\n",
    "    plt.plot(acc, label=label, color=color)\n",
    "\n",
    "# Add a horizontal line at y = -1\n",
    "plt.axhline(y=-0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Breast cancer mini-batch ELBO loss\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T00:17:03.845713Z",
     "end_time": "2023-05-14T00:17:04.155465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHBCAYAAABzIlFzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvzElEQVR4nO3deXgUVfo24Kd6S9IhECAsoijI5oJA2AIKIps4CDoii4p8jvNTdKIgjKIgM4oLisuIrIooKIqIsigqo6MzCqjIoiiOMygyCiiCJCFkTy9V3x/dVV1VXdVdHdLdSfq5r8vL7srp6pNDk7y85z3nCJIkSSAiIiKqh2zJ7gARERFRTTGQISIionqLgQwRERHVWwxkiIiIqN5iIENERET1FgMZIiIiqrcYyBAREVG9xUCGiIiI6i0GMkSUcNyHk4hqCwMZqpMmTZqESZMmJbsbpjZv3ozBgwfjggsuwH333ZeQ95w5cyaGDBmiPNeP0ffff4+rrroKXbt2xciRI+Hz+TBr1iz07NkTPXv2xOeff56Qfkbzww8/4Nprr63Ra4cMGYKZM2cqz7t06YJFixbVVtfibtGiRejSpUuyu1Fneb1ejBs3zvDPtKysDPfddx8uuugi9OjRAzfeeCN++OGHsHYrV67EsGHDcMEFF+DKK6/Ehx9+mIiuUxI5kt0BovrogQceQLt27TBv3jy0atUqKX24//77Nc8XL16MX375BYsXL0bz5s2xbds2bNiwAfn5+bjwwgtx3nnnJaWfen//+9+xZ8+eWrnX2rVr0bp161q5VyKMGzcOAwcOTHY36qSqqirMmDEDe/fuxcUXXxz29TvvvBN79+7FjBkz0KhRIyxevBg33HAD3n33XWRnZwMAnn/+eTz11FO47bbb0LVrV6xfvx5Tp07FSy+9hD59+iT4O6JEYSBDVAPFxcW46KKLkJeXl7Q+dOzYUfP8xIkT6Ny5My655BIAwMaNGwEAY8aMQdu2bRPdvYTo0aNHsrsQk9atW9erwCtRdu/ejQceeAC//fab4df37NmDjz/+GM899xwGDRoEAOjduzeGDh2KV199Ffn5+aiqqsKyZcvwhz/8AbfddhsA4OKLL8Y111yDJUuW4MUXX0zUt0MJxqklqtc+/fRTXHfddejVqxfy8vJw55134tdff1W+LooiFixYgCFDhqBr164YMmQInnrqKXi9XqXN5s2bccUVV6Bbt27o168f7rrrLtMfqDt27FCmBpYsWYIuXbrg559/ttSXDRs24LzzzsMbb7yBAQMG4OKLL8b+/fsN3+fkyZOYNWsW8vLy0KdPHzzxxBMQRVHTRj211KVLF+zcuRO7du1Cly5dNFMww4YNU9qJoojnnnsOw4cPR9euXTFixAi8/PLLYfe96667MHXqVPTs2ROTJ08GAFRXV+Pxxx/HoEGD0LVrV4wePRqbN2/WvHbIkCFYuHAhHnvsMVx44YXo1q0b/u///g8//vgjgMDUyuLFi5U+R5oW2rdvH2688Ubk5uZi8ODB2LRpU1gb9T3kP5vt27dj0qRJ6NatGy655BK88cYb+O2333D77bcjNzcXgwYNCvulVlxcjPvuuw8XXnghLrjgAowfPx7bt28Pe6/Vq1dj9uzZ6Nu3L3JzczF16lQUFBQobQ4fPow//elPyMvLQ/fu3TFhwgRs2bJF+brR1NLmzZsxZswY5Obm4qKLLsJ9992HkydPal4zfPhwfPzxxxg9erTy5yYHqrKXX34Zl112GS644AIMHDgQc+bMQVlZmen4mlm/fr3yPl26dAn7z8jPP/9s2Fb+L9o08Z/+9Cecfvrp2LBhg+HXP/nkE7jdblx00UXKtWbNmqFPnz7YunUrAODrr79GSUkJLr30UqWNIAgYPnw4du7ciaqqqliHguoJZmSo3nrrrbdw9913Y+TIkbjllltw4sQJLFy4EBMmTMDGjRvRvHlzLF++HKtXr8Y999yDtm3b4uuvv8b8+fPhdDoxZcoUfPHFF7jrrruQn5+PPn364OjRo3jiiSdw5513hv2CB4Dzzz8fa9euxYQJEzB27FiMGzcOLVu2tNQXAPD7/Xj22Wfx8MMPo6ioKCyrAgSCjZtuugk///wz7rrrLjRv3hzPP/889u7di5YtWxqOxdq1a/HAAw8ACEw5CYKAjz76CM888wwWL16M9u3bAwDmzJmDDRs24JZbbkFubi527dqFRx55BCUlJcq/YoHA9M9ll12GJUuWwO/3Q5Ik3Hbbbfjyyy8xdepUdOjQAR988AGmT58Oj8eD3//+98prV61ahV69euHRRx/FyZMnMXfuXMycORNr167FuHHjcPToUaxbty7itNCxY8dw/fXX48wzz8QTTzyBsrIyPPnkkygsLIz6ufjzn/+MyZMn409/+hOee+453H///TjzzDMxcuRITJgwAWvWrMGjjz6Knj17olu3bqiursYNN9yAgoICTJ8+HS1btsT69etx00034fnnn0f//v2Ve8+fPx/Dhw/HU089hcOHD+PRRx+Fw+HAU089BVEUccstt6BFixZ4/PHH4XA4sGrVKuTn52Pz5s0466yzwvq6dOlSLFiwANdddx2mT5+Ow4cPY8GCBfjqq6/w+uuvIz09HQBw/PhxPPjgg8ov/BdeeAEzZ85Et27d0KFDB7z77rt47LHHcM8996BLly743//+h8ceewxVVVWYN29e1DGTLV68GIsWLcLEiRNxzz33KP2RJAlPP/00MjIyDF/XsmVLrF271vS+jRo1ivi+r7zySsTaoQMHDuCMM86Aw6H9lXXmmWfi7bffVtoAQLt27TRtzjrrLPj9fhw6dAidO3eO2A+qnxjIUL0kiiKeeOIJXHjhhZg/f75yvWfPnhg5ciRWrFiBGTNmYOfOnTj//PNx9dVXAwD69u2LjIwM5QfrF198gbS0NNx8881IS0sDAGRnZ+Obb76BJEkQBEHzvo0aNVKmM1q3bo0ePXpY7ovs1ltvVaZ/jGzduhV79+7FsmXLlHb9+vXTFPrq9ejRQ/me5P7JP9jPPfdcnHHGGfjxxx/x+uuvK7/oAWDAgAEQBAHLli3Dddddh6ZNmwIAbDYbHnroIbjdbgCBbNO2bdswf/58jBw5EgAwcOBAVFZW4sknn8SoUaOUXzKNGzfG0qVLYbfbAQCHDh3CokWLcOLECc3USqRpoRdffBE+nw/Lly9XgsD27dtj/Pjxpq+RXX311bjxxhsBAG63GxMmTEC3bt0wdepUAEDXrl3xz3/+E19++SW6deuGt956C/v27cPrr7+O7t27AwhMSUyaNAlPPvkk1q9fr9y7c+fOePTRR5Xne/fuxXvvvQcAKCwsxIEDB3Drrbcq0x/dunXD4sWLUV1dHdbPkydP4plnnsG4ceM09U6dO3fGxIkTsWHDBlx33XUAgMrKSsydO1cJqtq1a4fBgwdjy5Yt6NChA3bs2IHTTz8dEydOhM1mQ9++feF2u3HixImo4yU7ceIEli1bhvHjx2sK2Dt16oSJEydi//79+H//7/8Zvtblcp3SNF+0AujS0lLDYCgzMxPl5eVKGyA8aMrMzASAGmWnqH7g1BLVSz/++COOHz+O0aNHa66feeaZyM3NxY4dOwAAeXl5+Oyzz3Dddddh5cqVOHDgAK6//nolg9CnTx9UVVVh9OjRmD9/Pr744gsMGDAAt99+e1gQc6p9kUX7V+Hu3bvhdDo1BY9ut1v55VhTn3/+OSRJwpAhQ+Dz+ZT/hgwZgurqanzxxRdK2zPOOEMJYgBg+/btEAQBgwYNCnvt8ePHNVNkF1xwgRLEAFACl8rKSst9/eKLL9CjRw8liAGA7t27o02bNlFfm5ubqzzOyclRXiuTgzX5F9/27dvRokULnH/++cr35ff7MXjwYPz73//WTPPof1m3bt1a+b5ycnLQsWNH/PWvf8XMmTOxefNmSJKEWbNmGf6Zf/XVV/B4PGGfm969e+P0008P+9yo31se04qKCgCBQPenn37CmDFjsHTpUvznP//B6NGjccMNN0QdL9nevXvh8XgwatSosP60adMGu3fvjvh69edC/5/f77fcDyOiKJr+fZSv66deZfJSf5uNv+4aKmZkqF4qLi4GEPpFpZaTk4P//Oc/AICbbroJmZmZWL9+PR577DHMmzcPnTt3xr333ov+/fsjNzcXzz33HF588UW88MILePbZZ9GiRQvcfPPNln8JWO2LTP3L2cjJkyeRnZ0d9oO3RYsWlvoTrZ+XX3654dePHTumPNZ/L8XFxZAkCT179jR87W+//YZzzz0XAMKmH+Tvw+wXjZGTJ0/ijDPOCLtuZQyM/uVuNiUCBL6348eP4/zzzzf8+vHjx9GkSRPD+9hsNuUXpSAIWLFiBZ555hl88MEH2LhxI5xOJ4YNG4Y5c+YoK2tkcoBk9rmRAy2j70EeU/m9R44cCVEU8eqrr2Lx4sVYsGABTj/9dNx5552mf95G4wAYj3GLFi3C+qP2888/Y+jQoaZf79u3r+FUrVVZWVmG04rl5eXIysoCEMgEytfkPy8gFOzJ7ajhYSBD9ZL8S0FdaCk7fvy4Zopk4sSJmDhxIgoLC7FlyxY8++yzmDJlCj777DO4XC4MHDhQmSb5/PPPsWrVKjzyyCPo0aOH5l/yp9oXq5o2bYoTJ07A7/drMhvyL5qakn/Qv/TSS0q6XS1StiMrKwtutxurVq0y/LpR/cepaNq0qeF4nuoYGMnKykK7du3w5JNPGn7dKKAy06pVK8yZMwf3338/9u3bh/feew/Lly9HkyZNlBommfzLtqCgAB06dNB87fjx4zGvNBs1ahRGjRqF0tJSfPLJJ1i+fDlmzJiB3r17W9oiQP05Pvvss8P6E2kcWrZsiXXr1pl+3ejzFov27dvjk08+gSiKmgD/0KFDytjJdWAHDx5Et27dlDYHDx6Ey+VqsCv3iFNLVE+1b98eLVq0UAr9ZIcPH8ZXX32lZA6uueYaPPzwwwACmZAxY8Zg4sSJKC0tRVlZGR577DGMHTsWkiQhIyMDgwcPxj333AMAmhVHtdEXq/r37w+fz6fZyMvj8eDTTz+N6T568j4aJ06cwAUXXKD8V1xcjKeffjpikNC3b19UVFRAkiTNa/fv348lS5bA5/NZ7oeVFH+/fv2wZ88eTZbohx9+wOHDhy2/j1V9+/bFr7/+iubNm2u+t+3bt+P555/XBJOR7NmzBxdeeCH27t0LQRBw7rnnYvr06ejcuTOOHj0a1r579+5wuVxhn5vdu3fjyJEjMX1upk2bhttvvx1AIDD73e9+h/z8fPj9ftMVeGb90a9Ek/sTaR8Wl8ulGTv9f/rAKFYDBgxAeXk5tm3bplwrKirCrl27MGDAAACBKUW32433339faSNJEj744AP07dsXLpfrlPpAdRczMlRnHT161HDvh44dO2LAgAH485//jFmzZmH69On4/e9/jxMnTmDx4sVo0qSJUuzZp08frFixAjk5OcjNzcWxY8ewcuVK9O3bF82aNUP//v2xcuVKzJw5E1dccQW8Xi+ef/55ZGdno1+/fpb6abPZLPXFqv79+2PAgAH4y1/+gsLCQpx++ulYtWoVioqKok5LRdK5c2dcccUV+Otf/4pffvkFXbt2xY8//oj58+fjjDPOCFvtoTZo0CD06dMH+fn5yM/PR4cOHbB3714sWrQIAwYMQLNmzSz3Q84MvfPOO+jevbvhv5RvuOEGrFu3Dv/3f/+HKVOmwO/34+mnn4bT6Yz5+45mzJgxeOWVV3DjjTfi1ltvxWmnnYbPPvsMy5cvx/XXX2/5Pc877zykp6fj7rvvxpQpU5CTk4PPPvsM//3vfw2LZLOzszF58mQsXrwYTqcTQ4cOxc8//4wFCxagY8eOGDNmjOXvoV+/frj//vvx2GOP4eKLL0ZJSQkWL16Mdu3a4ZxzzgEQyF4UFRWZFuVmZ2fj5ptvxtKlS+F0OjFo0CBl1VLnzp01K9MSrU+fPujbty9mzJiBGTNmIDs7G4sWLUJWVhauueYaAIGptz/+8Y9YsmQJnE4ncnNzsX79enz77bd46aWXktZ3ij8GMlRnHTp0SLNCRHbVVVdhwIABGDNmDDIzM7Fs2TLcdtttaNSoEQYOHIg///nPyjz/HXfcAZfLhfXr12PJkiXIysrCkCFDcOeddwIIrE558sknsWLFCqXAt1evXli1alVYTUMkVvoSi8WLF+PJJ5/EwoULUV1djZEjR2L8+PH45z//GfO91B599FEsW7YMr732Go4ePYrmzZtj5MiRmDZtWsTMg81mw3PPPYcFCxZg2bJlKCwsRKtWrTSbj1l16aWX4q233sLMmTMxduxYzJkzJ6xN06ZNsWbNGmXpdmZmJm666aawbEFtcLvdWL16Nf72t7/hiSeeQGlpqVJf8sc//tHyfdLS0rBixQr87W9/w9y5c1FSUoJ27drhwQcfNA1K5IDnlVdewRtvvIHs7GxcdtllmDZtWsS6Hr1rrrkGXq8Xr732Gl599VWkp6ejf//+mDFjhhKILV26FBs3bsR3331nep+pU6eiZcuWePnll7FmzRo0adIEl112GaZPnx5Tf+Jh8eLFmDdvHh5//HGIooiePXvi6aef1tTD3H777bDb7Xj99dexYsUKdOzYEUuXLkWvXr2S2HOKN0Hi6W1ERCnh0ksvxT/+8Y9kd4OoVrFGhogoBbz++uuGGzAS1XfMyBARpYD//e9/OO2005I+RURU2xjIEBERUb3FqSUiIiKqtxjIEBERUb3FQIaIiIjqLQYyREREVG8xkCEiIqJ6K2V29i0sLEVtrs8SBKB586xav29DxfGyjmNlHccqNhwv6zhWsYnHeMn3jCZlAhlJQlw+jPG6b0PF8bKOY2Udxyo2HC/rOFaxScZ4cWqJiIiI6i0GMkRERFRvMZAhIiKieitlamSIiIjqI1EU4ff7kt2NiAQBqKqqgtfrsVwjY7c7YLOdej6FgQwREVEdJEkSSkqKUFlZluyuWFJUZIMoijG9JiOjERo3bgZBEGr8vgxkiIiI6iA5iGnUqClcrrRT+mWfCHa7AL/fWjpGkiR4PNUoKzsBAGjSpHmN35eBDBERUR0jin4liGnUqHGyu2OJw2GDz2c9I+NypQEAyspOICuraY2nmVjsS0REVMf4/X4AoV/2DZX8/Z1KDRADGSIiojqqrk8nnara+P4YyBAREVG9ldRApqioCMOHD8eOHTuitv3+++/RvXt3S22JiIgoNSQtkPniiy8wYcIEHDp0KGrbyspK3HnnnaiqqkpAz4iIiOhU+f1+3H77ZMydOyeu75OUVUsbN27EwoULMWPGDEyfPj1q+wceeADDhg3D999/n4DekVU+0QdREuGyu5LdFSKilCBJQEVF4t7P7Q5sdlcTK1cux969X+G009rUbqd0khLIDBgwAKNHj4bD4YgayLz55ps4ePAg5s6di6VLl9b4PWu7Xkq+XwOvw4ro8g3DcKKqCJ9d9wWcdmfEthwv6zhW1nGsYsPxsi7ZY2X0vpIEjBrlxq5d9oT1o29fH95+uzLmcfjii134+ON/YdCgIZbaC0L492z1PZMSyLRo0cJSuwMHDmD+/PlYs2YN7PZT+4Nr3jzrlF6f6PvWdaIkYs9vXwIAbJle5DRqZul1qTpeNcGxso5jFRuOl3XJGquqqioUFdlgtwtwOAJVIJIE1MKO/jERhMD7Ww4qHDYUFRVh3ryH8PjjT2HNmtXKdSOiKMBms6Fp00ykp6fXqI91dkO86upqTJ8+Hffeey/atDn1tFRhYanl8x+sEITAB7y271vX3bP1TpR7yzH/kkXKtYLCUtir3BFfl6rjVRMcK+s4VrHheFmX7LHyej3BM5YkzSZzmzZVJHxqKbilTVQOhw0ejw/33z8bEyZch/btO0IKDp7ZRnl+vwRRFHHiRDmcTq/ma/KfQdT3tda9xPvmm2/w008/Yfbs2Zg9e7Zy/dZbb8WVV16JOXPmxHQ/SUJcPozxum9d5BN9WPHNcgDA7Lz7leuSJFkeg1Qar1PFsbKOYxUbjpd1yRors/cUBCAzM7F9icXLL6+Ey+XC2LHXxPS6UxnnOhvI9O7dG3v37tVc69KlC5599lnk5eUlqVepTZRCEbXH71EeS+BPRCIiAt5/fzMKCgpw2WWXAICy2njbto/x3nsfx+U961wgk5ubiwceeABXXHFFsrtCOuqAxSuGAhl1gENERKnr1VfXa57LS69nz54Tt/dMeiDz3XffaZ7v2bPHcltKLHXAUq3OyDBHTURESZL0QIbqD3XA4uXUEhERRRHPTIyMZy2RZSJUNTIiAxkiIko+BjJknSYj41VdZiBDRETJwUCGLNPWyFQbXiciIkokBjJkmdmqJU4tERFRsjCQIcu0+8ioppYYyBARUZIwkCHLzDIy3CKUiIiShYEMWSaqAhZtjQwDGSIiSg4GMmSZZh8ZkVNLRESUfAxkyDLNPjLc2ZeIiOoA7uxL1klctURERJGVlJzEggV/w/btn0IUReTm9sSdd85CTk5OXN6PGRmyzGzVEveRISIi2ezZd6OyshJr176JDRvegc1mw+OPPxy392NGhizjPjJEREkmSYBYkbj3s7kBQbDcfN++/+Lbb/+Nt99+H5mZjQAA99zzFxQUFMSrhwxkyDp15sXLGhkiosSSJGTvuhTOkzsS9pbe7H4o7v2+5WDmv//9Fu3atcemTW/izTfXoaqqEnl5F+L226fFrY+cWiLL1JkXD1ctERElXgzZkWQoKTmJAwf24+efD2HlytVYufJVHD/+Gx5++P64vSczMmSZtkYmtI8MAxkiogQQhEB2pA5PLTmdLgDA1Kl3Ii0tDW53JiZPzsfkyX9ARUUF3G53rXeRgQxZJmk2xFNPLbHYl4goIQQBsGcmuxem2rdvD0mS4PN5kZaWBgDw++XfEfH5Ry+nlsgy9T4yrJEhIiK9Pn36oU2b0/Hoow+ioqICJ06cwPLlSzFw4CVwu+MTgDGQIeskdY0MVy0REZGWw+HA4sXPwW6349prr8K1145BixYtMWvWffF7z7jdmRoc9ZlKXvXp18zIEBFRUE5OCzzwwKMJez9mZMgy7aqlUEZGPeVERESUSAxkyDLuI0NERHUNAxmyjPvIEBFRXcNAhiwz3UeGcQwRESUJAxmyTDI5/Zo1MkRElCwMZMgydcCiPv2aKRkiIkoWBjJknUlGhjUyRESULAxkyDJtjQxXLRERUfIxkCHL1JkXr2rVEmtkiIgoWRjIkGXMyBARUV3DIwrIMs0+Murl16yRISKioO++24eFC/+GAwf2Iy0tDYMHD0d+/lS4XK64vB8zMmSZOiNTzYwMERHpiKKIu++ehksuGYrNm/+F5ctXYefO7Xj11VVxe09mZMgydbzCVUtERIknSRIqfBUJez+3ww1BECy3Ly0tQWFhASRJVP6Ra7PZkJaWHq8uMpAh69RFvZpiX4nFvkRE8SZJEkZtvBS7ju5I2Hv2bd0Pb1/1vuVgpkmTbEyYcB0WL34aS5YsgN/vx8CBgzBhwnVx6yOnlsg60ykkZmSIiBJBgPXsSDKIogiXKw3Tp9+NDz7YhlWr1uLHH3/ECy8si9t7MiNDlpllXlgjQ0QUf4Ig4O2r3q/TU0tbt36ELVv+hVdfXQ8AOPvsDvjjH2/G008/iZtv/lNc+shAhiwzq4VhjQwRUWIIgoBMZ2ayu2Hq2LGj8Hq9mmt2uwNOZ/zCDU4tkWVmGRnWyBAREQD07dsfhYUFWLVqBfx+P3755WesWvUCLr10ZNzeM6mBTFFREYYPH44dO8wLl9asWYMRI0YgNzcXI0aMwOrVqxPYQ1Izz8gQEREB7dufjccem49PPtmKyy8fiqlTb8WFFw7E5Mn5cXvPpE0tffHFF5g5cyYOHTpk2ubDDz/EU089heXLl6N79+746quvMHnyZOTk5GDEiBEJ7C0BrJEhIqLo+vTJQ58+eQl7v6RkZDZu3Ii77roL06dPj9ju2LFjuPnmm9GjRw8IgoDc3Fzk5eVh165dCeopqZkFLKyRISKiZElKRmbAgAEYPXo0HA5HxGBm4sSJmueFhYXYtWsXZs2aFfN7xlB0HdP9avu+dZlkcjikBDHqOKTieNUUx8o6jlVsOF7WJXusUu3PSBDCv2erY5CUQKZFixYxv+b48eO45ZZb0LVrV4waNSrm1zdvnhXza5J537oo64TxzoxZWenIybE2Dqk0XqeKY2Udxyo2HC/rkjVWVVVVKCqywW4X4HDUn3U5sfZVFAXYbDY0bZqJ9PSa7f5bL5Zff/XVV7jjjjvQu3dvPProo3A4Yu92YWGp+X5uNSAIgQ94bd+3Lis+WW54/WRJBQoKSiO+NhXHq6Y4VtZxrGLD8bIu2WPl9XogiiL8fgk+X/1YGepw2GLuq98vQRRFnDhRDqdTu2xb/jOI+r4xvWMSrFu3Dg8//DCmTp2KP/7xjzW+jyRF2Jj2FMTrvnWRaFYjI0mWxyCVxutUcays41jFhuNlXbLGSn7Phr6YQv7+TmWc63Qg8/7772POnDl45plnMHDgwGR3J+WZFvs28L9oRESJZrfbAQAeTzVcrrQk9yZ+PJ5qAIFN82qqzgUyubm5eOCBB3DFFVdg8eLF8Pv9mDp1qqbN6NGj8eCDDyaph6mLG+IRESWGzWZHRkYjlJWdAAC4XGkxHRWQDKIowO+39g9bSZLg8VSjrOwEMjIawWareR1Q0gOZ7777TvN8z549yuO333470d2hCHhEARFR4jRu3AwAlGCmrrPZbBDF2P5hm5HRSPk+ayrpgQzVH6Yb4jGQISKqdYIgoEmT5sjKagq/35fs7kQkCEDTppk4caLccq2L3e44pUyMjIEMxYA1MkREiWaz2WCzuZLdjYgEAUhPT4fT6U14cXT9WZxOSccaGSIiqmsYyJBlPKKAiIjqGgYyZJlodkQBp5aIiChJGMiQZVYzMrd9OBmXbxgOv+hPRLeIiCiFsdiXLDNdtaQLcDYd2IhqfzWOlP+CtllnJqJrRESUopiRIcus7iMjBzycciIionhjIEOWWc3IKIEMi4CJiCjOGMjQKTPLyHBZNhERxRsDGbLM6s6+8nNmZIiIKN4YyJBlZjUv6gBH3UZiRoaIiOKMgQxZZmUfGW1QE/cuERFRimMgQ5ZZ2UfG7DEREVE8MJAhy6zUyKjbsNiXiIjijYEMWWa6j4xJ8MKMDBERxRsDGbLMyj4yzMgQEVEiMZChGMRYI8NqXyIiijMGMmSZlYyMZprJZJUTERFRbWEgQ5aZ7iMDk+kkZmSIiCjOGMiQZeb7yKjasNiXiIgSiIEMWWaWYDGrkWGxLxERxRsDGbLM2qolFvsSEVHiMJAhy8ymisxqZFjsS0RE8cZAhiyztGqJy6+JiCiBGMhQDMwCE5Pl1wxkiIgozhjIkGWx7uzLVUtERBRvDGTIMiunXzOQISKiRGIgQ5aZFe+aBS8Sl18TEVGcMZAhiJKIA8X7oxbnxpyRYY0MERHFGQMZwnN7l6L/q73w6n9fjtgu5tOvufyaiIjijIEM4ceT/wMAHCz5KWI7s5oXnn5NRETJwkCG4BcDmZNoxblmNS/a6SQW+xIRUeIwkCGIkj/4/8hTQVYyMqLJNBMREVE8MJAh+IOBTLQMiukGd2b7yHBqiYiI4oyBDCmBTNSMjIVVS9rHzMgQEVF8MZAh+MVgRiZKBsV8HxlmZIiIKDkYyFCoRiZKBsU0I2O2/Jo1MkREFGdJDWSKioowfPhw7Nixw7TNli1bMHr0aPTo0QO/+93v8NFHHyWwh6nBHww4ou3Ea7qPjLrYF1y1REREiZO0QOaLL77AhAkTcOjQIdM2P/30E6ZMmYI77rgDu3fvxpQpUzBt2jQcO3YsgT1t+JRi32g7+1pYtaQu/GUYQ0RE8ZaUQGbjxo246667MH369KjtevfujWHDhsHhcGDkyJHo06cP1q5dm6Cepga/5amlGHf25dQSERHFmSMZbzpgwACMHj0aDocjYjDzww8/oHPnzpprHTt2xL59+2J+T0GI+SWW7lfb900GUbX8OtL3Y56REZXXaVcqSWHj1BDGK944VtZxrGLD8bKOYxWbeIyX1XslJZBp0aKFpXbl5eXIyMjQXEtPT0dFRUXM79m8eVbMr0nmfRPJ7gh8WtLSHMjJMf9+0tKNPy7p6U7ldU2q3cr1RllpYfdrCOOVKBwr6zhWseF4Wcexik0yxispgYxVGRkZqKqq0lyrqqpCZmZmzPcqLCxFba4GFoTAH1ht3zcZKqurA/+v9KCgoNS0XUVltel1+XVFJ0KvP1lSoVxvSOMVbxwr6zhWseF4Wcexik08xku+ZzR1OpDp3Lkzvv32W821H374AV27do35XpKEuHwY43XfRJJXLfklMeL3Eun0a/l1flFVLyOG368hjFeicKys41jFhuNlHccqNskYrzq9j8wVV1yBnTt3YvPmzfD5fNi8eTN27tyJK6+8Mtlda1DE4IZ40dYZma1q0hT4cvk1ERElUJ0LZHJzc7Fp0yYAQIcOHbBkyRIsW7YMffr0wdKlS7Fo0SK0b98+yb1sWKweUWB21pIECQeK9+Ob419rl1/znzFERBRnSZ9a+u677zTP9+zZo3k+cOBADBw4MJFdSjm1sY/MVW+NQnHVCTw/4iXlerTl3ERERKcq6YEMJZ/1IwrMa2R+qzgGURJxsvqk5joREVE81bmpJUo8q4dGmmVkRElUpqXk7I58nYiIKJ4YyJCyail6jUz00699ok95zGJfIiKKNwYyFKqRibZqKcLOvjJ1IMOMDBERxRsDGQrVyNQwI+MXQ9NJfsln2IaIiCgeGMiQKhCp2T4y6roYdVDDYl8iIoo3BjIUwz4yxl9XTyf5WOxLREQJxECGVIFMTVcthYIXFvsSEVEiMZAhJXMStdjXrEZGfUQBMzJERJRADGRIqWuJFniYBTp+ZmSIiChJGMiQ5SMKzKaeNIGMxOXXRESUOAxkKFQjE+2IArMaGdFk1RIzMkREFGcMZChU1xI1I2NWI2MytcTl10REFGcMZMjyEQVW9pFRTy2ZFQcTERHVFgYyFDo0MspUkNnUk2ZnXxb7EhFRAjGQIctHFJhNPZlNLbHYl4iI4o2BDFk+NFIOTJw2p+H1wL1Cj5mRISKieGMgQ5aPKJADE4fNYfh6QDu1FG2nYCIiolPFQIZCNTIWVy05dBkZv+asJa5aIiKixGEgk+IkSVIyLWK0IwrkjIxg11xXTydxHxkiIkokBjIpTj0tZHUfmbCMjHpqiTv7EhFRAjGQSXH+GA55lKeKwmpkRPWqJb/6FafeQSIioggYyKS4WKaC5KknedWSTQh8fESetUREREnCQCbFiTFkZOSppwxHBgAg3R74v9mqJRb7EhFRvDmiN6GGLJapJfnrE86ZiJ9O/ohGrkZY+tVC8w3xohxCSUREdKqYkUlx6iBEgoTjFcfx3NdLUVRVGNZWnno6M+tMPHnJ0+jctEvwHqGAxae+HzMyREQUZwxkUpxfDAUhoiRixb+fw18+nYmX/r0irK2ckREEIfB/BP4vqupsRC6/JiKiBGIgk+LUNTKAhFJPCQCg1Fsa1lYOTITgx0YOaNQFviz2JSKiRGIgk+L0NTJy8GEUhOgzMvrrgLZGhhkZIiKKNwYyKc6vq2mJFMjINS/ysmuj5dfaVUvMyBARUXwxkElx6n1kRIQCGaMgRAquQpJrY+T/q++hOf2aCRkiIoozBjIpTgzLyATPXYqYkQkGMkqNjMnya2ZkiIgozhjIpDh1BkWURCXrYrQHjFIjEyEj4xO9ymPWyBARUbwxkElx+n1kItbIBP8fqUZGvWqJgQwREcUbA5kUpzlrSRKV6SPRoMDFdB8ZVdCjz/AQERHFEwOZFCfqMzKQi33DAxmzfWRq86ylFf9ejj99cJOm1oaIiMgMz1pKcWb7yEiRamR0GZnaPGtp5tY7AQCjOlyJy88eHfPriYgotTAjk+Ji20cmcE2ujdFvjKe/X6zrr9UZnGp/VUyvJSKi1JSUQKawsBD5+fno3bs38vLyMHfuXPh8xlMJL730EoYMGYKePXti9OjReP/99xPc24ZNc9YSIu/sG5pakjMy4R8f/yns7Fvhq1AeZzobxfRaIiJKTUkJZKZNmwa3241t27Zh3bp12L59O1588cWwdlu2bMGyZcvw/PPP48svv8Ttt9+OadOm4eeff058pxso/T4ykoUjCiJlZHy6qapYnKwuVh47bZz1JCKi6BIeyBw8eBA7d+7EjBkzkJGRgbZt2yI/Px+rV68Oa/u///0v+Ms18J/dbofT6YTDwV9ytSW8Rib6hnj6fWQ09zuFjEyxKpDx+L3mDYmIiIISHhHs378f2dnZaNWqlXKtQ4cOOHLkCEpKStC4cWPl+uWXX44NGzZg5MiRsNvtEAQBTzzxBFq3bh3z+xokD06JfL/avm+i6U+/VlYtQQz73uSv2Ww2CEJoh181fWCkH6dI43XSU6w89ojV9X5sa6qhfLYSgWMVG46XdRyr2MRjvKzeK+GBTHl5OTIyMjTX5OcVFRWaQMbr9eKcc87B3Llzcc455+Dtt9/G7Nmz0aFDB3Tp0iWm923ePOvUO5/A+yZKo5NpoSc2wOWyAwCcLjtycrTfm80W+FQ1zc5ETk4Wsgszw+7nVe3sm57uDLtHpPESC0IFvunu8PdPNfX9s5VIHKvYcLys41jFJhnjlfBAxu12o7KyUnNNfp6Zqf3F+NBDD6Fnz57o1q0bAODqq6/GO++8g40bN2LmzJkxvW9hYWmtHmIoCIE/sNq+b6IVFZcqj30+P6qqPQCAqmoPCgpKNW29wYLskpNVKCgoRWmp9s8R0E5JVVRWK/ewMl6Hjv+qPC4oPhn2/qmioXy2EoFjFRuOl3Ucq9jEY7zke0aT8ECmU6dOKC4uRkFBAXJycgAABw4cQOvWrZGVpe3wkSNH0LVrV801h8MBp9MZ8/tKUnxOY47XfRNFs7MvJGVnXlGUwr4vdc2LJAGQIuf9RMngHhHGq7iqWHns8Xvq9bjWhvr+2UokjlVsOF7Wcaxik4zxSnixb7t27dCrVy888sgjKCsrw+HDh7F06VKMHTs2rO2QIUPwyiuv4Ntvv4UoinjvvfewY8cOjBw5MtHdbhB2Hd2Bie+Ow4Hi/cq1sEMj5UDGYDO70OnX5quWdK+IqX8nq08ojz3+6pheS0REqSkpy68XLlwIn8+HoUOHYvz48Rg4cCDy8/MBALm5udi0aRMA4Pbbb8fEiRMxZcoU9OnTB8899xyWLFmCc889Nxndrvde2/cqPjj4Pt45sEm5ps/IxLKPjBzQmIl1+bVm1ZLIVUtERBRdUtYx5+TkYOHChYZf27Nnj/LY4XBgypQpmDJlSqK61qB5xUD9i/qEatHkiAIr+8jAYPm1WqxnLWmXXzMjQ0RE0fGIghQin4OkPa3a+IgCqYb7yKjFetZSsXpqKRh0ERERRcJAJoXI2RfTQAaiMn1kmJFB9J191WLNyKh39vVyQzwiIrKAgUwK8QXrYdTZFk2NjCQpO/sa7cqrBCaCxYzMqdTIcGqJiIgsYCCTQkJTS6EgRTRbtRSpRib4sYlW7BvrEQUnNcW+nFoiIqLoGMikkOhTSxZXLckZmVqcWpIkSZeRYSBDRETRMZBJIXJGRh28aM9GCp21ZHxopK5GJtqqpRiKfcu9ZUr/AAYyRERkTY0CmX//+98AgJKSEjzxxBN44YUX4PP5oryKks0fS0bGqEYGsa1aMsrIFFUV4q+fzsK3Bf/WXFdnYwAGMkREZE3MgcwzzzyDG264AQDw8MMP46OPPsLGjRvx2GOP1XrnqHb55EBGlSkRReN9ZIyWX+v3kYm+IV54ILPphzex7OslWPLVAs31sECGNTJERGRBzIHMO++8g9WrV8Pj8eD999/HU089hZdeegmbN2+OR/+oFvmDUzdShH1k5CyKcY1MgJKJiVYjY5DVOVl9EgBQ6avUXS/WPOeqJSIisiLmnX1/++03nHPOOdi+fTuysrJwzjnnAEDYidZU9xhPLYUeB/aRsbKzb82XX1cFAxi/qJ2KDM/IcB8ZIiKKLuaMTKtWrbBr1y68+eab6N+/P4BAlqZt27a13jmqXTHt7FsL+8gY3aPKXxX2vgBQEszUyJiRISIiK2LOyEyZMgU33XQT0tPTsWbNGmzfvh2zZs3CokWL4tE/qkVGy6/Da2Qi7Owbto9M7MW+Fb4KANCsUAKA6mDg4rA54BN98LLYl4iILIg5kBkxYgQuueQSAEBaWhpatWqFf/7zn2jZsmVt941qmbyzr7oIV7P8GpEPjUSM+8gYnbVU5QtkZHy6jIzcjwyHG6WeElQzkCEiIgtinloSRRFbt25FWloajh07htmzZ+PZZ59FWVlZPPpHtUgOFtT7u8RyaKR+1VK0qSUYZGTMamREJZDJABA6qZuIiCiSmAOZefPm4eGHHwYA3H///SgoKMD//vc/PPjgg7XeOapd/ig1Murl1xF39rV6+rVhsa9xjYz8PD0YyHAfGSIisiLmqaUtW7ZgzZo1KC8vxyeffIJ3330XzZs3x9ChQ+PRP6pFPik8kBFF9aolCfL0kdGGeGEZmRosvzarkfEH++FmIENERDGIOSNz4sQJtGnTBrt27ULLli1x1llnISMjA36/P/qLKan8YuSdfdXPrWRkom+IFyEjow9kgkGWPLXEDfGIiMiKmDMybdu2xZtvvon33nsPAwYMgCiKWLFiBTp27BiP/lEtinZEgVkbWaw1MsbLrwM1MmHFviKnloiIKHYxBzIzZ87EPffcg/T0dDz44IP4/PPP8cILL+DZZ5+NR/+oFlnJyPiU3X+j7yMTdWdfg3tUeuViX7NVSyz2JSIi62IOZPr06YN//etfyvPs7Gxs3boVLperVjtGtU+ukZFMzloCoNoQz3xqSd5HpkbFvsqGePqppWBGxh4IZKq5IR4REVkQcyADAB9++CHWrl2LX375BS1atMDYsWMxevTo2u4b1bJoq5YA491/AW12RS7yjVYjE56PCZ2xpC/21S+/FiURftEPu80e8T2IiCi1xVzs+/bbb2PmzJno3LkzJk2ahPPOOw9z5szBG2+8EY/+US2Sgxa/JpARDdvoAxn1c6tnLRntRaMEMmEBlDaQAZiVISKi6GLOyCxfvhyLFy9Gv379lGuDBg3Cgw8+iHHjxtVq56h2+QxqZERJP7VkHMioC3eVfWRqsPxa3hBPP6Wlr5EB5DoZNwDgaPmvAIDWmadFfE8iIkotMWdkjhw5gry8PM21vn374ujRo7XWKYoPoyAlrOjWINjRP7e6akl+jV/049NftqGkugTe4KnWPrMaGU1GxoOj5b9ixLpL0O2lLuj1clf8WnYkyndJRESpJOZApnXr1ti1a5fm2q5du9CmTZta6xTFR2hFUoQaGTnY0WVTjDIy0WtkAq955uvF+P2bl2PYqmFhfZHJGRq7YIfLFigc9/o92PbzFuz57cvAc9GLgyU/RXxPIiJKLTFPLd1www247bbbMGHCBLRt2xaHDh3C2rVrMWvWrHj0j2qR0c6+YfvIBAMKfX1LTTIycoHw6v++BADYdSQUAIdviBd4X5vNBpc9DR7RA4/oCd8BWNdfIiJKbTEHMuPGjYPdbseGDRvw4Ycf4vTTT8fDDz+Myy67LB79o1qiPhAyUo2MvCxavweMdtWSfERB5PeU36eRMyvsa+GnXwfa2gU7XHYn4A1siqcPXIxP5SYiolRVo+XXY8aMwZgxY5Tnfr8fP/74I9q3b19rHaPapTkcUn36tWhx1ZLqNVYPjZSnlho5G4X3J6w2JxBAOQQHXPY0AIFjCsx2HiYiIgJqUCNjpKCgACNHjqyNW1Gc6E+5NroOqPaR0W+Ip8rIhA6NtHbWUiOXQSBjUuxrt4VqZDz+aoOMDAMZIiIKqZVABjDejp7qDnWtiaj6szLLcERatSRY3EdG3hIv0yAjY1b7YhPscNnlYl9v+DJtkYEMERGF1FogE21PEUoudSZDilAjE7puvo+MckRBlD/zSDUyfsmvCX79qlVLzmBGptpfbbBMmzUyREQUUmuBDNVt2oyM+T4yskirlqxmZORAxWhqSX9POaCyC7ZQRkb0hNXwsNiXiIjULBf76veOUSsqKqqVzlD8+ESTYt+aZGQEaxkZ+RV2wfi8JJ/kgx324GO5RsahBDLVBquWWOxLRERqlgOZSZMmRfw6p5bqNtG02Nc4w6E/XkBdV6NsiBcloafs7GsSfPhEH9KCK5T8JhvimR2hQEREBMQQyOzbty+e/aA4M5taMq+RibSPTGxnLZkFMn5Nn1SrluyhGhlmZIiIKBLWyKQIq8uvjdoAoekodV2M1bOW9CuPjN5bWX6tXrUkesNqeFgjQ0REagxkUoR69Y9kodg3LGAIZmTU5ytFzchIkTMy6rqd0PJrm2ZDvLCdh7n8moiIVBjIpAh1AGAlIyPBeLWQOniJtiGefA+zOhz1pnhyUOOwOeC0OQHIG+Jx1RIREZlLSiBTWFiI/Px89O7dG3l5eZg7dy58Pp9h2507d2LcuHHIzc3FoEGDsGzZsgT3tmHQTuPUfB8ZdYGv1eXXZu/hM6qREexKAbDH7+WhkUREFFFSAplp06bB7XZj27ZtWLduHbZv344XX3wxrN2BAwcwefJkXHfddfjyyy+xbNkyrFixAu+9917iO13Pme4jY5LhMNvZV5ORsXjWklkWxaxGxhnhiAIGMkREpJbwQObgwYPYuXMnZsyYgYyMDLRt2xb5+flYvXp1WNtXX30VQ4cOxVVXXQVBEHDOOefgtddeQ69evRLd7XrPdPm1xRoZJSMTQ41MtOXX6lVLcj9sgh1pqg3xwpdfc2qJiIhCanT69anYv38/srOz0apVK+Vahw4dcOTIEZSUlKBx48bK9b179+LCCy/En//8Z3z66ado1qwZ/vCHP2DChAkxv29tb3Mj36++bJ+jrkeRICr9Npv2kSBpvjdJtWpJvm63Rc/ICIL5e/glf1g/HKrl1x6DDfFE1Wsaqvr22UomjlVsOF7WcaxiE4/xsnqvhAcy5eXlyMjI0FyTn1dUVGgCmZMnT2LVqlWYP38+Hn/8cezZswe33HILmjRpgssuuyym923ePPy8n9oQr/vWtqzKdOWxYANycoL9thkf9ilKYqgNgBJ7ZqC5zaZct1V6I76n/D4Ol3HiL6tJWug97IF+NM1uhCalgSMN7C7AJWp3Bc5wOzX9asjqy2erLuBYxYbjZR3HKjbJGK+EBzJutxuVlZWaa/LzzMxMzXWXy4WhQ4fikksuAQD06dMHV155Jf7+97/HHMgUFpaiNg/oFoTAH1ht3zdeCk6UKI+9Ph8KCkoBAB6feTBy/HiJMn1UUBx8vSQory2uKov4nj6fHwUFpaiorDLuU1EJCuyBe1V7Av0oL/XA7wl8/WR5Wdip6iVlFcr7N1T17bOVTByr2HC8rONYxSYe4yXfM5qEBzKdOnVCcXExCgoKkJOTAyBQ1Nu6dWtkZWk73KFDB3g8Hs01v98f9svNCklCXD6M8bpvbdMX+8p9jrQvi18UYbcFMiKSah+Z0PcbfWpJkswLin2iL9QPKVQjEyr29WhqcuQ+1Yfxrg315bNVF3CsYsPxso5jFZtkjFfCi33btWuHXr164ZFHHkFZWRkOHz6MpUuXYuzYsWFtr7nmGvzzn//EW2+9BUmSsGvXLrz99tu48sorE93tes9sH5lIxbPadoFPZkyrluQN8UyCJbPl1zyigIiIrErK8uuFCxfC5/Nh6NChGD9+PAYOHIj8/HwAQG5uLjZt2gQA6N+/P5YuXYpVq1ahV69emDVrFu655x4MHTo0Gd2u19TFvqLqQMhIgYH6lOzQPjKh4EWfLdFTll/DJCOjXn6tOjRSzsh4xfB9ZHhoJBERqSV8agkAcnJysHDhQsOv7dmzR/N80KBBGDRoUCK61aCpsyKShZ19AePMjWbJtcXl12ZnLYlGRxTYQhvief0eOG3ajygzMkREpMYjClKEL8Z9ZPTtDPeRsTq1pAs+5Huoz3+S++cQ7HAEgxeP6IFf1GZzeNYSERGpMZBJEWY7+0aaqpFUU1Ch18Rw+jXCN8Rr17g9zm7SIbxPqqklOZDxi37NYZLqexIREQEMZFKG6c6+kQIZdUbG4PTrqDUySkYmcJ9XrnoFO67fg0bOwD4xmp195WJfmx0OwaFck6+7gnUzoshAhoiIQhjIpIhYz1rStxNVO/vKoh1RoBT7iqEgxSbYlCXdfoOAyibYYQ9mZHyiTwnAnMGVTKyRISIiNQYyKUIdAEiIvUYGBhmZqFNLurOW7II9+P9QoBJqGz615BN9Sv9cNmfY90FERMRAJkWY7yOjDTLURCm8RkaIoUYGutOv5UyMUgOjLvYNBjUOmwP2YLDkl3xK4OIIBjI8NJKIiNQYyKQI9QohoykdZzBQUIu2ailajYxpRsYWnpGR+2QXbKqMjF9ZzSRvksd9ZIiISI2BTIowy8joMx5q6hVCRvvIRK2RkeSMjHblUSjjEr4hnk2wa6ae5PoaJ6eWiIjIAAOZFKHZ2TcYlEiSpDzWbzwX+Hp4RkaIpUYG2lVLytSSEFpeHeqTatVSsC+ietWSXOzLfWSIiEiFgUyKMNrZV52ZMcrISIY1MiFWMzLq4wcC7xXMuEgGy6/Vq5ZUNTLysQWRVlkREVHqYSCTIox29lVP0zgMMjKaGplgTKOvi4mUlVGWX6uyLYH/h9fIyI/tNgccwYBHvfzaZXcG+8FAhoiIQhjIpAh/lEDGsNgXkfeRASJnZcyXX9uDXw9clyRJCXrCdvYV9RkZTi0REVEIA5kUod5F1+joADlbohZtHxkgSkZGd9ZSaPl1KOMS1g/BpptaCtbwcEM8IiIywEAmRRjt7Ks+fTra8mujfWSAyBkZeeM9ZR+ZsA3xAu+vDWTsSjufGKqRUTbEY7EvERGpMJBJEdGmluTgQs1o1VLNMjKRN8RTByc29VlLok/JJDmVDfEYyBARUQgDmRShz2RIkqRZAWRc7GuwakmXgYm0KZ4+8xPaR0Y/tRTKFgVqZEJnMSmrlpQN8UJ9IiIiYiCTIvS1JaIqSLAJNmWTOn0bmbKPDGJftWS2s698XR1kOQSHZlWTfudh1sgQEZEaA5kUoa6RAYKBjHy+keAwrHWRAxG5PRCekYlcIxO52NevZGRCAZNdPbWkKvZ1sdiXiIgMMJBJEerpGyCwckl9UKPRFJF2H5nYa2SUqSVdRsYRodjXpjlrKXREgcuWprkXERERwEAmZRhNLck76wamcsIDEu3UktmqJfOPUNjOvsFMjE2ukQm+vz7QUU89hWpk5GMLuCEeERGFMJBJET7RoEYmeM0h2I0zMji1jIyys69qsztAvWpJWyMTWp4deg+PvxoAN8QjIiJjDGRShH5KRpJEeEUvgEAGxCiQkQz3kdGyct6SPiOjr5GRMzNygKNeQVXt9wAAXDYeGklEROEYyKQIfbGvX/KHin1tDsPMitGqpVgyMvI9wqaOBO1ZS6HVU9qvA6qMjN2p3I+IiEjGQCZFGNbIqFYtRSv2lfdvCd9HJkpGBpJmmTcQyszI10XReMM8APCIgYwMl18TEZERBjIpInz5taQq9rUbZlbUy69rso8MIG+8p5taEkKHQgLqfWYC9zbanC+0IR4zMkREFMJAJkXoa0vUxb5Om9NCRib2fWSAQMFwWDGv6lBIIHxqySbYwgIkFzMyRERkgIFMigibWoKoLbI1CEjUxwHUZNVS4B6iks0xPf1a1Bb76h8DgMvOfWSIiCgcA5kU4dNtiCepamTsggM2o6klS/vIRA5k/KL2HCX1/8OnluxhbWVOnn5NREQGGMikCNFwakm1askwI2NlH5nIHyF1bY6ckQk7a8kokNFlZJTTr8FDI4mIKISBTIrQZ2QCO/sGN8SzRd8QL7SPTGwZGZ9qKijsiAK5Ria4akndh/CpJe4jQ0RE4RjIpAijnX3VU0vx2kdGPbVk061Kkr8m6lY1AYHdhtXknX1ZI0NERGoMZFKEPgDQTy1ZXbWkLwqOlpGRdw8G1GctBd7Lp9vZN9LUksvOVUtERBSOgUyKCNtHBtpDIw33kVGtWpIDGX1RsM3gI6S+l8+g2Dd01lLgnqHl2apVS4I2kHFw+TURERlgIJMi9AGApNnZ17hGRkL41JKVfWTUU0RGxb6hDfG0+8hoppZMamS4IR4REakxkEkRfoOdfZXTr20OCBanlqzUyKiniNRFxqEjCrTFvvqzmAJttDUyLltgHxk/AxkiIlJhIJMi9AFAYNVS5Kklo+yHlVVLmkBGNKh/EXQb4gXfx64KksL3kQkEP/pl5ERElNrCD7WhBin8rCXtoZFGRKMaGX1GxiCTY1MFIX6DQEbe2VfOxMj9sAnGU0s2wRZ20CQRERHAjEzK8BvsIxNatWS3vCFeWEbG4L0EQVDaqQ+mlMlBirwkXJT8muuAtvDXLtiVgIk1MkREpJaUQKawsBD5+fno3bs38vLyMHfuXPh8voiv+f7779G9e3fs2LEjQb1sWMIOjVSvWhIchquPNDUysF4jYxNsSjtvMFhS7wAsBymhs5bCa2S0QY09dKwBMzJERKSSlEBm2rRpcLvd2LZtG9atW4ft27fjxRdfNG1fWVmJO++8E1VVVYnrZAMTtrOv6FcyIoFi3/DXaFYtydNMFlYt2SAo15WpJVt4Ia9ff/q1LXz6CQhMOcmBDDfEIyIitYQHMgcPHsTOnTsxY8YMZGRkoG3btsjPz8fq1atNX/PAAw9g2LBhCexlw2NU7BttQzzjfWTMMzJyFkUQBKWdvCGeupBXWX4ddtZSeNYGCAQ+oYwMp5aIiCgk4cW++/fvR3Z2Nlq1aqVc69ChA44cOYKSkhI0btxY0/7NN9/EwYMHMXfuXCxdurTG7xtlA9oa36+27xsv+uXXEkQlI+IwW7UEMfT9CaF9ZNTfs00XoPjgg02whTIyul17BQFw2OXTr30QBO2hkfK9tVNLNthttuBr/PVmzGuqvn22koljFRuOl3Ucq9jEY7ys3ivhgUx5eTkyMjI01+TnFRUVmkDmwIEDmD9/PtasWQO7XbscN1bNm2ed0usTfd/aJkI7JdO4SQZcxwNj2sidAb/dE/aaRo3SkJMT+P7c7sCGdBnpLuUaADgcqukguwPwBzIocoCT2cgV+hoC45VT1STQJ0FETk4W3JmBXXvd6enKvdPTXMp9nXYncpoHPhcSRM37N2T15bNVF3CsYsPxso5jFZtkjFfCAxm3243KykrNNfl5Zmamcq26uhrTp0/HvffeizZt2pzy+xYWlkI1U3LKBCHwB1bb940Xn1+bkSkqLkNJeQUAwFstwlMdXmx9sqQcBQWlAIDSssCfkdcjKtcAQPSHvnllOkgKrVoqOhloKxf7FhaWoqQkUOvk8XlRUFCKkyXlAAC/V1LurU4gCbDh5InA+/tFv+b9G6L69tlKJo5VbDhe1nGsYhOP8ZLvGU3CA5lOnTqhuLgYBQUFyMnJARDIvLRu3RpZWaEOf/PNN/jpp58we/ZszJ49W7l+66234sorr8ScOXNiel9JQlw+jPG6b20L20dG1J9+HV4j45dE5XuTa2QEaL9fTY2MMn0kQF6YLQdQ8tSSJAF2yEcU+CFJgE8u9hXsyr0duuXXNtWqpfow3rWhvny26gKOVWw4XtZxrGKTjPFKeCDTrl079OrVC4888ggefPBBnDhxAkuXLsXYsWM17Xr37o29e/dqrnXp0gXPPvss8vLyEtnlBiG0e64dfsmv3RDP5oi4j8yWwx/ho0P/BBC+/Fr9XD56wAb18mu52Dd8abVcPyNy+TUREdVQUpZfL1y4ED6fD0OHDsX48eMxcOBA5OfnAwByc3OxadOmZHSrQZODFuXwRWg3xDPaR0aSJHj8Hox7+0p8eOgfwav6gEedkQkGMqpi39CuverVTfIRBbpVS7bwoAgILMvmhnhERGQkKUcU5OTkYOHChYZf27Nnj+nrvvvuu3h1qcGTsx9OmwuVqNSetSSYZ2Q8/mrNtfAjCkyWXwfbGR0/YNOdteRTMjKhj6N2asmmydaIkmi4XJyIiFIPfxukCDnroRy+KImaDfEM95GBpEwNycKPKAg9l+8hCDblaqQjCvQb4hltmgfIU0uh/ul3KSYiotTFQCZFyNkPpzy1JInwBYOUwD4yxkcUeHVFwpFqZBxKjUx4RkZT/6LbEE+Uwmtk9I/VgQ3rZIiISMZAJgWo60pctkAgI0m6VUsmU0s+fUYmwhEFSiAj2JRMjdHp13bl0EgfJEkKHVFgVuxrc2hP1GYgQ0REQQxkUoB66bXTHth8TpTUO/vaNcW4MhFi2NRSpCMK5BqXwO6/8unX4UGKvt4ldGhkeHZHbq/O/Egs+CUioiAGMilAncGQMzIiJO2hkQZHFEhWMjKqx07V8mt5qkp+vXpFkvpASJ/kCx1jYDObWtIW+zIjQ0REMgYyKUB9zpLDFsrIqKeWjIp9Y62RsdsiLL+G8dJqv+iHXwxkWNQrlbRTS3YGMkREZIiBTApQTy25DKeWTA6NlER4/fozmMxrZORgwyYYbIhnCy/2BQIrl4xqZDT7yOimluTAh4iIiIFMCvCrakpCGRm/Zmdf44xM+PJr/VSTZkM8JfgQVMW+kWtkfKLPcPm1/ogCQQjdUwQDGSIiCmAgkwLkvVwECEqAoD+iwOi89MA+Mtqppd8qjmmea4p9DVYthTbdM94jxif6DZdf64t91a8TuY8MEREFMZBJAcpZRrbQFE1gailY7Cs4DI8oMFp+fbT8qOa5dmopcA/11JLRPjLqr6szQ+pVS+rHtmAAw/OWiIhIj4FMCqj0VwIA0uzpmjOLlAAiwqGR+qmlo+VHNM+V3XwhKIGGevm1so+MTftRkzNDgaklUemHTP1YPlWbgQwREekxkEkBld5AION2uJX9YvRTS4ZHFBhkZAqrCjXP5Skk9flKNghKwCQHQuoaGSA0TeSTfMZTS0L41JKNgQwREekwkEkBFb5yAIDb6dZNLQUDGcFuvmpJVyPTu1VfzXM582JT7fViU5215DcIUgLPg8cUiD7VhnjGq5bkoEfuOzfEIyIiWVJOv6bEqvBWAADcjkylFkZSbYhnN1u1hFBG5uwmHfD7Tldj0rl/0LSRAyAbbEoWRjBYfq2/v7wpnl9Vq2MzOFgy8Fp5ailwDy6/JiIiGQOZFFDhCwYyzgxNRkY9tWSekQkEIqc3OgMz+/4lrI3NoMBXUC2/Nir2BQBncIfhan+1ycGS4cu17TZOLRERkRanllJAhTc4teTINJlachietSRJErz+0AnZRpSMjCqQUe/sKxf7qrMtAJDhdAMAqnyVSo2Mw2xqiTUyRERkgoFMCqj0BYt9ne4Iq5bMppYCbZzBjfTCCHKxr02ZtrKpHvtMamQy7OlK30KrlkzOWrKF7guwRoaIiEIYyKSAUEZGW+wrBxkOm3Gxr6SaWnKYBDLKqiUISlZHc/q1wR4xAJDhyAAAVPoqDI8oMK6RYUaGiIi0GMikALlGJkMdyEBUpn0cpodGSvCKgbOWzDIyNtWqJUFZfq3eEC941pI+IxOcWgpkZCLv7Cs/ZiBDRER6DGRSgLJqyekOrVqyvCGe6hgDA6EaGUFbI6Mr9g2rkVEyMpWhnYdNzmNSL+sGuGqJiIhCGMikgEqfavm1akM89enX0Y4ocNpNppaE8GJfQZWdMVu1lOEIZWSU85iiLb+Wz1piRoaIiIIYyKSA0PJrtxIUaJZfC9GPKJCXS+upVy0pRxSorstBin7qKl1d7GuQkdEeGhmaspL7RUREBDCQabBKPSXK4/Jgsa+mRkZSb4hnN66RgTqQiTy1JMB4+bVZRsat1MhUKIGJdtVS+M6+3EeGiIj0GMg0QEu/WoSOz7fFvw59CECfkTHYR8bmAAxWLUGS4PNHXn4dmk7S1siE6lmMMzJyjUyVr8qw2NdoKTb3kSEiIj0GMg3Q3uN7IEHCt4X/BgBUKkcUhAIZv+TXTC0Zr1qysPxavWoJBsW+ZvvIOEIZGcPl16rH+uXXrJEhIiIZA5kGyBPcjdfrDyydDmVkQjv7hq1aMjqiQHXWkllGRn3WkrKPjGpPGXlnYHuEVUtG00/GO/uyRoaIiLQYyDRA8t4vnuD/KwwyMj7JBwkSgMCGeOqMjFxoq83ImBzLZbBqSZ2Rkaev9BmZ9GAgU+GtCB1RYLJqKbSPjJxNYiBDREQBDGQaIE8wEyNnQyp8wWJfp1uZ/pGzNYC8ain0+tAUjhT1iALNsQQGy6+9ZhviyTUy/qrQEQWaqSWDVUtyjYzIqSUiIgpgINMAycGDPiOT6XArUz6eYBsgMI2j3kfGrlqirWRkouwjA1Wxr/r0azno0J/lpDmiQAyvkVFPRen3kWGxLxERyRjINEChjEzg/+pDI+Vgw+OvVto7bNpiX7k+RZKsL7+2QQgdUWC4/Fr7UXOrNsSTp5Y0G+IZLb9msS8REekwkGmA5AJdOQiRp5YCO/vKgYx+aklQPQ/PyJgW+wrhG+Kpp5miTS1VeisMi30dLPYlIiILGMg0QPK0kcfvgcfvUQKFDEdGWIABaA98BFQZGUhRl18b1cjYBCG82Fe/asno0EiDYwnUj7mPDBER6ZksRaH6TJ5S8ooeVAR39QUCy68FXUbGETwwUr38Wr1qyeePlpEJ/N8m2JSgJrD8Wj5rKbz+BVAdUeCvUt7ZbrByKnDdrvk6i32JiEjGjEwDJBf5evxepT7GYXPAZXcpwYa8RFuuRdEsvxasL79Wn7WkWbWEyEcUKBvieVVHFGimltSFvzbN1zm1REREMgYyDZC87NorejT1MQBUNTLyRnWBAEWdkbHZQgFDtOXXgsEmeOqgxmdWI+MMbYhndGik+qwlfbDFQIaIiGQMZBogOSPjFb3K0mu5uDZUIxOaWlJfB0JTOBKsnH4dvneMAEGZc/KZ1Mi4VUcUKAXBBpvgAaHAysbl10REpMNApgFSVi35vShXHRgJIGzVkrxCSVMjo5paUo4oiLKPjNnOvnL2RL0qCggFVn7Jj6KqQgBAdlp2qA+GNTIMZIiISIuBTAMkTxt5VMW+oaml4BlIutVIxkcUSPAqU0vWa2QCj7WBi9kRBUAoMGmekaNqbx7IcB8ZIiKSJSWQKSwsRH5+Pnr37o28vDzMnTsXPp/PsO2aNWswYsQI5ObmYsSIEVi9enWCe1v/yNNGXr9HsxkeEFo9pF61BGgzJnZbeEYm6unXEJRAQ72zr3JPXSDjsrk0wVOms5GSpQn0IXynYa5aIiIivaQEMtOmTYPb7ca2bduwbt06bN++HS+++GJYuw8//BBPPfUUHnvsMXz55ZeYN28enn76abz//vuJ73Q9IUmSEqR4RK+SkZFXCYVtVGdQ7CtPN6n3kYl6+rVgw8VnXIIzG7fDpe1+pwlSgPBARhAEpU8AkKPKxgT6oN5TJlSHAwRO5SYiIgKSEMgcPHgQO3fuxIwZM5CRkYG2bdsiPz/fMNNy7Ngx3HzzzejRowcEQUBubi7y8vKwa9euRHe73vBLfuVUa6/fgwrTGpnAEQVKjYxJRiba8utQkCGgZ6ve2H39Xow8e1RYRsamK/YFoMnA6AMZdeGv/ogCv8hAhoiIAhK+Id7+/fuRnZ2NVq1aKdc6dOiAI0eOoKSkBI0bN1auT5w4UfPawsJC7Nq1C7NmzYr5fXUlG6dMdVZinSJPKwGBGplKX+jASEFQBTKiekM87WZ0cuAgqZZfu+xOw+9VXeyr/rrNpo2RQwFT6Jpbk5Fpofma065ewWQP9FFeFg5/nRv32lRXP1t1EccqNhwv6zhWsYnHeFm9V8IDmfLycmRkZGiuyc8rKio0gYza8ePHccstt6Br164YNWpUzO/bvHlW7J1N4n1rqrgqVD/ihw+CK/C8WVY2cnKykJWZoXwNANKcLuTkZKHxr6GgIt0VWGrtcNmUdi2aBV6vl5EeaOtyOjVfT3Npp6KaNA4UG6vHKzPNDZQGHp/RtI3m9X4x1J+mTbKQk5OFzIzAbsDpGQ7DvjQ0de2zVZdxrGLD8bKOYxWbZIxXwgMZt9uNyspKzTX5eWZmpuFrvvrqK9xxxx3o3bs3Hn30UTgcsXe7sLAUkhR7f80IQuAPrLbve6oKKk8oj6u81Th+MvDc5neioKAUlZVe5WsAANGGgoJSlJeFTsOWfIEwuKrag+pgu7ISDwocpWHvV10dCHT8PgkFBaGvez3agtyK8kAGSD1eLiFd+Xqm0ETzekk1qOVlHhQUlMJTHbhnaXmlpm1DU1c/W3URxyo2HC/rOFaxicd4yfeMJuGBTKdOnVBcXIyCggLk5ATqIg4cOIDWrVsjKyu8w+vWrcPDDz+MqVOn4o9//GON31eSEJcPY7zuW1MeX2hqyesPLb/OsLshSaEN7LzKqiW75jqgmsKRRGX5tUNwGH6fgurQSPXXBV2xr3w0gnq89DUy2vsLcNgc8Ik+2BDoo3JopOivU2MeL3Xts1WXcaxiw/GyjmMVm2SMV8KLfdu1a4devXrhkUceQVlZGQ4fPoylS5di7NixYW3ff/99zJkzB4sWLTqlICaVeDQ1MqGdfcOKfZWjA4xWLcWw/Fq1asnoukx/aCSgDWSap+eEfV2/7FpZfs19ZIiIKCgpy68XLlwIn8+HoUOHYvz48Rg4cCDy8/MBALm5udi0aRMAYPHixfD7/Zg6dSpyc3OV/+67775kdLtekM9ZCjz2oMofmLZLdwSmcZQN8cL2kQnfEE+SLCy/Vp21pBa2/Npw1ZK22FdPDrL0q5ZErloiIqKghE8tAUBOTg4WLlxo+LU9e/Yoj99+++1EdanB8IStWqoCAKTbg2ctIXzVEqANRNTLr+Xsh3lGJvh/fUYmys6+gG5qyR0eyITOgeJZS0REZIxHFDQwcqZFVuYtA6DOyGhPkJYDDO2hkYFr1f5QAbDL5Kyl0LEEuoyM7qMVNZAxmFpy6DIx8j15+jUREckYyDQw8lSQrLT6JIBQ0KDPnBgeUaDbNC/QLvqhkdrr2nb6r6v7BGjPWQr1Izi1JNfKMCNDREQ6DGQaGH0gU+IpARA6pFEfUISmb9SrlgLXqlXZnahHFCBysW+kGpnGriZw2V1hX5f7JveHh0YSEZEeA5kGxqObWlICGbt2akkWWrUUIgcQHjGUkYkWyOhrYsKWXxtlZJyB4Ep/PIG+H1y1REREZhjINDDqIwoAoLQGGRl5+bUcFNkFe1igIjOdWopy+jUQysgYrVgCgFFnX4lzmp2Lc5qfF3wvnn5NRERaDGQaGI9fO7UkF+xmyMW+0AcywTOQDFYtyYGMWTYGCAUX0TIwRvvIZKdlAwBOy2xjeO8HLpqLrdfsQCNno0C/lKkl7k5FREQBSVl+TfGjz8jIlOXXZlNLmn1kAgGDckJ2pEDGrEbGwvLr0R2uxC9lP+PKDmNM7290D9bIEBGRjIFMA6OvkZHJy6/1AYbhPjK65ddOm/nHxOrOvnZbePIvy9UYM/pYP8mcq5aIiEiPU0sNjC94NpKeXCOjz4wY1cjYdIFMxIyMSY1MeOYnPCMTK+WsJQYyREQUxECmgfGYTC1lOMxWLYVviCcHN3LAEKlGRn6dPgNjpdg3VvrN/IiIiBjINDD6nX1lZjUyRhviyauWlOcmu/oC6qmlyGctGRX7xsquBDLMyBARUQADmQbGo9sQDwhkQ5zBYCT8MMfg1JLqo6DfvM5KjUy0s5aM9pGJlZzV8fPQSCIiCmIg08AYZWTSVUcBhGVkBIOMjC5wibz82qzYNw41Miz2JSIiHQYyDYxRjYxcHwOEBxihqaXwDfFkTlv48QEym+lZS9GPKIiVnDViIENERDIGMg2Mz2BqSa6PAYymlsI3xLPVYGopPCOjVStTS8F+SSz2JSKiIAYyDYx+Z18ASHOkKY/1AYUrmG2xCeH7yMgiLb+Wj7nWr1IyKyo+FXYuvyYiIh0GMg2M0c6+2oyMNuBo7GoMQBuIOAR9RsbKqqXIU0vycQSnQn4PBjJERCRjINPAGO3sm66qkdEHHFnBQEZ93a7LnkTKpsivC1turfpo2QSb8j6nIrRqiYEMEREFMJBpYLwGNTIZEVYtZRllZGJYtRTaUE+bxVFnZLLTsmu1RoYZGSIikvGspQbGMCNjN1+11DgtPCMTy4Z4I88ejU9/2YarO4/XXFevgspOa2qh59HJ02AlnpJauR8REdV/DGQaGMMamQgZGaVGRl3sG7ZqyTyQOafZuVh/5dth19UZnqbptRPINE1vBgAoqiyslfsREVH9x6mlBsYbPDRSvfLISo2MOoOiX7UUafm1GXUgU1sZmWbpzQEARVVFtXI/IiKq/xjINDDyzr6ZzkbKtVhrZPQZmYjLr03Y4jC11DwYyFT4ylHpq6yVexIRUf3GQKaBkXf2dTvdyjV1jYzZ1FKkGplIU0tm1FNVzYJTQqcqy9VYKUQ+wawMERGBgUyD4w1uiJfpzFSuqWtk1FNI6fZ0uOzyhniRll/XICOj+mhl11KNjCAIaJoWrJNhIENERGAg0+DIGRn11JK6RsauClgaubKUx5GXX9egRkaVkWlaS1NLANA8Q66TKYQoiZAkqdbuTURE9Q8DmQYmVCNjnJFRZ14aqzap004taWtkXPY0xEq9g3BtZWSA0Mql3Ud3ov3y0zDns7/U2r2JiKj+YSDTwMirltyOUI1MhrpGBsaBjLbYV5uBaeluFXM/NMuvazEjI69cevOH9aj0VeLVfS9zp18iohTGQKaB8RpOLRlnZLI0GRnzqaXTMk+LvSNxysjIgcx3RfsAACeri/HV8S9r7f5ERFS/MJBpYDyGU0vGq5Y05x9FOP36tMw2MfdDnfmp3YxMYGpJQqg2Zsvhj2rt/kREVL8wkGlg5LOWNIGM3XjVknw8AaA/5FEbyLSuQUbGL/mUx01rafk1EMrIqG35mYEMEVGqYiDTwHgMN8Qzycg4VauWNFNLpx7IqM9DauxqEvPrzRjtSbP76E6Uectq7T2IiKj+YCDTwMg1MupiX9MamTSzVUuhGpnm6c01U1NWFVcVK4/1OwWfCn0gc1pmG3hFL7b/8kmtvQcREdUfDGQaGI/BhnhpquXT2lVLoUyJ2aql1jWojwECRbjx0CwjNLXUyt0aw84aAYDTS0REqYqBTAPjU2pkrKxayjK8rl61VKMVSwCK4xTIqOttzmrcDpe0HQwA+Pjwv+LyfkREVLcxkGlAJElS7ewbyshoa2RCmRezfWTUU0unNapbGZnmqmLfsxq3w4DTL4YAAd+f+A5Hyn6Jy3sSEVHdxUCmAfGJoZVCVlYtZZns7GuzhR63creuUV9y3C1q9LpoGruaKMvDz2x8FpqmN0OPlrkAgK0/fxyX9yQiorqLgUwDImdjgNinltQBjnofmZqsWAKApwcvwbAzL8Wm379Xo9ebEQRBmV46q3E7AMCgM4YAAD4+/M9afS8iIqr7khLIFBYWIj8/H71790ZeXh7mzp0Ln89n2HbLli0YPXo0evTogd/97nf46CMWdZqRz1kCALdTvWrJePm1WbGvemqpVWbNMjLtm5yNV0etQ782F9bo9ZG0a9weAHBe8/MBQCn4fe/Hv6PMU1rr70dERHVXUgKZadOmwe12Y9u2bVi3bh22b9+OF198MazdTz/9hClTpuCOO+7A7t27MWXKFEybNg3Hjh1LfKfrAU+w0BcAMtRnLakyMuqAxfTQSFWxb6sanLMUb88Mfx6vXv4GurXoAQDo07ovOmV3RoWvHBv2r0tu54iIKKEc0ZvUroMHD2Lnzp3YunUrMjIy0LZtW+Tn5+OJJ57ATTfdpGm7ceNG9O7dG8OGDQMAjBw5Ehs2bMDatWsxderUmN63vLwCkiSFXbfb7UhPT1e1Kze9h81mQ0ZGICj46deDeGnzJuS4T0NmWnjRrM1mQ1paGuS4oaqqCoJJ3CgIUPogBdsivKvBxlKwbeDG1dXVyvdV6CkAPIGMyvEDvwAewJnmxPEff1H68FPZT0AwcXPiwDFUOQIZjJOek8pbFB0+BngDnfH9XIkfj38X1g13RihQqq6ujnhwY0Z6BgSbgKrCTPx2/IRp9k1pGyxI9ng88PmN23ZAO/z6w0GlnmdU81GY/9tTWP75M+hU2T6svSstTWnr9Xrhj9AHp8sFu90ec1ufzwef13vqbQWgWbPGqKj0AhLg9/vh9XiM2wJwOJ1wOAJ/lWuzrd3hgNPpjLmtKIrwVFfXSlub3Q6XywUgUMxeXVWlbSAAWVkZKC2thM0Wpa3JfQGgqrKyVtoK8t/7mrStqgIMfkYFGguan1OxtK2uroYkisGvhcZL/hmTnpFh3NaAuq3H44HoN/97H0vbtPR0zd/72moby9/7sLZ+X9hYyZL+M0LXNtk/I9q37YLGjbJQXl6O8vJyw4+m0+lU/h6JoojKCH831G2tSHggs3//fmRnZ6NVq9C/9Dt06IAjR46gpKQEjRuHgoIffvgBnTt31ry+Y8eO2LdvX8zve8EFnVBaGj7tMGzYpVizJvSv+PPP74CKigrDe1x44QC89dZmAMDtbw7GjnkFgHFToA2Ayarn8wGcNGnbAsBtqudLABw3adsEwHTV8+cAHNE28cGHMbgKzkzgxoe86HogMAVzycPAlv+G2l3yyCDlsdsF4N7A47yDA3H2RuB//wFGPvI7w25Iq0OPxy0A1u006S+AsheAzODP1b88C7y0zbztb88ALYIfgdtWAks/NG/749NAu2BNsedVAH8HvsM+XIkrwhvnA2gZfPwRgC3m98XNAE4PPv4UwAcR2t4AQI6bdgLYHKHtdQDkj/MeAG9FaDsOwPnBx98CeCNC2ysB5AYffw/g1QhtRwLoG3z8I4CXIrQdDuCi4ONfACyP0HYQgMHBx78BWBqh7YUALg0+PgFgQYS2fQBcHnxcDuCJCG27A7gq+NgD4JEIbc8DMF71fE6Etp0ATFQ9n4tAoG/kLAA3qp4/jjr5M0LhBnC36vlKAAdN2joBzFY9Xw1gv0lbQDumrwP4T4S29wKQf29tBPB1hLYzAMhrGd4FsCtC2zsAyEe9/QPAZxHa8mdEQA1+RrS02bD0/PUYe/VVpk1nzJiJu+8O/JLZv/87DByYZ9r2ttumYs6ch9VHAEaU8ECmvLxcyWrI5OcVFRWaQMaobXp6ummgURMulwM5OVnRGwJwOu1K28ua/R678TzM/i1gA5Cu+kOoFCIkWYJt5eaViNBWANxC6HUVAMz+/dREAOZnZ6Ai+A9eUayO0Bq4IsOGDEGA3+tCJ0c1/hehbUV16M/FH+W+FZ7Qv6B8ogcwHTWgojodFdXBtv7IbSs9aaioDvwLyiF5AUT415YA2ILj5hUi3VXb1hfxroBTAOw1aStYb+sXzH9vAoBDCPxnqS1q1lYUlESeIbsQ6LOltqhZW0kAzHM3gT8zl9W2CLUFAPPcTWxtBQFIs9oWurYRfmjr21bD/GcEBO3PnohtoWsb4eeUvq0Hkf7Wx9Y2TQidW+sRrLf1wvrf5Zja8mdETG1bw42WLcLPwVNzu9OU359Nm2ZGbJuR4bL8exkABMloviWOPvjgA/zlL3/Bjh07lGvfffcdrrjiCuzevRtZWaHO/+lPf0K7du1wzz33KNfmzZuHw4cPY8mSJTG976FDx2p1aikwHWRDYWGpYRpN3RYIBGlmQy0IAtxud43aVlZWQoyQCs7MzKxR26qqKvgjpGxjaet2u2GzCWjePAtHjhTA6zX/6+l2u5Wgp7q6OvI0VEaGkgr2eDzwRkjDxtI2PT1dSdnG0tbr9cITIQ2blpampGwjtRUEoE2bHJw8WQlJCqSYqyNMv7hcLmWqJpa2fr8/MEVhQp3ejaVtLGnjaG0dDocy/SJJUtg/YgQBaN48C4WFpbDbI7dVi+XvfU1/RsTaNhE/I9TjJb+8rvyMsPr3PlE/I3w+b9hYyZL9M0Lfti78jBBFPzIznaa/E2vyM0L+vEaT8IxMp06dUFxcjIKCAuTk5AAADhw4gNatW2uCGADo3Lkzvv32W821H374AV27do35fd1ut+mUsvq62x05UlS3zczMRGWlaOm+Gaqaktpsm56eYd7wFNqmpUU+XymWtur2LlcanM40y21dLmttnU4XnM7Ic6rxbutwOOFwOE+5rSAEfoFLUqC93e6A2x35r6p831ja2mx2y5/3WNoKgi0ubQEhrK0gaP8eRmprft/Y/t7Hq20ifkboxytS22j3jefPCKt/7+P5M8LlckX8GZ/MnxH6tnXlZ4TV34mx/b2PLuGrltq1a4devXrhkUceQVlZGQ4fPoylS5di7NixYW2vuOIK7Ny5E5s3b4bP58PmzZuxc+dOXHnllYnuNhEREdVBSVl+vXDhQvh8PgwdOhTjx4/HwIEDkZ+fDwDIzc3Fpk2bAASKgJcsWYJly5ahT58+WLp0KRYtWoT27cNXpRAREVHqSXiNTLIUFBjP29WUIAA5OVm1ft+GiuNlHcfKOo5VbDhe1nGsYhOP8ZLvGQ2PKCAiIqJ6i4EMERER1VsMZIiIiKjeYiBDRERE9RYDGSIiIqq3GMgQERFRvcVAhoiIiOotBjJERERUbzGQISIionqLgQwRERHVWwk//TpZgqe+1/r9avu+DRXHyzqOlXUcq9hwvKzjWMUmHuNl9V4pc9YSERERNTycWiIiIqJ6i4EMERER1VsMZIiIiKjeYiBDRERE9RYDGSIiIqq3GMgQERFRvcVAhoiIiOotBjJERERUbzGQISIionqLgUwNFBYWIj8/H71790ZeXh7mzp0Ln8+X7G7VCZs3b8Z5552H3Nxc5b8ZM2YAAL7++muMGzcOubm5GDJkCN54440k9zZ5ioqKMHz4cOzYsUO5Fm18Nm7ciOHDh6NHjx4YM2YM9uzZk+huJ4XRWN1///3o2rWr5nO2du1a5eupOFb79u3DjTfeiL59++Kiiy7C3XffjaKiIgD8bOlFGit+tsJt374d48aNQ8+ePXHRRRfhoYceQlVVFYA68tmSKGbXX3+9dOedd0oVFRXSoUOHpMsvv1xavnx5srtVJ8ybN0+aOXNm2PXi4mKpb9++0iuvvCJ5vV7ps88+k3Jzc6Wvv/46Cb1Mrt27d0vDhg2TOnfuLH3++eeSJEUfn88//1zKzc2Vdu/eLXk8HmnlypVSXl6eVFFRkcxvJe6MxkqSJOmqq66SNmzYYPiaVByryspK6aKLLpIWLFggVVdXS0VFRdLNN98s3XLLLfxs6UQaK0niZ0uvsLBQuuCCC6T169dLfr9fOnbsmDRq1ChpwYIFdeazxYxMjA4ePIidO3dixowZyMjIQNu2bZGfn4/Vq1cnu2t1wjfffIOuXbuGXf/HP/6B7OxsTJw4EQ6HA/3798fo0aNTbtw2btyIu+66C9OnT9dcjzY+b7zxBi6//HL06tULTqcTf/jDH9C0aVNs3rw5Gd9GQpiNlcfjwffff2/4OQNSc6yOHDmCc845B7fddhtcLheaNm2KCRMmYNeuXfxs6UQaK362wjVr1gyfffYZxowZA0EQUFxcjOrqajRr1qzOfLYYyMRo//79yM7ORqtWrZRrHTp0wJEjR1BSUpLEniWfKIr49ttv8fHHH2Pw4MG4+OKL8de//hUnT57E/v370blzZ037jh07Yt++fUnqbXIMGDAAH3zwAUaOHKm5Hm18fvjhh5QbP7Ox2rdvH3w+HxYuXIgLL7wQI0aMwHPPPQdRFAGk5lidffbZeP7552G325Vr77//Ps4//3x+tnQijRU/W8YaNWoEABg0aBBGjx6NFi1aYMyYMXXms8VAJkbl5eXIyMjQXJOfV1RUJKNLdUZRURHOO+88jBgxAps3b8Zrr72Gn376CTNmzDAct/T09JQbsxYtWsDhcIRdjzY+qTh+ZmNVWlqKvn37YtKkSdiyZQueeOIJvPzyy1ixYgWA1BwrNUmSMH/+fHz00UeYPXs2P1sR6MeKn63I/vGPf2Dr1q2w2WyYOnVqnflsMZCJkdvtRmVlpeaa/DwzMzMZXaozcnJysHr1aowdOxYZGRlo06YNZsyYga1bt0KSJKU4TFZVVZXyYybLyMiIOD7Rvp5KLrroIqxatQp9+/aF0+lEt27dcMMNNyjp6lQeq7KyMkydOhVvv/02XnnlFXTp0oWfLRNGY8XPVmTp6elo1aoVZsyYgW3bttWZzxYDmRh16tQJxcXFKCgoUK4dOHAArVu3RlZWVhJ7lnz79u3Dk08+CUmSlGsejwc2mw3dunXD/v37Ne1/+OEHdOrUKdHdrJM6d+4ccXw6derE8Qv68MMP8dprr2mueTwepKenA0jdsTp06BCuvvpqlJWVYd26dejSpQsAfraMmI0VP1vhvvzyS1x22WXweDzKNY/HA6fTiY4dO9aNz1atlg6niGuvvVaaPn26VFpaqqxaWrhwYbK7lXS//vqr1KNHD+m5556TvF6v9Msvv0jjx4+X7r33XqmoqEjq3bu3tHLlSsnj8Ujbt2+XcnNzpe3btye720mjXokTbXzk1QDbt29Xqv/79OkjnThxIonfQeKox+of//iH1K1bN+mzzz6TRFGUvvzySykvL0968803JUlKzbEqLi6WLrnkEmnmzJmS3+/XfI2fLa1IY8XPVriysjJp0KBB0iOPPCJVV1dLP//8szR27Fjp/vvvrzOfLQYyNXD8+HFpypQpUt++faV+/fpJ8+bNk3w+X7K7VSfs2LFDmjBhgpSbmyv169dPeuihh6SqqipJkiRp7969yteGDh0qrV+/Psm9TS79kuJo4/Pmm29KI0aMkHr06CGNHTtW+uqrrxLd5aTRj9WaNWukSy+9VOrevbs0dOhQ6ZVXXtG0T7WxWrFihdS5c2epe/fuUo8ePTT/SRI/W2rRxoqfrXD79++XbrzxRql3797S4MGDpaeeekqqrq6WJKlufLYESVLNAxARERHVI6yRISIionqLgQwRERHVWwxkiIiIqN5iIENERET1FgMZIiIiqrcYyBAREVG9xUCGiBLmt99+i+u5NPG+PxHVPQxkiCiuJk2ahEWLFqGgoAAjRoxAUVFRXN5Hf/9nn30WN910U1zei4jqjvCjZYmI4qCqqiqu2RL9/W+99da4vRcR1R3MyBBR3Pn9fowaNQoAMGrUKOU04XfffRejR49Gr169MGbMGHzyySfKayZNmoSZM2di8ODBuOSSS1BWVoZ//etfuOaaa9C/f390794d119/PX766SfD+y9atAiTJk1S7vfhhx9izJgx6NmzJ0aMGIEXX3wRoigCAGbOnIn77rsPt956K3JzczF06FCsWrUqUcNDRKeAgQwRxZ3dbsc777wDAHjnnXcwcuRIbNmyBffffz/uu+8+7Ny5E1OmTMGUKVM0p+V+9tlneO2117Bp0yaUlZXhjjvuwOTJk7F9+3Z8/PHHkCQJS5YsMby/2ueff45p06bhpptuws6dO/HUU09h5cqVmmBlw4YNmDRpEnbt2oWbb74Z8+bNw7FjxxIwOkR0KhjIEFFSvPLKK7j22mvRp08f2O12DB48GEOGDMFrr72mtLn44ovRqlUrNG7cGM2aNcO7776LIUOGoKysDEePHkXTpk0tBRsbNmzA0KFDMXLkSDgcDpx//vmYPHmy5r3y8vJw0UUXweFw4Oqrr4bf78ehQ4fi8r0TUe1hjQwRJcUvv/yCnTt3Ys2aNco1v9+Pfv36Kc9btmypPHY6nXjnnXfw2muvQRAEdO7cGWVlZXA4ov8YKywsxLnnnqu5dsYZZ+CXX35Rnrdo0ULzXgCUqSciqrsYyBBRUrRu3Rq///3vMXnyZOXakSNHkJ6erjwXBEF5/Pe//x2vvPIK1qxZg7POOgsA8NBDD+H777+P+l6nn356WHbl8OHDmuCFiOonTi0RUUKkpaUBAMrKygAA48ePx6pVq7B3714AwDfffIMxY8YotS56paWlsNlsSE9PhyRJ2Lp1K9588014vV7D+6tdffXV+Ne//oW///3v8Pv9+M9//oPly5fj6quvrvXvk4gSixkZIkqInJwcDB8+HBMmTMDMmTNx7bXXoqKiAvfeey+OHDmC7Oxs/OEPf9CsNFK76qqr8MUXX+Dyyy+H3W7H2WefjRtuuAGrV6+Gx+MJu79a9+7dsWDBAixZsgT33nsvmjZtimuvvRY333xzIr51IoojQZIkKdmdICIiIqoJTi0RERFRvcVAhoiIiOotBjJERERUbzGQISIionqLgQwRERHVWwxkiIiIqN5iIENERET1FgMZIiIiqrcYyBAREVG9xUCGiIiI6i0GMkRERFRvMZAhIiKieuv/A/0C0QHKoAXtAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the lists\n",
    "labels = [\"4\", \"6\", \"8\", \"10\", \"15\", \"20\"]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"yellow\"]\n",
    "\n",
    "# Plot the data\n",
    "for i, (acc, label, color) in enumerate(zip(acc_lists1, labels, colors)):\n",
    "    plt.plot(acc, label=label, color=color)\n",
    "\n",
    "# Add a horizontal line at y = -1\n",
    "plt.axhline(y=-0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss for different dimensions, σ = 100\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T22:02:38.359206Z",
     "end_time": "2023-05-05T22:02:38.500925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n"
     ]
    },
    {
     "ename": "InconclusiveDimensionOperation",
     "evalue": "Cannot divide evenly the sizes of shapes (300, 9) and (300, 15, 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInconclusiveDimensionOperation\u001B[0m            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m funnel_config \u001B[38;5;241m=\u001B[39m set_task(funnel_config, task, div, c)\n\u001B[1;32m      7\u001B[0m funnel_config\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39minput_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9\u001B[39m\n\u001B[0;32m----> 8\u001B[0m out_dict \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunnel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m out_dicts2\u001B[38;5;241m.\u001B[39mappend(out_dict)\n\u001B[1;32m     10\u001B[0m acc_lists2\u001B[38;5;241m.\u001B[39mappend([x\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m out_dict[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m]])\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/train_dds.py:234\u001B[0m, in \u001B[0;36mtrain_dds\u001B[0;34m(config)\u001B[0m\n\u001B[1;32m    228\u001B[0m subkeys \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mbcast_local_devices(rng_key)\n\u001B[1;32m    230\u001B[0m p_init \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mpmap(\n\u001B[1;32m    231\u001B[0m     functools\u001B[38;5;241m.\u001B[39mpartial(forward_fn\u001B[38;5;241m.\u001B[39minit, batch_size\u001B[38;5;241m=\u001B[39mbatch_size_,\n\u001B[1;32m    232\u001B[0m                       training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), axis_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_devices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 234\u001B[0m params, model_state \u001B[38;5;241m=\u001B[39m p_init(subkeys)\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m#hcb.id_print(params)\u001B[39;00m\n\u001B[1;32m    238\u001B[0m trainable_params, non_trainable_params \u001B[38;5;241m=\u001B[39m hk\u001B[38;5;241m.\u001B[39mdata_structures\u001B[38;5;241m.\u001B[39mpartition(\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m module, name, value: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstl_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m module, params)\n",
      "    \u001B[0;31m[... skipping hidden 12 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/transform.py:338\u001B[0m, in \u001B[0;36mtransform_with_state.<locals>.init_fn\u001B[0;34m(rng, *args, **kwargs)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m base\u001B[38;5;241m.\u001B[39mnew_context(rng\u001B[38;5;241m=\u001B[39mrng) \u001B[38;5;28;01mas\u001B[39;00m ctx:\n\u001B[1;32m    337\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 338\u001B[0m     \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    339\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m jax\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mUnexpectedTracerError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m jax\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mUnexpectedTracerError(unexpected_tracer_hint) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/train_dds.py:219\u001B[0m, in \u001B[0;36mtrain_dds.<locals>._forward_fn\u001B[0;34m(batch_size, training, ode, exact, dt_, new_target)\u001B[0m\n\u001B[1;32m    207\u001B[0m model_def \u001B[38;5;241m=\u001B[39m ref_proc(\n\u001B[1;32m    208\u001B[0m     sigma, data_dim, drift_network, tfinal\u001B[38;5;241m=\u001B[39mtfinal, dt\u001B[38;5;241m=\u001B[39mdt_,\n\u001B[1;32m    209\u001B[0m     step_scheme\u001B[38;5;241m=\u001B[39mstep_scheme, alpha\u001B[38;5;241m=\u001B[39malpha, target\u001B[38;5;241m=\u001B[39mtarget, tpu\u001B[38;5;241m=\u001B[39mtpu,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    212\u001B[0m     m\u001B[38;5;241m=\u001B[39mm, log\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mlog, exp_bool\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mexp_dds, exact\u001B[38;5;241m=\u001B[39mexact\n\u001B[1;32m    213\u001B[0m )\n\u001B[1;32m    215\u001B[0m \u001B[38;5;66;03m# print(batch_size)\u001B[39;00m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;66;03m# print(training)\u001B[39;00m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;66;03m# print(ode)\u001B[39;00m\n\u001B[0;32m--> 219\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_def\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:426\u001B[0m, in \u001B[0;36mwrap_method.<locals>.wrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m method_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__call__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    424\u001B[0m     f \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mnamed_call(f, name\u001B[38;5;241m=\u001B[39mmethod_name)\n\u001B[0;32m--> 426\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001B[39;00m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;66;03m# execution with `named_call`.\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:272\u001B[0m, in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m interceptor_stack:\n\u001B[0;32m--> 272\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m ctx \u001B[38;5;241m=\u001B[39m MethodContext(module\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m                     method_name\u001B[38;5;241m=\u001B[39mmethod_name,\n\u001B[1;32m    276\u001B[0m                     orig_method\u001B[38;5;241m=\u001B[39mbound_method)\n\u001B[1;32m    277\u001B[0m interceptor_stack_copy \u001B[38;5;241m=\u001B[39m interceptor_stack\u001B[38;5;241m.\u001B[39mclone()\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/stl_samplers.py:71\u001B[0m, in \u001B[0;36mAugmentedBrownianFollmerSDESTL.__call__\u001B[0;34m(self, batch_size, is_training, dt, ode, exact)\u001B[0m\n\u001B[1;32m     69\u001B[0m key \u001B[38;5;241m=\u001B[39m hk\u001B[38;5;241m.\u001B[39mnext_rng_key()\n\u001B[1;32m     70\u001B[0m dt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdt \u001B[38;5;28;01mif\u001B[39;00m dt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m is_training \u001B[38;5;28;01melse\u001B[39;00m dt\n\u001B[0;32m---> 71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_aug_trajectory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexact\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexact\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:426\u001B[0m, in \u001B[0;36mwrap_method.<locals>.wrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m method_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__call__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    424\u001B[0m     f \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mnamed_call(f, name\u001B[38;5;241m=\u001B[39mmethod_name)\n\u001B[0;32m--> 426\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001B[39;00m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;66;03m# execution with `named_call`.\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:272\u001B[0m, in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m interceptor_stack:\n\u001B[0;32m--> 272\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m ctx \u001B[38;5;241m=\u001B[39m MethodContext(module\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m                     method_name\u001B[38;5;241m=\u001B[39mmethod_name,\n\u001B[1;32m    276\u001B[0m                     orig_method\u001B[38;5;241m=\u001B[39mbound_method)\n\u001B[1;32m    277\u001B[0m interceptor_stack_copy \u001B[38;5;241m=\u001B[39m interceptor_stack\u001B[38;5;241m.\u001B[39mclone()\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/stl_samplers.py:389\u001B[0m, in \u001B[0;36mAugmentedOUDFollmerSDESTL.sample_aug_trajectory\u001B[0;34m(self, batch_size, key, dt, rng, ode, exact, **_)\u001B[0m\n\u001B[1;32m    386\u001B[0m ddpm_param \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexp_bool\n\u001B[1;32m    387\u001B[0m integrator \u001B[38;5;241m=\u001B[39m partial(odeint_em_scan_ou, exact\u001B[38;5;241m=\u001B[39mexact) \u001B[38;5;28;01mif\u001B[39;00m ode \u001B[38;5;28;01melse\u001B[39;00m sdeint_ito_em_scan_ou\n\u001B[0;32m--> 389\u001B[0m param_trajectory, ts \u001B[38;5;241m=\u001B[39m \u001B[43mintegrator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_aug\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mg_aug\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my0_aug\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtfinal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_scheme\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_scheme\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mddpm_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mddpm_param\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m param_trajectory, ts\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/solvers.py:176\u001B[0m, in \u001B[0;36msdeint_ito_em_scan_ou\u001B[0;34m(dim, alpha, f, g, y0, rng, args, dt, step_scheme, start, end, dtype, scheme_args, ddpm_param)\u001B[0m\n\u001B[1;32m    173\u001B[0m   out \u001B[38;5;241m=\u001B[39m (y, t_, rng)\n\u001B[1;32m    174\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out, y\n\u001B[0;32m--> 176\u001B[0m _, ys \u001B[38;5;241m=\u001B[39m \u001B[43mhk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan\u001B[49m\u001B[43m(\u001B[49m\u001B[43meuler_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_pas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrng\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mswapaxes(np\u001B[38;5;241m.\u001B[39mconcatenate((y0[\u001B[38;5;28;01mNone\u001B[39;00m], ys), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m), ts\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/stateful.py:611\u001B[0m, in \u001B[0;36mscan\u001B[0;34m(f, init, xs, length, reverse, unroll)\u001B[0m\n\u001B[1;32m    609\u001B[0m   x0 \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mtree_util\u001B[38;5;241m.\u001B[39mtree_map(\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;241m0\u001B[39m], xs)\n\u001B[1;32m    610\u001B[0m   xs \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mtree_util\u001B[38;5;241m.\u001B[39mtree_map(\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;241m1\u001B[39m:], xs)\n\u001B[0;32m--> 611\u001B[0m init, y0 \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    612\u001B[0m y0 \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mtree_util\u001B[38;5;241m.\u001B[39mtree_map(\u001B[38;5;28;01mlambda\u001B[39;00m y: jnp\u001B[38;5;241m.\u001B[39mexpand_dims(y, \u001B[38;5;241m0\u001B[39m), y0)\n\u001B[1;32m    613\u001B[0m length \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/solvers.py:136\u001B[0m, in \u001B[0;36msdeint_ito_em_scan_ou.<locals>.euler_step\u001B[0;34m(ytpas, t_)\u001B[0m\n\u001B[1;32m    132\u001B[0m noise \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal(this_rng, y_pas\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m    134\u001B[0m y_pas_naug \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mlax\u001B[38;5;241m.\u001B[39mstop_gradient(\n\u001B[1;32m    135\u001B[0m     y_pas[:, :dim]) \u001B[38;5;28;01mif\u001B[39;00m detach \u001B[38;5;28;01melse\u001B[39;00m y_pas[:, :dim]\n\u001B[0;32m--> 136\u001B[0m g_aug \u001B[38;5;241m=\u001B[39m \u001B[43mg\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_pas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m f_aug \u001B[38;5;241m=\u001B[39m f(y_pas, t_pas, args)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# State update\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:426\u001B[0m, in \u001B[0;36mwrap_method.<locals>.wrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m method_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__call__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    424\u001B[0m     f \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mnamed_call(f, name\u001B[38;5;241m=\u001B[39mmethod_name)\n\u001B[0;32m--> 426\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001B[39;00m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;66;03m# execution with `named_call`.\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:272\u001B[0m, in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m interceptor_stack:\n\u001B[0;32m--> 272\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m ctx \u001B[38;5;241m=\u001B[39m MethodContext(module\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m                     method_name\u001B[38;5;241m=\u001B[39mmethod_name,\n\u001B[1;32m    276\u001B[0m                     orig_method\u001B[38;5;241m=\u001B[39mbound_method)\n\u001B[1;32m    277\u001B[0m interceptor_stack_copy \u001B[38;5;241m=\u001B[39m interceptor_stack\u001B[38;5;241m.\u001B[39mclone()\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/stl_samplers.py:365\u001B[0m, in \u001B[0;36mAugmentedOUDFollmerSDESTL.g_aug\u001B[0;34m(self, y, t, args)\u001B[0m\n\u001B[1;32m    363\u001B[0m   u_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdetached_drift(y_no_aug, t_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget)\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 365\u001B[0m   u_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrift_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_no_aug\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    367\u001B[0m delta_t \u001B[38;5;241m=\u001B[39m (u_t)  \u001B[38;5;241m/\u001B[39m gamma_t\n\u001B[1;32m    369\u001B[0m out \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((gamma_t, delta_t, zeros), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:426\u001B[0m, in \u001B[0;36mwrap_method.<locals>.wrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m method_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__call__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    424\u001B[0m     f \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mnamed_call(f, name\u001B[38;5;241m=\u001B[39mmethod_name)\n\u001B[0;32m--> 426\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001B[39;00m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;66;03m# execution with `named_call`.\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/module.py:272\u001B[0m, in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m interceptor_stack:\n\u001B[0;32m--> 272\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m ctx \u001B[38;5;241m=\u001B[39m MethodContext(module\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m                     method_name\u001B[38;5;241m=\u001B[39mmethod_name,\n\u001B[1;32m    276\u001B[0m                     orig_method\u001B[38;5;241m=\u001B[39mbound_method)\n\u001B[1;32m    277\u001B[0m interceptor_stack_copy \u001B[38;5;241m=\u001B[39m interceptor_stack\u001B[38;5;241m.\u001B[39mclone()\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/drift_nets.py:308\u001B[0m, in \u001B[0;36mPISGRADNet.__call__\u001B[0;34m(self, input_array, time_array, target, training, ode)\u001B[0m\n\u001B[1;32m    306\u001B[0m     grad_bool \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_grad \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ode\n\u001B[1;32m    307\u001B[0m     \u001B[38;5;66;03m# Using score information as a feature\u001B[39;00m\n\u001B[0;32m--> 308\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[43mhk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_x\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_x\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_array\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;66;03m#     print(\"grad bool\", grad_bool)\u001B[39;00m\n\u001B[1;32m    310\u001B[0m     grad \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mlax\u001B[38;5;241m.\u001B[39mstop_gradient(grad) \u001B[38;5;28;01mif\u001B[39;00m grad_bool \u001B[38;5;28;01melse\u001B[39;00m grad\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/stateful.py:152\u001B[0m, in \u001B[0;36mgrad.<locals>.grad_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fun)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrad_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 152\u001B[0m   value, grads \u001B[38;5;241m=\u001B[39m \u001B[43mvalue_and_grad_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m has_aux:\n\u001B[1;32m    154\u001B[0m     value, aux \u001B[38;5;241m=\u001B[39m value\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/stateful.py:224\u001B[0m, in \u001B[0;36mvalue_and_grad.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(grad_fun)\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    223\u001B[0m   kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhk_state\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m internal_state()\n\u001B[0;32m--> 224\u001B[0m   (value, (aux, hk_state)), grads \u001B[38;5;241m=\u001B[39m \u001B[43mgrad_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    225\u001B[0m   update_internal_state(hk_state)\n\u001B[1;32m    226\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m has_aux:\n",
      "    \u001B[0;31m[... skipping hidden 8 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/haiku/_src/stateful.py:213\u001B[0m, in \u001B[0;36mvalue_and_grad.<locals>.stateful_fun\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m state_in \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhk_state\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m temporary_internal_state(state_in), \\\n\u001B[1;32m    212\u001B[0m      base\u001B[38;5;241m.\u001B[39mpush_jax_trace_level():\n\u001B[0;32m--> 213\u001B[0m   out \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m   out, aux \u001B[38;5;241m=\u001B[39m (out \u001B[38;5;28;01mif\u001B[39;00m has_aux \u001B[38;5;28;01melse\u001B[39;00m (out, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    215\u001B[0m   state_out \u001B[38;5;241m=\u001B[39m difference(state_in, internal_state())\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/drift_nets.py:308\u001B[0m, in \u001B[0;36mPISGRADNet.__call__.<locals>.<lambda>\u001B[0;34m(_x)\u001B[0m\n\u001B[1;32m    306\u001B[0m     grad_bool \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_grad \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ode\n\u001B[1;32m    307\u001B[0m     \u001B[38;5;66;03m# Using score information as a feature\u001B[39;00m\n\u001B[0;32m--> 308\u001B[0m     grad \u001B[38;5;241m=\u001B[39m hk\u001B[38;5;241m.\u001B[39mgrad(\u001B[38;5;28;01mlambda\u001B[39;00m _x: \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_x\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msum())(input_array)\n\u001B[1;32m    309\u001B[0m \u001B[38;5;66;03m#     print(\"grad bool\", grad_bool)\u001B[39;00m\n\u001B[1;32m    310\u001B[0m     grad \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mlax\u001B[38;5;241m.\u001B[39mstop_gradient(grad) \u001B[38;5;28;01mif\u001B[39;00m grad_bool \u001B[38;5;28;01melse\u001B[39;00m grad\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/targets/toy_targets.py:311\u001B[0m, in \u001B[0;36mbreast_target_class.breast\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    308\u001B[0m   V_x \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mV_x \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiv) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39me\n\u001B[1;32m    309\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m V_x \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43munbatched\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping hidden 3 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/targets/toy_targets.py:307\u001B[0m, in \u001B[0;36mbreast_target_class.breast.<locals>.unbatched\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munbatched\u001B[39m(x):\n\u001B[1;32m    305\u001B[0m   \u001B[38;5;66;03m#div, e, other_dim = get_attr()\u001B[39;00m\n\u001B[1;32m    306\u001B[0m   v \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m--> 307\u001B[0m   V_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m   V_x \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mV_x \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiv) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39me\n\u001B[1;32m    309\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m V_x \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/dds/targets/toy_targets.py:299\u001B[0m, in \u001B[0;36mbreast_target_class.f\u001B[0;34m(self, v, type)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(\u001B[38;5;28mself\u001B[39m, v, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 299\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbreast_task\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Masters/MetaDDS_Jax/denoising_diffusion_samplers/experimental/breastcancer_t.py:200\u001B[0m, in \u001B[0;36mbreast_task.get_loss\u001B[0;34m(self, parameters, type)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, parameters, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 200\u001B[0m     l, b, l1, b1 \u001B[38;5;241m=\u001B[39m \u001B[43mparameters\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m, parameters[\u001B[38;5;241m150\u001B[39m:\u001B[38;5;241m160\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m10\u001B[39m), parameters[\u001B[38;5;241m160\u001B[39m:\u001B[38;5;241m170\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m), parameters[\u001B[38;5;241m170\u001B[39m:]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39marray(l)\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear_1\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39marray(l1)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:812\u001B[0m, in \u001B[0;36m_reshape\u001B[0;34m(a, order, *args)\u001B[0m\n\u001B[1;32m    810\u001B[0m newshape \u001B[38;5;241m=\u001B[39m _compute_newshape(a, args[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m args)\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m order \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 812\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m order \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    814\u001B[0m   dims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(ndim(a))[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n",
      "    \u001B[0;31m[... skipping hidden 20 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Py310/lib/python3.10/site-packages/jax/_src/core.py:1833\u001B[0m, in \u001B[0;36mDimensionHandler.divide_shape_sizes\u001B[0;34m(self, s1, s2)\u001B[0m\n\u001B[1;32m   1831\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1832\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sz1 \u001B[38;5;241m%\u001B[39m sz2:\n\u001B[0;32m-> 1833\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m InconclusiveDimensionOperation(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot divide evenly the sizes of shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(s1)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(s2)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1834\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sz1 \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m sz2\n",
      "\u001B[0;31mInconclusiveDimensionOperation\u001B[0m: Cannot divide evenly the sizes of shapes (300, 9) and (300, 15, 10)"
     ]
    }
   ],
   "source": [
    "div = 1000\n",
    "funnel_config.trainer.epochs = 300\n",
    "acc_lists2 = []\n",
    "out_dicts2 = []\n",
    "for div in [1, 0.5, 0.2]:\n",
    "    funnel_config = set_task(funnel_config, task, div, c)\n",
    "    funnel_config.model.input_dim = 9\n",
    "    out_dict = train_dds(funnel_config)\n",
    "    out_dicts2.append(out_dict)\n",
    "    acc_lists2.append([x.item() for x in out_dict[-1][\"training_loss\"]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the lists\n",
    "labels = [\"4\", \"6\", \"8\", \"10\", \"15\", \"20\"]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"yellow\"]\n",
    "\n",
    "# Plot the data\n",
    "for i, (acc, label, color) in enumerate(zip(acc_lists2, labels, colors)):\n",
    "    plt.plot(acc, label=label, color=color)\n",
    "\n",
    "# Add a horizontal line at y = -1\n",
    "plt.axhline(y=-0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss for different dimensions, σ = 1000\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T06:06:56.362024Z",
     "end_time": "2023-05-03T06:57:19.655041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utility_func import *\n",
    "import visualisation\n",
    "plot_training_loss(out_dict[-1][\"elbo\"])\n",
    "print(out_dict[-1][\"elbo\"][-1])\n",
    "visualisation.heat_2d(out_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:19.669854Z",
     "end_time": "2023-05-03T06:57:27.326606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.327598Z",
     "end_time": "2023-05-03T06:57:27.331857Z"
    }
   },
   "outputs": [],
   "source": [
    "out_dict[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.333139Z",
     "end_time": "2023-05-03T06:57:27.336573Z"
    }
   },
   "outputs": [],
   "source": [
    "onp.mean(out_dict[-1][\"is_eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.340408Z",
     "end_time": "2023-05-03T06:57:27.342755Z"
    }
   },
   "outputs": [],
   "source": [
    "onp.mean(out_dict[-1][\"pf_eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.343911Z",
     "end_time": "2023-05-03T06:57:27.390183Z"
    }
   },
   "outputs": [],
   "source": [
    "out_dict[-1][\"pf_eval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "loss_list1, loss_list2, loss_list3 = [], [], []\n",
    "\n",
    "for i in acc_lists:\n",
    "    #loss_list1.append(np.log(min(i)))\n",
    "    loss_list1.append(min(i))\n",
    "\n",
    "for i in acc_lists1:\n",
    "    #loss_list2.append(np.log(min(i)))\n",
    "    loss_list2.append(min(i))\n",
    "\n",
    "for i in acc_lists2:\n",
    "    #loss_list3.append(np.log(min(i)))\n",
    "    loss_list3.append(min(i))\n",
    "\n",
    "# Combine the lists\n",
    "loss_lists = [loss_list1, loss_list2, loss_list3]\n",
    "labels = ['σ = 10', 'σ = 100', 'σ = 1000']\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "# Custom x-axis labels\n",
    "x_labels = [\"4\", \"6\", \"8\", \"10\", \"15\", \"20\"]\n",
    "\n",
    "# Plot the data\n",
    "for i, (loss, label, color) in enumerate(zip(loss_lists, labels, colors)):\n",
    "    plt.plot(x_labels, loss, label=label, color=color, marker=\"o\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"X-axis Label\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs. X-axis Label\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T15:28:10.455163Z",
     "end_time": "2023-05-03T15:28:10.753031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.348210Z",
     "end_time": "2023-05-03T06:57:27.390284Z"
    }
   },
   "outputs": [],
   "source": [
    "funnel_config.model.reference_process_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(out_dict[-1][\"aug\"].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.352563Z",
     "end_time": "2023-05-03T06:57:27.390347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:57:27.362682Z",
     "end_time": "2023-05-03T06:57:27.730526Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ode_targ = out_dict[-1][\"aug_ode\"][:, -1,:2]\n",
    "sde_targ = out_dict[-1][\"aug\"][:, -1,:2]\n",
    "\n",
    "#plt.plot(ode_targ[:, 0], abs(ode_targ[:, 1]), \".\", alpha=0.4)\n",
    "plt.plot(sde_targ[:, 0])#, sde_targ[:, 1], \".\", alpha=0.4)\n",
    "#print(onp.mean(sde_targ[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_x = []\n",
    "data_fx = []\n",
    "for sample in out_dict[-1][\"aug\"]:\n",
    "    x = sample[-1][:input_dim-1]\n",
    "    fx = abs(sample[-1][input_dim-1])\n",
    "    data_x.append(x)\n",
    "    data_fx.append(fx)\n",
    "\n",
    "m = np.argmax(data_fx)\n",
    "print(f\"weights: {data_x[m]}\")\n",
    "\n",
    "\n",
    "# Create a list of tuples containing x, y, and z values\n",
    "combined_data = zip(data_x, data_fx)\n",
    "\n",
    "# Sort the combined data based on the z values in descending order\n",
    "sorted_data = sorted(combined_data, key=lambda t: t[1], reverse=True)\n",
    "\n",
    "# Unzip the sorted data back into separate x, y, and z lists\n",
    "data_x_sorted, data_fx_sorted = zip(*sorted_data)\n",
    "\n",
    "best = np.array(list(zip(data_x_sorted, data_fx_sorted)))[:100]\n",
    "# avg = np.mean(best, axis=0)\n",
    "# v, w = avg\n",
    "# print(np.sin(3*np.pi*v) + (v - 1)**2 * (1+np.sin(3*np.pi*w)**2) + (w-1)**2 * (1 + np.sin(2*np.pi*w)**2))\n",
    "# print(avg)\n",
    "#print(best)\n",
    "# for v,w in best:\n",
    "#     v = np.sin(3*np.pi*v) + (v - 1)**2 * (1+np.sin(3*np.pi*w)**2) + (w-1)**2 * (1 + np.sin(2*np.pi*w)**2)\n",
    "#     print(v)\n",
    "from experimental.xor_t import xor_task\n",
    "task = xor_task()\n",
    "b = 1\n",
    "w = None\n",
    "print(len(data_x))\n",
    "for weights in data_x:\n",
    "#for weights, _ in best:\n",
    "    l = task.get_loss(weights)\n",
    "    #print(l)\n",
    "    if l < b:\n",
    "        b = l\n",
    "        w = weights\n",
    "\n",
    "print(b, w)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T02:16:12.326052Z",
     "end_time": "2023-04-27T02:16:24.838047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from visualisation import *\n",
    "\n",
    "heat_2d(out_dict, save_name=save_name, sde=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T02:16:24.838719Z",
     "end_time": "2023-04-27T02:16:29.164931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = []\n",
    "for sample in out_dict[-1][\"aug\"]:\n",
    "    s = sample[-1]\n",
    "    data.append(s)\n",
    "\n",
    "# Compute the histogram values\n",
    "hist, bin_edges = np.histogram(data, bins=100)\n",
    "\n",
    "# Compute the bin centers\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Create a line plot using Seaborn\n",
    "sns.lineplot(x=bin_centers, y=hist)\n",
    "\n",
    "# Set the x and y axis labels\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='x=0.3', alpha=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T17:04:32.657248Z",
     "end_time": "2023-05-01T17:04:34.167125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dds.targets.toy_targets import *\n",
    "\n",
    "car = carillo_target_class()\n",
    "x_values = np.linspace(-10, 10, 1000)\n",
    "\n",
    "# Compute the corresponding y values\n",
    "# using the provided function\n",
    "y_values = np.exp(-car.f(x_values) / 10)\n",
    "\n",
    "#y_values = -norm.logpdf(y_values,loc=0., scale=1.)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel(\"v\")\n",
    "plt.ylabel(\"f(v)\")\n",
    "plt.title(\"Plot of the function f(v)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T23:56:58.056304Z",
     "end_time": "2023-04-29T23:56:58.239384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dds.targets.toy_targets import *\n",
    "\n",
    "\n",
    "def temp(x):\n",
    "    tc = levy_target_class(0,0)\n",
    "    k = np.exp(-tc.f(x)/10) * 1000\n",
    "    return k\n",
    "\n",
    "def rosenbrock_function(x):\n",
    "    return np.exp(-((1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2)/0.01)\n",
    "\n",
    "def rastrigin_function(x, A=10):\n",
    "    n = len(x)\n",
    "    return np.exp(-(A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x)))/1)\n",
    "\n",
    "# Create a grid of points for the plot\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Evaluate the Rosenbrock function for each point in the grid\n",
    "Z = np.array([temp(np.array([x, y])) for x, y in zip(np.ravel(X), np.ravel(Y))])\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "# Create a contour plot\n",
    "plt.figure()\n",
    "plt.contourf(X, Y, Z, levels=100, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Rosenbrock Function')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T01:45:41.384062Z",
     "end_time": "2023-05-03T01:45:43.294212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import logsumexp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def euclidean_distance_einsum(x, y):\n",
    "    \"\"\"Efficiently calculates the euclidean distance between vectors in two mats.\n",
    "\n",
    "\n",
    "    Args:\n",
    "      x: first matrix (nxd)\n",
    "      y: second matrix (mxd)\n",
    "\n",
    "    Returns:\n",
    "      pairwise distance matrix (nxm)\n",
    "    \"\"\"\n",
    "    xx = jnp.einsum('ij,ij->i', x, x)[:, jnp.newaxis]\n",
    "    yy = jnp.einsum('ij,ij->i', y, y)\n",
    "    xy = 2 * jnp.dot(x, y.T)\n",
    "    out = xx + yy - xy\n",
    "\n",
    "    return out\n",
    "\n",
    "def log_p_pure(x):\n",
    "    \"\"\"Gaussian mixture density on well like structure.\n",
    "\n",
    "    Args:\n",
    "      x: vectors over which to evaluate the density\n",
    "\n",
    "    Returns:\n",
    "      nx1 vector containing density evaluations\n",
    "    \"\"\"\n",
    "\n",
    "    mu = 1.0\n",
    "    sigma2_ = 0.05\n",
    "    mus_full = np.array([\n",
    "        [- mu, 0.0],\n",
    "        [- mu, mu],\n",
    "        [- mu, -mu],\n",
    "        [- mu, 2 * mu],\n",
    "        [- mu, - 2 * mu],\n",
    "        [mu, 0.0],\n",
    "        [mu, mu],\n",
    "        [mu, -mu],\n",
    "        [mu, 2 * mu],\n",
    "        [mu, - 2 * mu],\n",
    "    ])\n",
    "    dist_to_means = euclidean_distance_einsum(x, mus_full)\n",
    "\n",
    "    out = logsumexp(-dist_to_means / (0.01 * sigma2_), axis=1)\n",
    "\n",
    "    return out\n",
    "\n",
    "#print(log_p_pure(jnp.array([1,2]).reshape(1,2)))\n",
    "\n",
    "x = np.linspace(-2, 2, 100)\n",
    "y = np.linspace(-2, 2, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Evaluate the Rosenbrock function for each point in the grid\n",
    "Z = np.array([log_p_pure(np.array([x, y]).reshape(1,2)) for x, y in zip(np.ravel(X), np.ravel(Y))])\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "# Create a contour plot\n",
    "plt.figure()\n",
    "plt.contourf(X, Y, Z, levels=100, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Rosenbrock Function')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T22:31:01.009892Z",
     "end_time": "2023-04-30T22:31:09.361271Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T21:52:47.667355Z",
     "end_time": "2023-04-30T21:52:47.688342Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (denoising_diffusion_samplers)",
   "language": "python",
   "name": "pycharm-c47a5953"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
